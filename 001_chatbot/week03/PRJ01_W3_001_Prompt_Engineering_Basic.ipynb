{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ - íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ê³„\n",
    "\n",
    "### **í•™ìŠµ ëª©í‘œ:**  íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì˜ ê¸°ë³¸ êµ¬ì¡°ì™€ ì„¤ê³„ ì›ì¹™ì„ ì´í•´í•œë‹¤\n",
    "\n",
    "### í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "```bash\n",
    "uv add langchain-openai langchain-core python-dotenv defusedxml\n",
    "```\n",
    "\n",
    "### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒê³¼ ê°™ì´ OpenAI API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤:\n",
    "```\n",
    "OPENAI_API_KEY=your_api_key_here\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì¶”ê°€ í•„ê¸°\n",
    "- í”„ë¡¬í”„íŠ¸ ëª¨ë²” ì‚¬ë¡€ : https://platform.claude.com/docs/ko/build-with-claude/prompt-engineering/claude-prompting-best-practices\n",
    "\t- êµ¬ì²´ì ì¸ ì§ˆë¬¸, \n",
    "- êµì•ˆ\n",
    "\t- class ë³´ë‹¤ëŠ” from_template ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ë”ìš± ê¶Œì¥í•œë‹¤.\n",
    "\t\t- classë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ë”°ë¡œ ë³€ìˆ˜ ì²˜ë¦¬ë¥¼ í•´ì•¼í•˜ë¯€ë¡œ í•¨ìˆ˜ ë°©ì‹ì„ ë”ìš± ê¶Œì¥í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í™˜ê²½ ì„¤ì • ë° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env í™˜ê²½ë³€ìˆ˜`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) LLM ì„¤ì •`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4.1-nano',\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **í”„ë¡¬í”„íŠ¸ ìœ í˜•**\n",
    "\n",
    "- ì¢…ë¥˜: ì§ˆë¬¸í˜•, ì§€ì‹œí˜•, ëŒ€í™”í˜•, ì¡°ê±´ë¶€, ì˜ˆì‹œ ê¸°ë°˜ ë“± \n",
    "- ì´ëŸ¬í•œ í”„ë¡¬í”„íŠ¸ ìœ í˜•ë“¤ì€ ìƒí™©ì— ë”°ë¼ ì¡°í•©í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥\n",
    "- ëª©ì ì— ë§ëŠ” ì ì ˆí•œ ìœ í˜•ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ì§ˆë¬¸í˜• í”„ë¡¬í”„íŠ¸ (Question Prompts)`\n",
    "   - ì •ë³´ ì¶”ì¶œì— íš¨ê³¼ì \n",
    "   - êµ¬ì²´ì ì¸ ë‹µë³€ ìœ ë„ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# ë‹¨ìˆœ ì§ˆë¬¸í˜•\n",
    "question_prompt = PromptTemplate(\n",
    "    template=\"ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ë¬´ì—‡ì„ ì•Œê³  ìˆë‚˜ìš”?: {topic}\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "# LCEL chain êµ¬ì„±\n",
    "chain = question_prompt | llm\n",
    "\n",
    "# ì§ˆë¬¸\n",
    "topic = \"ì–‘ì ì»´í“¨íŒ…\"\n",
    "output = chain.invoke({\"topic\": topic})\n",
    "pprint(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from_template ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•œ ë°©ë²•\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pprint import pprint\n",
    "\n",
    "# from_templateì„ ì‚¬ìš©í•œ PromptTemplate ìƒì„±\n",
    "question_template = \"ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ë¬´ì—‡ì„ ì•Œê³  ìˆë‚˜ìš”?: {topic}\"\n",
    "question_prompt = PromptTemplate.from_template(question_template)\n",
    "\n",
    "# LCEL chain êµ¬ì„±\n",
    "chain = question_prompt | llm\n",
    "\n",
    "# ì§ˆë¬¸ ì‹¤í–‰\n",
    "topic = \"ì–‘ì ì»´í“¨íŒ…\"\n",
    "output = chain.invoke({\"topic\": topic})\n",
    "pprint(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ì°¸ê³ ]** `from_template` ë°©ì‹ì˜ ì¥ì :\n",
    "- ì½”ë“œê°€ ë” ê°„ê²°í•´ì§„ë‹¤\n",
    "- ì…ë ¥ ë³€ìˆ˜ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì§€ì •í•  í•„ìš”ê°€ ì—†ë‹¤\n",
    "- í…œí”Œë¦¿ì—ì„œ ì‚¬ìš©ëœ ë³€ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•œë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶„ì„ ì§ˆë¬¸í˜• \n",
    "analysis_prompt = PromptTemplate(\n",
    "    template=\"\"\"ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” ë…¼ì ì€ ë¬´ì—‡ì¸ê°€ìš”? ì„¸ ê°€ì§€ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "    [í…ìŠ¤íŠ¸]\n",
    "    {text}\n",
    "\n",
    "    [ë‹µë³€]\n",
    "    \"\"\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "# LCEL\n",
    "chain = analysis_prompt | llm\n",
    "\n",
    "# ì§ˆë¬¸\n",
    "text = \"\"\"ì–‘ì ì»´í“¨íŒ…ì€ ì–‘ìì—­í•™ì˜ ì›ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì»´í“¨íŒ… ê¸°ìˆ ì´ë‹¤. \n",
    "ì–‘ì ì»´í“¨íŒ…ì€ ì „í†µì ì¸ ì»´í“¨íŒ…ê³¼ëŠ” ë‹¤ë¥´ê²Œ ì–‘ìì—­í•™ì˜ ì›ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ì •ë³´ë¥¼ ì²˜ë¦¬í•œë‹¤. \n",
    "ì–‘ì ì»´í“¨íŒ…ì€ ì–‘ìì—­í•™ì˜ ì›ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì»´í“¨íŒ… ê¸°ìˆ ì´ë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "output = chain.invoke({\"text\": text})\n",
    "pprint(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[ì‹¤ìŠµ 1]**\n",
    "\n",
    "- ì•ì˜ ì˜ˆì œë¥¼ from_template ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ì§€ì‹œí˜• í”„ë¡¬í”„íŠ¸ (Instruction Prompts)`\n",
    "   - ëª…í™•í•œ ì‘ì—… ìˆ˜í–‰ ì§€ì‹œ\n",
    "   - ë‹¨ê³„ë³„ ì²˜ë¦¬ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# ì‘ì—… ì§€ì‹œí˜•\n",
    "task_prompt = PromptTemplate(\n",
    "    template=\"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”:\\n\\n[í…ìŠ¤íŠ¸]\\n{text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "# LCEL\n",
    "chain = task_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ì§ˆë¬¸\n",
    "text = \"Quantum computing is a computing technology that uses the principles of quantum mechanics to process information.\"\n",
    "output = chain.invoke({\"text\": text})\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì¶”ê°€ í•„ê¸°\n",
    "- ì•„ë˜ ì‘ì—… ìˆœì„œë¥¼ ë„£ì–´ì£¼ë©´ ë¨¸ì‹ ì´ í•´ë‹¹ ìˆœì„œëŒ€ë¡œ ì§„í–‰ëœë‹¤.\n",
    "- nano ëª¨ë¸ì´ì–´ë„ ì›í•˜ëŠ” ìˆœì„œëŒ€ë¡œ ì§„í–‰ì´ ëœë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¨ê³„ë³„ ì§€ì‹œí˜•\n",
    "step_prompt = PromptTemplate(\n",
    "    template=\"\"\"ë‹¤ìŒ í…ìŠ¤íŠ¸ì— ëŒ€í•´ì„œ ì‘ì—…ì„ ìˆœì„œëŒ€ë¡œ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
    "\n",
    "    [í…ìŠ¤íŠ¸]\n",
    "    {text}\n",
    "\n",
    "    [ì‘ì—… ìˆœì„œ]\n",
    "    1. í…ìŠ¤íŠ¸ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½\n",
    "    2. í•µì‹¬ í‚¤ì›Œë“œ 3ê°œ ì¶”ì¶œ\n",
    "    3. ê°ì • ë¶„ì„ ìˆ˜í–‰(ê¸ì •/ë¶€ì •/ì¤‘ë¦½)\n",
    "\n",
    "    [ì‘ì—… ê²°ê³¼]\n",
    "    \"\"\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "# LCEL\n",
    "chain = step_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ì§ˆë¬¸\n",
    "text = \"\"\"\n",
    "ì–‘ì ì»´í“¨íŒ…ì€ ì–‘ìì—­í•™ì˜ ì›ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ìƒˆë¡œìš´ í˜•íƒœì˜ ê³„ì‚° ë°©ì‹ì´ë‹¤. \n",
    "ê¸°ì¡´ì˜ ê³ ì „ì  ì»´í“¨í„°ëŠ” 0ê³¼ 1ë¡œ ì´ë£¨ì–´ì§„ ì´ì§„ë²•(bit)ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì§€ë§Œ, \n",
    "ì–‘ì ì»´í“¨í„°ëŠ” ì–‘ì ë¹„íŠ¸(íë¹„íŠ¸, qubit)ë¥¼ ì‚¬ìš©í•˜ì—¬ í›¨ì”¬ ë” ë³µì¡í•˜ê³  ë¹ ë¥¸ ê³„ì‚°ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤. \n",
    "\n",
    "íë¹„íŠ¸ëŠ” ë™ì‹œì— 0ê³¼ 1ì˜ ìƒíƒœë¥¼ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì–‘ì ì¤‘ì²©(superposition) ìƒíƒœë¥¼ í™œìš©í•˜ë©°, \n",
    "ì´ë¥¼ í†µí•´ ë³‘ë ¬ ê³„ì‚°ê³¼ ê°™ì€ ê³ ê¸‰ ê¸°ëŠ¥ì´ ê°€ëŠ¥í•˜ë‹¤.\n",
    "\"\"\" \n",
    "\n",
    "output = chain.invoke({\"text\": text})\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[ì‹¤ìŠµ 2]**\n",
    "\n",
    "- ë‘ ê°œì˜ ë¬¸ì¥ì„ ì…ë ¥ë°›ì•„ì„œ, ë‘ ë¬¸ì¥ì˜ ë§¥ë½ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ë¹„êµ ë¶„ì„í•˜ëŠ” ì²´ì¸ì„ êµ¬ì„±í•˜ì„¸ìš”.\n",
    "- PromptTemplateë¥¼ ì‚¬ìš©í•˜ê³ , ë‘ ë¬¸ì¥ì„ ì…ë ¥ë°›ì„ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. \n",
    "- ë‹¨ê³„ë³„ ì§€ì‹œí˜• í”„ë¡¬í”„íŠ¸ë¡œ ì‘ì„±í•©ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ì‹¤ìŠµ2 ê°•ì‚¬ë‹˜ ì½”ë“œ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "context_prompt = PromptTemplate(\n",
    "    template=\"\"\"ë‹¤ìŒ ë‘ ë¬¸ì¥ì˜ ë§¥ë½ ì¼ì¹˜ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "    [ë¬¸ì¥ 1]\n",
    "    {sentence1}\n",
    "\n",
    "    [ë¬¸ì¥ 2]\n",
    "    {sentence2}\n",
    "\n",
    "    [ë¶„ì„ ë‹¨ê³„]\n",
    "    1. ê° ë¬¸ì¥ì˜ ì£¼ìš” ì£¼ì œ íŒŒì•…\n",
    "    2. í•µì‹¬ í‚¤ì›Œë“œ ë¹„êµ\n",
    "    3. ë¬¸ë§¥ì  ì—°ê´€ì„± ë¶„ì„\n",
    "    4. ì¼ì¹˜ì„± ì ìˆ˜ ì‚°ì¶œ (0-100%)\n",
    "\n",
    "    [ë¶„ì„ ê²°ê³¼ í˜•ì‹]\n",
    "    ì£¼ì œ ë¶„ì„:\n",
    "    í‚¤ì›Œë“œ ë¹„êµ:\n",
    "    ë§¥ë½ ë¶„ì„:\n",
    "    ì¼ì¹˜ì„± ì ìˆ˜:\n",
    "    ìµœì¢… íŒë‹¨: (ì¼ì¹˜/ë¶ˆì¼ì¹˜)\n",
    "    \"\"\",\n",
    "    input_variables=[\"sentence1\", \"sentence2\"]\n",
    ")\n",
    "\n",
    "# LCEL chain êµ¬ì„±\n",
    "chain = context_prompt | llm\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë¬¸ì¥\n",
    "sentence1 = \"ì¸ê³µì§€ëŠ¥ì€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\"\n",
    "sentence2 = \"ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì€ ë°ì´í„°ì…‹ì„ í†µí•´ íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤.\"\n",
    "\n",
    "# ì§ˆë¬¸ ì‹¤í–‰\n",
    "output = chain.invoke({\"sentence1\": sentence1, \"sentence2\": sentence2})\n",
    "pprint(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ (Conversational Prompts)`\n",
    "   - ìì—°ìŠ¤ëŸ¬ìš´ ìƒí˜¸ì‘ìš©\n",
    "   - ë¬¸ë§¥ ìœ ì§€ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ChatPromptTemplate ê°ì²´ë¥¼ ì§ì ‘ ìƒì„± (ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸, ì…ë ¥ ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸)\n",
    "chat_prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ìì…ë‹ˆë‹¤.\"),\n",
    "        (\"human\", \"{customer_message}\")\n",
    "    ],\n",
    "    input_variables=[\"customer_message\"]\n",
    ")\n",
    "\n",
    "# LCEL chain êµ¬ì„±\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ì§ˆë¬¸ ì‹¤í–‰\n",
    "customer_message = \"ì•ˆë…•í•˜ì„¸ìš”. ì œí’ˆ ë°°ì†¡ ë¬¸ì œë¡œ ì—°ë½ë“œë ¸ì–´ìš”.\"\n",
    "output = chain.invoke({\"customer_message\": customer_message})\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# from_messages ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•œ ChatPromptTemplate ìƒì„±\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ìì…ë‹ˆë‹¤.\"),\n",
    "    (\"human\", \"{customer_message}\"),\n",
    "])\n",
    "\n",
    "# LCEL\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ì§ˆë¬¸\n",
    "customer_message = \"ì•ˆë…•í•˜ì„¸ìš”. ì œí’ˆ ë°°ì†¡ ë¬¸ì œë¡œ ì—°ë½ë“œë ¸ì–´ìš”.\"\n",
    "output = chain.invoke({\"customer_message\": customer_message})\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "# ë©”ì‹œì§€ í…œí”Œë¦¿ ì‚¬ìš©\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ìì…ë‹ˆë‹¤.\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"{customer_message}\"\n",
    "    )\n",
    "])\n",
    "\n",
    "# LCEL\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ì§ˆë¬¸\n",
    "customer_message = \"ì•ˆë…•í•˜ì„¸ìš”. ì œí’ˆ ë°°ì†¡ ë¬¸ì œë¡œ ì—°ë½ë“œë ¸ì–´ìš”.\"\n",
    "output = chain.invoke({\"customer_message\": customer_message})\n",
    "pprint(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[ì‹¤ìŠµ 3]**\n",
    "\n",
    "- ìƒí’ˆ ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ëŠ” AI ì²´ì¸ì„ ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤. \n",
    "- ë©”ì‹œì§€ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ ì—­í• ì„ êµ¬ë¶„í•©ë‹ˆë‹¤. \n",
    "- role, message êµ¬ë¶„í•´ì„œ ì²˜ë¦¬í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì‹¤ìŠµì„ ë³€ê²½í•´ë„ ëœë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì‹œ ë¦¬ë·°\n",
    "reviews = [\n",
    "    \"ì´ ë¸”ë£¨íˆ¬ìŠ¤ ì´ì–´í° ì •ë§ ë§Œì¡±ìŠ¤ëŸ¬ì›Œìš”! ìŒì§ˆë„ ì¢‹ê³  ë°°í„°ë¦¬ë„ ì˜¤ë˜ê°€ìš”. ë‹¤ë§Œ ì¼€ì´ìŠ¤ê°€ ì¢€ í° ê°ì´ ìˆë„¤ìš”.\",\n",
    "    \"ë°°ì†¡ì€ ë¹¨ëëŠ”ë° ì œí’ˆ í’ˆì§ˆì´ ê¸°ëŒ€ì— ëª» ë¯¸ì³ìš”. í„°ì¹˜ê°ì´ ë‘”í•˜ê³  ì—°ê²°ì´ ìì£¼ ëŠê¹ë‹ˆë‹¤. ê°€ì„±ë¹„ ìƒê°í•˜ë©´ ê·¸ëƒ¥ ì“¸ë§Œí•˜ë„¤ìš”.\",\n",
    "    \"ê°€ê²©ëŒ€ë¹„ ê´œì°®ì€ ê²ƒ ê°™ì•„ìš”. ë””ìì¸ë„ ê¹”ë”í•˜ê³  ê¸°ë³¸ì ì¸ ê¸°ëŠ¥ì€ ë‹¤ ê°–ì·„ë„¤ìš”. ì¶”ì²œí•©ë‹ˆë‹¤!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "\n",
    "# ê° ë¦¬ë·° ë¶„ì„ ì‹¤í–‰\n",
    "for idx, review in enumerate(reviews, 1):\n",
    "    print(f\"\\n=== ë¦¬ë·° {idx} ë¶„ì„ ê²°ê³¼ ===\")\n",
    "    result = review_chain.invoke({\"review\": review})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ì‹¤ìŠµ 3 ê°•ì‚¬ë‹˜ ì½”ë“œ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¦¬ë·° ë¶„ì„ í…œí”Œë¦¿ ìƒì„±\n",
    "review_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"ë‹¹ì‹ ì€ ìƒí’ˆ ë¦¬ë·° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¦¬ë·°ì˜ ê°ì •ê³¼ ì£¼ìš” í¬ì¸íŠ¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.\"\n",
    "        ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"ë‹¤ìŒ ë¦¬ë·°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”: {review}\"\n",
    "        )\n",
    "])\n",
    "\n",
    "# LCEL\n",
    "review_chain = review_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ê° ë¦¬ë·° ë¶„ì„ ì‹¤í–‰\n",
    "for idx, review in enumerate(reviews, 1):\n",
    "    print(f\"\\n=== ë¦¬ë·° {idx} ë¶„ì„ ê²°ê³¼ ===\")\n",
    "    result = review_chain.invoke({\"review\": review})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) ì˜ˆì‹œ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ (Few-Shot Prompts)`\n",
    "   - ì›í•˜ëŠ” ì¶œë ¥ í˜•ì‹ ëª…í™•í™”\n",
    "   - ëª¨ë¸ì˜ ì´í•´ë„ í–¥ìƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = PromptTemplate(\n",
    "    template=\"\"\"ë‹¤ìŒì€ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤:\n",
    "\n",
    "ì›ë¬¸: {example_input}\n",
    "ìš”ì•½: {example_output}\n",
    "\n",
    "ì´ì œ ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ 50ì ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n",
    "ì›ë¬¸: {input_text}\n",
    "ìš”ì•½:\n",
    "\"\"\",\n",
    "    input_variables=[\"example_input\", \"example_output\", \"input_text\"]\n",
    ")\n",
    "\n",
    "# LCEL\n",
    "chain = few_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ì˜ˆì‹œ í…ìŠ¤íŠ¸ \n",
    "example_input = \"\"\"ì¸ê³µì§€ëŠ¥(AI)ì€ ì¸ê°„ì˜ í•™ìŠµëŠ¥ë ¥, ì¶”ë¡ ëŠ¥ë ¥, ì§€ê°ëŠ¥ë ¥, ìì—°ì–¸ì–´ì˜ ì´í•´ëŠ¥ë ¥ ë“±ì„ \n",
    "ì»´í“¨í„° í”„ë¡œê·¸ë¨ìœ¼ë¡œ ì‹¤í˜„í•œ ê¸°ìˆ ì´ë‹¤. ì¸ê³µì§€ëŠ¥ì€ ë”¥ëŸ¬ë‹, ê¸°ê³„í•™ìŠµ ë“± ë‹¤ì–‘í•œ ê¸°ìˆ ì„ í¬í•¨í•˜ë©°, \n",
    "ìµœê·¼ì—ëŠ” ììœ¨ì£¼í–‰, ì˜ë£Œì§„ë‹¨, ì–¸ì–´ë²ˆì—­ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ê³  ìˆë‹¤.\"\"\"\n",
    "\n",
    "example_output = \"ì¸ê³µì§€ëŠ¥: ì¸ê°„ì˜ í•™ìŠµëŠ¥ë ¥, ì¶”ë¡ ëŠ¥ë ¥, ì§€ê°ëŠ¥ë ¥ ë“±ì„ ì»´í“¨í„° í”„ë¡œê·¸ë¨ìœ¼ë¡œ ì‹¤í˜„í•œ ê¸°ìˆ \"\n",
    "\n",
    "# ì…ë ¥ í…ìŠ¤íŠ¸ \n",
    "input_text = \"\"\"ì–‘ì ì»´í“¨íŒ…ì€ ì–‘ìì—­í•™ì˜ ì›ë¦¬ë¥¼ í™œìš©í•˜ì—¬ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” í˜ì‹ ì ì¸ ì»´í“¨íŒ… ê¸°ìˆ ì´ë‹¤. \n",
    "ê¸°ì¡´ì˜ ë””ì§€í„¸ ì»´í“¨í„°ê°€ 0ê³¼ 1ì˜ ì´ì§„ë²•ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ë‹¬ë¦¬, ì–‘ì ì»´í“¨í„°ëŠ” ì¤‘ì²© ìƒíƒœë¥¼ í™œìš©í•˜ì—¬ \n",
    "ë™ì‹œì— ì—¬ëŸ¬ ê³„ì‚°ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ íŠ¹ì • ë¬¸ì œì—ì„œëŠ” ê¸°ì¡´ ì»´í“¨í„°ë³´ë‹¤ \n",
    "ì›”ë“±íˆ ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ë¥¼ ë³´ì—¬ì¤€ë‹¤. í˜„ì¬ëŠ” ì•„ì§ ì´ˆê¸° ë‹¨ê³„ì§€ë§Œ, ì•”í˜¸í™”, ì‹ ì•½ ê°œë°œ, ê¸°í›„ ëª¨ë¸ë§ ë“± \n",
    "ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í˜ì‹ ì ì¸ ë°œì „ì´ ê¸°ëŒ€ëœë‹¤.\"\"\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "output = chain.invoke({\n",
    "    \"example_input\": example_input, \n",
    "    \"example_output\": example_output, \n",
    "    \"input_text\": input_text\n",
    "})\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[ì‹¤ìŠµ 4]**\n",
    "\n",
    "- [ì‹¤ìŠµ 3]ì˜ ìƒí’ˆ ë¦¬ë·° ë¶„ì„ ì‹œìŠ¤í…œì˜ ì…ì¶œë ¥ í˜•ì‹ì„ ì˜ˆì‹œë¡œ ì¶”ê°€í•´ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "- ì²´ì¸ì„ ì‹¤í•´í•˜ì—¬ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) ì¡°ê±´ë¶€ í”„ë¡¬í”„íŠ¸ (Conditional Prompts)`\n",
    "   - ìƒí™©ë³„ ë‹¤ë¥¸ ì²˜ë¦¬\n",
    "   - ìœ ì—°í•œ ì‘ë‹µ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¡°ê±´ë¶€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (ì…ë ¥ í…ìŠ¤íŠ¸ì— ë”°ë¼ ì‘ì—… ìœ í˜•ì„ ì§€ì •)\n",
    "conditional_prompt = PromptTemplate(\n",
    "    template=\"\"\"ì…ë ¥ í…ìŠ¤íŠ¸: {text}\n",
    "\n",
    "ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ê°€ ì§ˆë¬¸ì¸ ê²½ìš°: ëª…í™•í•œ ë‹µë³€ì„ ì œê³µ\n",
    "ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ê°€ ì§„ìˆ ë¬¸ì¸ ê²½ìš°: ì§„ìˆ ë¬¸ì˜ ì‚¬ì‹¤ ì—¬ë¶€ë¥¼ ê²€ì¦\n",
    "ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ê°€ ìš”ì²­ì‚¬í•­ì¸ ê²½ìš°: ìˆ˜í–‰ ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…\n",
    "\n",
    "ì‘ë‹µì€ ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”:\n",
    "ìœ í˜•: [ì§ˆë¬¸/ì§„ìˆ ë¬¸/ìš”ì²­ì‚¬í•­]\n",
    "ë‚´ìš©: [ìƒì„¸ ì‘ë‹µ]\"\"\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "# LCEL ì²´ì¸ êµ¬ì„±\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "chain = conditional_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸í˜• í…ŒìŠ¤íŠ¸\n",
    "response = chain.invoke({\n",
    "    \"text\": \"ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ ì¼ìë¦¬ë¥¼ ëª¨ë‘ ëŒ€ì²´í•˜ê²Œ ë ê¹Œìš”?\",\n",
    "})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§„ìˆ ë¬¸ í…ŒìŠ¤íŠ¸\n",
    "response = chain.invoke({\n",
    "    \"text\": \"ì–‘ìì»´í“¨í„°ëŠ” í˜„ì¬ ëª¨ë“  ì•”í˜¸í™” ì‹œìŠ¤í…œì„ ë¬´ë ¥í™”í•  ìˆ˜ ìˆë‹¤.\"\n",
    "})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìš”ì²­ì‚¬í•­ í…ŒìŠ¤íŠ¸\n",
    "response = chain.invoke({\n",
    "        \"text\": \"íŒŒì´ì¬ìœ¼ë¡œ ê°„ë‹¨í•œ ì›¹ ìŠ¤í¬ë˜í¼ë¥¼ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤.\"\n",
    "})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°œë…**\n",
    "\n",
    "1. **ê°œë…**:\n",
    "    - AI ëª¨ë¸ì—ê²Œ íš¨ê³¼ì ì¸ ì§€ì‹œë¥¼ ì œê³µí•˜ì—¬ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ì–´ë‚´ëŠ” ê¸°ìˆ \n",
    "    - ì…ë ¥(í”„ë¡¬í”„íŠ¸)ì„ ìµœì í™”í•˜ì—¬ ì¶œë ¥ì˜ í’ˆì§ˆì„ í–¥ìƒí•˜ëŠ” ë°©ë²• \n",
    "\n",
    "2. **ì›ì¹™**:\n",
    "\n",
    "    1. **ëª…í™•ì„±(Clarity)**\n",
    "        - ëª¨í˜¸í•˜ì§€ ì•Šì€ ëª…í™•í•œ ì§€ì‹œì‚¬í•­ ì œê³µ\n",
    "        - êµ¬ì²´ì ì¸ ìš”êµ¬ì‚¬í•­ê³¼ ì œì•½ì¡°ê±´ ëª…ì‹œ\n",
    "        - ì˜ˆì‹œ: \"5ê°œì˜ ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”\" vs \"ìš”ì•½í•´ì£¼ì„¸ìš”\"\n",
    "\n",
    "    2. **ë§¥ë½ì„±(Context)**\n",
    "        - ê´€ë ¨ ë°°ê²½ ì •ë³´ ì œê³µ\n",
    "        - ëª©ì ê³¼ ì˜ë„ ëª…ì‹œ\n",
    "        - ëŒ€ìƒ ë…ìë‚˜ ì‚¬ìš© í™˜ê²½ ì„¤ëª…\n",
    "\n",
    "    3. **êµ¬ì¡°í™”(Structure)**\n",
    "        - ì²´ê³„ì ì¸ í˜•ì‹ ì‚¬ìš©\n",
    "        - ë‹¨ê³„ë³„ ì§€ì‹œì‚¬í•­ ì œê³µ\n",
    "        - ì›í•˜ëŠ” ì¶œë ¥ í˜•ì‹ ëª…ì‹œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ì¶”ê°€ í•„ê¸°\n",
    "\n",
    "- í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•  ë•Œ \n",
    " 1. ì˜ˆì‹œ í…ìŠ¤íŠ¸ì™€ ë¹„ìŠ·í•œ í˜•ì‹ìœ¼ë¡œ ì˜ˆì‹œë¥¼ ì‘ì„±í•˜ë©´ í˜¼ëˆì´ ë˜ë¯€ë¡œ, í˜•ì‹ì€ ë‹¤ë¥´ê²Œ ì…ë ¥í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•œë‹¤.\n",
    " \n",
    " 2. ì˜ˆì‹œì—ì„œ\n",
    "\t- 1. ì–´ë–»ê²Œ 2. ì €ë ¿ê²Œ 3. ìš”ë ‡ê²Œ\n",
    "\t- ì´ëŸ° ë°©ì‹ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì˜ˆì‹œë¥¼ ì‘ì„±í•´ì£¼ë©´ ì¢€ ë” ëª…í™•ì„±ì´ ì˜¬ë¼ê°€ê²Œ ëœë‹¤.\n",
    "\t- ë”°ë¼ì„œ, ê¸´ ë¬¸ì¥ìœ¼ë¡œ ëª…ë ¹í•˜ëŠ” ê²ƒì€ íŒë‹¨í•˜ê¸° ì–´ë µë‹¤.\n",
    "\n",
    "3. íŒŒì¼ì„ ì½ì–´ì˜¤ê²Œ í•˜ëŠ” ë°©ì‹ë„ ê°€ëŠ¥í•œê°€?\n",
    "\t- íŒŒì¼ì„ ê°–ê³ ì˜¤ëŠ” ê¶Œí•œì´ í”„ë¡¬í”„íŠ¸ì—ëŠ” ì—†ë‹¤.\n",
    "\t- íŠ¹ì • í•¨ìˆ˜ë¥¼ í†µí•´ì„œ ì–´ë–¤ íŒŒì¼ì„ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë°©ë²•ì€ ìˆë‹¤.\n",
    "\t\t- part2, 3ì—ì„œ ë„êµ¬ë¼ëŠ” ê°œë…ì—ì„œ ë°°ìš¸ ì˜ˆì •\n",
    "\t\t- https://platform.claude.com/docs/ko/agents-and-tools/tool-use/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. **ëª…í™•ì„±(Clarity)**\n",
    "\n",
    "- **í”„ë¡¬í”„íŠ¸ì˜ ëª…í™•ì„±**ì€ AI ëª¨ë¸ê³¼ì˜ íš¨ê³¼ì ì¸ ì†Œí†µì„ ìœ„í•œ í•µì‹¬ ìš”ì†Œ\n",
    "\n",
    "- ë¶ˆí•„ìš”í•œ ë‚´ìš©ì„ ì œì™¸í•˜ê³  **í•µì‹¬ ìš”êµ¬ì‚¬í•­**ì—ë§Œ ì§‘ì¤‘í•˜ì—¬ ì‘ì„±\n",
    "\n",
    "- ì›í•˜ëŠ” ê²°ê³¼ë¬¼ì— ëŒ€í•´ **êµ¬ì²´ì ì´ê³  ì •í™•í•œ ì§€ì‹œ**ë¥¼ ì œê³µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# ëª…í™•í•œ ì§€ì‹œì‚¬í•­ì´ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "clear_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"\"\"\n",
    "    ì£¼ì œ: {topic}\n",
    "    \n",
    "    ë‹¤ìŒ ê¸°ì¤€ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ ì„¤ëª…í•˜ì‹œì˜¤:\n",
    "    1. ì •í™•íˆ 3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•  ê²ƒ (Bullet point ì‚¬ìš©í•˜ì—¬ êµ¬ë¶„)\n",
    "    2. ê° ë¬¸ì¥ì€ 20ë‹¨ì–´ ì´ë‚´ë¡œ ì‘ì„±í•  ê²ƒ\n",
    "    3. ì „ë¬¸ ìš©ì–´ëŠ” ê´„í˜¸ ì•ˆì— ê°„ë‹¨í•œ ì„¤ëª…ì„ í¬í•¨í•  ê²ƒ\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# LCEL ì²´ì¸\n",
    "clear_chain = clear_prompt | llm \n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "result = clear_chain.invoke({\"topic\": \"ì¸ê³µì§€ëŠ¥\"})\n",
    "pprint(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. **ë§¥ë½ì„±(Context)**\n",
    "\n",
    "- **ë§¥ë½ ì œê³µ**ì€ AIê°€ ì‘ì—…ì˜ ë°°ê²½ê³¼ ëª©ì ì„ ì´í•´í•˜ëŠ”ë° í•„ìˆ˜ì ì¸ ìš”ì†Œ\n",
    "\n",
    "- í”„ë¡¬í”„íŠ¸ì— **ë°°ê²½ ì •ë³´**, **ëª©ì **, **ëŒ€ìƒ í™˜ê²½**ì„ ëª…í™•íˆ í¬í•¨\n",
    "\n",
    "- ì ì ˆí•œ ë§¥ë½ ì œê³µì€ AIì˜ **ì¶œë ¥ í’ˆì§ˆ**ê³¼ **ì •í™•ë„**ë¥¼ í¬ê²Œ í–¥ìƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ë§¥ë½ì´ ë¶€ì¡±í•œ í”„ë¡¬í”„íŠ¸ì˜ ì˜ˆ\n",
    "bad_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "ì‚¬ìš©ì ì§ˆë¬¸: {user_question}                                              \n",
    "\"\"\")\n",
    "\n",
    "# ë§¥ë½ì´ í’ë¶€í•œ í”„ë¡¬í”„íŠ¸ì˜ ì˜ˆ\n",
    "good_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ì‚¬ìš©ì ì§ˆë¬¸: {user_question}\n",
    "\n",
    "ë°°ê²½: 65ì„¸ ì´ìƒ ë…¸ì¸ì„ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” ìŠ¤ë§ˆíŠ¸í° êµìœ¡ í”„ë¡œê·¸ë¨ì„ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "ëª©ì : ì²˜ìŒ ìŠ¤ë§ˆíŠ¸í°ì„ ì‚¬ìš©í•˜ëŠ” ë…¸ì¸ë“¤ì´ ê¸°ë³¸ ê¸°ëŠ¥ì„ ì‰½ê²Œ ìµí ìˆ˜ ìˆë„ë¡ ë•ê³ ì í•©ë‹ˆë‹¤.\n",
    "ëŒ€ìƒ: ë””ì§€í„¸ ê¸°ê¸° ì‚¬ìš© ê²½í—˜ì´ ê±°ì˜ ì—†ëŠ” ë…¸ì¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ìœ„ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ì‘ë‹µí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì‘ë‹µ í˜•ì‹:\n",
    "- ì‰¬ìš´ ìš©ì–´ ì‚¬ìš©\n",
    "- ë‹¨ê³„ë³„ ì„¤ëª…\n",
    "- êµ¬ì²´ì ì¸ ì˜ˆì‹œ í¬í•¨\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# LCEL ì²´ì¸\n",
    "good_chain = good_prompt | llm \n",
    "bad_chain = bad_prompt | llm\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "question = \"ì•„ì´í°ì— ì¹´ì¹´ì˜¤í†¡ ì„¤ì¹˜í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "good_result = good_chain.invoke({\"user_question\": question})\n",
    "bad_result = bad_chain.invoke({\"user_question\": question})\n",
    "\n",
    "print(\"ë§¥ë½ì´ ë¶€ì¡±í•œ í”„ë¡¬í”„íŠ¸ì˜ ê²°ê³¼\")\n",
    "pprint(bad_result.content)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"ë§¥ë½ì´ í’ë¶€í•œ í”„ë¡¬í”„íŠ¸ì˜ ê²°ê³¼\")\n",
    "pprint(good_result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. **êµ¬ì¡°í™”(Structure)**\n",
    "\n",
    "- í”„ë¡¬í”„íŠ¸ ì…ë ¥ì˜ êµ¬ì¡°í™”: PromptTemplate, ChatPromptTemplate ì‚¬ìš©\n",
    "- LLM ì¶œë ¥ì˜ êµ¬ì¡°í™”: OutputParser, Schema ì‚¬ìš©\n",
    "\n",
    "- ê¸°ëŒ€íš¨ê³¼:\n",
    "    - ì¼ê´€ëœ í˜•ì‹ì˜ ì…ì¶œë ¥ ë³´ì¥\n",
    "    - ë°ì´í„° ì²˜ë¦¬ ë° í›„ì† ì‘ì—…ì˜ ìš©ì´ì„±\n",
    "    - ì˜¤ë¥˜ ì²˜ë¦¬ì˜ ì²´ê³„í™”\n",
    "    - ì¬ì‚¬ìš©ì„± í–¥ìƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (Prompt Template)\n",
    "\n",
    "- **í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿**ì€ LLMê³¼ì˜ ìƒí˜¸ì‘ìš©ì„ êµ¬ì¡°í™”í•˜ëŠ” í•µì‹¬ ë„êµ¬\n",
    "\n",
    "- í…œí”Œë¦¿ì€ ë‹¤ì–‘í•œ ì…ë ¥ê°’ìœ¼ë¡œ **ì¬ì‚¬ìš©**ì´ ê°€ëŠ¥í•˜ë©° **ìœ ì—°í•œ ë³€ìˆ˜ ì²˜ë¦¬**ë¥¼ ì§€ì›\n",
    "\n",
    "- **ê²€ì¦ ê¸°ëŠ¥**ê³¼ **ë¶€ë¶„ í¬ë§·íŒ…**ì„ í†µí•´ í”„ë¡¬í”„íŠ¸ ì‘ì„±ì˜ ì•ˆì •ì„±ì„ ë³´ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ê¸°ë³¸ í…œí”Œë¦¿`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# í…œí”Œë¦¿ ì •ì˜\n",
    "template = \"\"\"\n",
    "ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”: {topic}\n",
    "í¬í•¨í•´ì•¼ í•  ë‚´ìš©: {content}\n",
    "ê¸€ììˆ˜: {length}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"topic\", \"content\", \"length\"]\n",
    ")\n",
    "\n",
    "# í…œí”Œë¦¿ ì‚¬ìš©\n",
    "formatted_prompt = prompt.format(\n",
    "    topic=\"ì¸ê³µì§€ëŠ¥\",\n",
    "    content=\"ì •ì˜, ì—­ì‚¬, ì‘ìš©ë¶„ì•¼\",\n",
    "    length=\"500ì\"\n",
    ")\n",
    "\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) from_template ë©”ì†Œë“œ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# í…œí”Œë¦¿ ë¬¸ìì—´ ì •ì˜\n",
    "template = \"\"\"\n",
    "ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”: {topic}\n",
    "í¬í•¨í•´ì•¼ í•  ë‚´ìš©: {content}\n",
    "ê¸€ììˆ˜: {length}\n",
    "\"\"\"\n",
    "\n",
    "# í…œí”Œë¦¿ ìƒì„± (í…œí”Œë¦¿ ë¬¸ìì—´ ì§€ì •)\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# í…œí”Œë¦¿ ì‚¬ìš© (ì…ë ¥ ë³€ìˆ˜ ì§€ì •)\n",
    "formatted_prompt = prompt.format(\n",
    "    topic=\"ì¸ê³µì§€ëŠ¥\",\n",
    "    content=\"ì •ì˜, ì—­ì‚¬, ì‘ìš©ë¶„ì•¼\",\n",
    "    length=\"500ì\"\n",
    ")\n",
    "\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) í…œí”Œë¦¿ ê²€ì¦ ë° ë¶€ë¶„ í¬ë§·íŒ…`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# í…œí”Œë¦¿ ìƒì„± \n",
    "template = PromptTemplate(\n",
    "    template=\"{product}ì˜ ë‹¤ìŒ íŠ¹ì§•ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: {feature}\",  # í…œí”Œë¦¿ ë¬¸ìì—´\n",
    "    input_variables=[\"product\", \"feature\"],  # ì…ë ¥ ë³€ìˆ˜ ëª©ë¡\n",
    "    validate_template=True  # í…œí”Œë¦¿ ìœ íš¨ì„± ê²€ì¦\n",
    ")\n",
    "\n",
    "# ë¶€ë¶„ì ìœ¼ë¡œ ë³€ìˆ˜ ì±„ìš°ê¸°\n",
    "partial_prompt = template.partial(product=\"ìŠ¤ë§ˆíŠ¸í°\")\n",
    "\n",
    "print(f\"ë¶€ë¶„ì ìœ¼ë¡œ ë³€ìˆ˜ ì±„ì›Œì§„ í…œí”Œë¦¿: {partial_prompt}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# ë‚˜ì¤‘ì— ë‚˜ë¨¸ì§€ ë³€ìˆ˜ ì±„ìš°ê¸°\n",
    "final_prompt1 = partial_prompt.format(feature=\"ì¹´ë©”ë¼\")\n",
    "\n",
    "print(f\"ë‚˜ë¨¸ì§€ ë³€ìˆ˜ ì±„ì›Œì§„ í…œí”Œë¦¿: {final_prompt1}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# ë‹¤ë¥¸ íŠ¹ì§•ì„ ë¶„ì„í•˜ë„ë¡ ë³€ìˆ˜ ë³€ê²½\n",
    "final_prompt2 = partial_prompt.format(feature=\"ë°°í„°ë¦¬ ìˆ˜ëª…\")\n",
    "\n",
    "print(f\"ë‹¤ë¥¸ ë³€ìˆ˜ ì±„ì›Œì§„ í…œí”Œë¦¿: {final_prompt2}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# ëª¨ë“  ë³€ìˆ˜ë¥¼ í•œ ë²ˆì— ì±„ìš°ê¸°\n",
    "final_prompt3 = template.format(product=\"ë…¸íŠ¸ë¶\", feature=\"ë°°í„°ë¦¬ ìˆ˜ëª…\")\n",
    "\n",
    "print(f\"ëª¨ë“  ë³€ìˆ˜ ì±„ì›Œì§„ í…œí”Œë¦¿: {final_prompt3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…œí”Œë¦¿ ìœ íš¨ì„± ê²€ì¦ ì‹¤íŒ¨\n",
    "try:\n",
    "    invalid_prompt = template.format(product=\"ìŠ¤ë§ˆíŠ¸í°\")\n",
    "except ValueError as e:\n",
    "    print(f\"í…œí”Œë¦¿ ìœ íš¨ì„± ê²€ì¦ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) ì±— í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (Chat Prompt Template)\n",
    "\n",
    "- **ì±— í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿**ì€ ëŒ€í™”í˜• AIì™€ì˜ ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ íŠ¹í™”ëœ í…œí”Œë¦¿\n",
    "\n",
    "- ì‹œìŠ¤í…œ/ì‚¬ìš©ì/ì–´ì‹œìŠ¤í„´íŠ¸ ë“± **ë‹¤ì–‘í•œ ì—­í• **ì˜ ë©”ì‹œì§€ë¥¼ êµ¬ì¡°í™”\n",
    "\n",
    "- ëŒ€í™”ì˜ **ë§¥ë½ê³¼ íë¦„**ì„ ìœ ì§€í•˜ë©´ì„œ ì¼ê´€ëœ ìƒí˜¸ì‘ìš© ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ë©”ì‹œì§€ í…œí”Œë¦¿ ì‚¬ìš©`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ë³µì¡í•œ í…œí”Œë¦¿ êµ¬ì„±\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# ê°œë³„ ë©”ì‹œì§€ í…œí”Œë¦¿ ìƒì„±\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"ë‹¹ì‹ ì€ {role} ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {style} ìŠ¤íƒ€ì¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "human_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "\n",
    "# from_messages ë©”ì†Œë“œ ì‚¬ìš© (ì—¬ëŸ¬ ê°œì˜ ë©”ì‹œì§€ë“¤ì„ ì›ì†Œë¡œ ê°–ëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ êµ¬ì„±)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    human_message\n",
    "])\n",
    "\n",
    "# í…œí”Œë¦¿ ì‚¬ìš©\n",
    "formatted_prompt = chat_prompt.format(\n",
    "    role=\"ì¸ê³µì§€ëŠ¥\",\n",
    "    style=\"ì¹œì ˆí•œ\",\n",
    "    question=\"ì¸ê³µì§€ëŠ¥ì˜ ì •ì˜ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ë¬¸ìì—´ í…œí”Œë¦¿ ì‚¬ìš©`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í¬í•¨í•œ í…œí”Œë¦¿ ì •ì˜\n",
    "template = \"\"\"\n",
    "ë‹¹ì‹ ì€ {role} ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {style} ìŠ¤íƒ€ì¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# from_template ë©”ì†Œë“œ ì‚¬ìš© (ë‹¨ì¼ í…œí”Œë¦¿ ë¬¸ìì—´ ì§ì ‘ ì‚¬ìš©)\n",
    "chat_prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# í…œí”Œë¦¿ ì‚¬ìš©\n",
    "formatted_prompt = chat_prompt.format(\n",
    "    role=\"ì¸ê³µì§€ëŠ¥\",\n",
    "    style=\"ì¹œì ˆí•œ\",\n",
    "    question=\"ì¸ê³µì§€ëŠ¥ì˜ ì •ì˜ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplateì„ ì§ì ‘ ìƒì„± - ì´ë•ŒëŠ” HumanMessageë¡œ ì²˜ë¦¬ë¨ (SystemMessageëŠ” ë³„ë„ë¡œ ì¶”ê°€í•´ì•¼ í•¨)\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)  OutputParser í™œìš©\n",
    "\n",
    "- **OutputParser**ëŠ” LLMì˜ ì¶œë ¥ì„ ë‹¤ì–‘í•œ ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬\n",
    "\n",
    "- **ë¬¸ìì—´**, **JSON**, **XML** ë“± ì—¬ëŸ¬ í˜•ì‹ì˜ íŒŒì‹±ì„ ì§€ì›\n",
    "\n",
    "- íŒŒì‹±ëœ ì¶œë ¥ì€ **ë‹¤ë¥¸ ì‹œìŠ¤í…œ**ì´ë‚˜ **í”„ë¡œì„¸ìŠ¤**ì™€ ì—°ë™í•˜ëŠ”ë° ìœ ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) JSONOutputParser`\n",
    "- LLMì˜ ì¶œë ¥ì„ **êµ¬ì¡°í™”ëœ JSON**ìœ¼ë¡œ ë³€í™˜\n",
    "- íŒŒì„œëŠ” ì¶œë ¥ì˜ **ë°ì´í„° ìœ íš¨ì„±**ì„ ê²€ì¦í•˜ê³  ì¼ê´€ëœ í˜•ì‹ì„ ë³´ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# ê´€ê´‘ì§€ ì •ë³´ë¥¼ ìœ„í•œ Pydantic ëª¨ë¸ ì •ì˜ (ì´ë¦„, ìœ„ì¹˜, ì¹´í…Œê³ ë¦¬, ì£¼ìš” ê´€ëŒ í¬ì¸íŠ¸)\n",
    "class TouristSpot(BaseModel):\n",
    "    name: str = Field(description=\"ê´€ê´‘ëª…ì†Œ ì´ë¦„\")\n",
    "    location: str = Field(description=\"ìœ„ì¹˜ (êµ¬/ë™ ì •ë³´)\")\n",
    "    category: str = Field(description=\"ì¹´í…Œê³ ë¦¬ (ê¶ê¶/ë°•ë¬¼ê´€/ì‡¼í•‘ ë“±)\")\n",
    "    highlights: List[str] = Field(description=\"ì£¼ìš” ê´€ëŒ í¬ì¸íŠ¸\")\n",
    "\n",
    "# JsonOutputParser íŒŒì„œ ì„¤ì • (Pydantic ëª¨ë¸ ì§€ì •)\n",
    "parser = JsonOutputParser(pydantic_object=TouristSpot)\n",
    "\n",
    "# parserì˜ get_format_instructions ë©”ì†Œë“œ ì‚¬ìš© (í¬ë§· ì§€ì‹œì‚¬í•­ ì¶œë ¥)\n",
    "pprint(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (parserì˜ get_format_instructions ë©”ì†Œë“œ ì‚¬ìš©)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"ì„œìš¸ì˜ ë‹¤ìŒ ê´€ê´‘ëª…ì†Œì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "{format_instructions}\n",
    "\n",
    "ê´€ê´‘ì§€: {spot_name}\n",
    "\"\"\",\n",
    "    input_variables=[\"spot_name\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¶œë ¥ (í¬ë§· ì§€ì‹œì‚¬í•­ í¬í•¨)\n",
    "pprint(prompt.format(spot_name=\"ê²½ë³µê¶\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ êµ¬ì„±\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# ì‹¤í–‰ ì˜ˆì‹œ\n",
    "result = chain.invoke({\n",
    "    \"spot_name\": \"ê²½ë³µê¶\"\n",
    "})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) XMLOutputParser`\n",
    "- LLMì˜ ì¶œë ¥ì„ **êµ¬ì¡°í™”ëœ XML** í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "- XML êµ¬ì¡°ëŠ” **ê³„ì¸µì  ë°ì´í„°**ë¥¼ í‘œí˜„í•˜ëŠ”ë° íš¨ê³¼ì \n",
    "- íŒ¨í‚¤ì§€ ì„¤ì¹˜: defusedxml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "\n",
    "# XML íŒŒì„œ ì„¤ì • - ì›í•˜ëŠ” íƒœê·¸ êµ¬ì¡° ì •ì˜\n",
    "parser = XMLOutputParser(tags=[\"tourist_spot\", \"name\", \"location\", \"category\", \"highlights\", \"point\"])\n",
    "\n",
    "# parserì˜ get_format_instructions ë©”ì†Œë“œ ì‚¬ìš© (í¬ë§· ì§€ì‹œì‚¬í•­ ì¶œë ¥)\n",
    "pprint(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"ì„œìš¸ì˜ ë‹¤ìŒ ê´€ê´‘ëª…ì†Œì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ XML í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "{format_instructions}\n",
    "\n",
    "ê´€ê´‘ì§€: {spot_name}\"\"\",\n",
    "    input_variables=[\"spot_name\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}  \n",
    ")\n",
    "\n",
    "# ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¶œë ¥ (í¬ë§· ì§€ì‹œì‚¬í•­ í¬í•¨)\n",
    "pprint(prompt.format(spot_name=\"ê²½ë³µê¶\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ êµ¬ì„±\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# ì‹¤í–‰ ì˜ˆì‹œ\n",
    "result = chain.invoke({\n",
    "    \"spot_name\": \"ê²½ë³µê¶\"\n",
    "})\n",
    "\n",
    "# ê²°ê³¼ëŠ” Python ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ íŒŒì‹±ë˜ì–´ ë°˜í™˜ë¨ \n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML í˜•ì‹ì˜ ê²°ê³¼ë¥¼ ë‹¤ì‹œ íŒŒì‹±í•˜ì—¬ ì¶œë ¥ (ê°€ì¥ ìƒìœ„ íƒœê·¸ë¥¼ ì œì™¸í•œ ë‚´ìš©ë§Œ ì¶œë ¥)\n",
    "result['tourist_spot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) ì‚¬ìš©ì ì •ì˜(Custom) OutputParser`\n",
    "- **ì‚¬ìš©ì ì •ì˜ íŒŒì„œ**ëŠ” **RunnableLambda**ë‚˜ **RunnableGenerator**ë¥¼ í™œìš©í•˜ì—¬ êµ¬í˜„\n",
    "- íŠ¹ì • ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” **ë§ì¶¤í˜• ì¶œë ¥ í˜•ì‹**ì„ ì •ì˜í•  ìˆ˜ ìˆìŒ \n",
    "- ë³µì¡í•œ **ë°ì´í„° ë³€í™˜**ê³¼ **í›„ì²˜ë¦¬ ë¡œì§**ì„ ìœ ì—°í•˜ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŒ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing import Dict\n",
    "\n",
    "# ì‚¬ìš©ì ì •ì˜ íŒŒì„œ\n",
    "def parse_tourist_spot(ai_message: AIMessage) -> Dict:\n",
    "    \"\"\"ê´€ê´‘ì§€ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ íŒŒì‹±\"\"\"\n",
    "    lines = ai_message.content.split('\\n')\n",
    "    return {\n",
    "        \"name\": lines[0] if lines else \"\",\n",
    "        \"description\": ' '.join(lines[1:]) if len(lines) > 1 else \"\"\n",
    "    }\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "prompt = PromptTemplate(\n",
    "    template=\"ë‹¤ìŒ ê´€ê´‘ì§€ì— ëŒ€í•´ ì²« ì¤„ì— ì´ë¦„, ë‹¤ìŒ ì¤„ë¶€í„° ì„¤ëª…ì„ 100ì ë‚´ì™¸ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:\\n{spot_name}\",\n",
    "    input_variables=[\"spot_name\"]\n",
    ")\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„± (invoke ë°©ì‹)\n",
    "invoke_chain = prompt | llm | parse_tourist_spot\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "result = invoke_chain.invoke({\n",
    "    \"spot_name\": \"ê²½ë³µê¶\"\n",
    "})\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ìœ„ êµ¬í˜„ì„ stream ë°©ì‹ìœ¼ë¡œ ë³€ê²½\n",
    "\n",
    "from langchain_core.runnables import RunnableGenerator\n",
    "from langchain_core.messages import AIMessageChunk\n",
    "from typing import Iterable\n",
    "import time\n",
    "\n",
    "# ì‚¬ìš©ì ì •ì˜ íŒŒì„œ (stream ë°©ì‹) \n",
    "def streaming_parse_tourist_spot(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:\n",
    "    \"\"\"ì‹¤ì‹œê°„ìœ¼ë¡œ ê´€ê´‘ì§€ ì •ë³´ íŒŒì‹±\"\"\"\n",
    "    for chunk in chunks:\n",
    "        yield f\"ğŸ› {chunk.content}\"   # ğŸ› ì´ëª¨ì§€ ì¶”ê°€ \n",
    "\n",
    "# stream ë°©ì‹ ì²´ì¸ êµ¬ì„± \n",
    "streaming_chain = prompt | llm | RunnableGenerator(streaming_parse_tourist_spot)\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ \n",
    "for chunk in streaming_chain.stream({\"spot_name\": \"ê´‘í™”ë¬¸\"}):\n",
    "    print(chunk)\n",
    "    time.sleep(0.1)   # ì‹œê°„ ì§€ì—° ì¶”ê°€ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ì°¸ê³ ] ì´ëª¨ì§€(emoji) ì…ë ¥ ë°©ë²•**\n",
    "\n",
    "1. Windowsì—ì„œ:\n",
    "    - `Windows í‚¤ + .` (ìœˆë„ìš° í‚¤ì™€ ë§ˆì¹¨í‘œë¥¼ ë™ì‹œì— ëˆ„ë¦„)\n",
    "    - ë˜ëŠ” `Windows í‚¤ + ;` (ìœˆë„ìš° í‚¤ì™€ ì„¸ë¯¸ì½œë¡ ì„ ë™ì‹œì— ëˆ„ë¦„)\n",
    "\n",
    "2. Macì—ì„œ:\n",
    "    - `fn(ì§€êµ¬ë³¸) í‚¤ + E` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) êµ¬ì¡°í™”ëœ ì¶œë ¥ í”„ë¡¬í”„íŠ¸ (Structured Output Prompts)`\n",
    "   - ì¼ê´€ëœ í˜•ì‹ì˜ ì‘ë‹µ\n",
    "   - ë°ì´í„° ì²˜ë¦¬ ìš©ì´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typing ì‚¬ìš©\n",
    "from typing import TypedDict, Annotated \n",
    "\n",
    "class AnalysisResult(TypedDict):\n",
    "    \"\"\"ë¶„ì„ ê²°ê³¼ ìŠ¤í‚¤ë§ˆ\"\"\"\n",
    "    summary: Annotated[str, ..., \"í•µì‹¬ ìš”ì•½\"]\n",
    "    keywords: Annotated[list[str], ..., \"ì£¼ìš” í‚¤ì›Œë“œ\"]\n",
    "    sentiment: Annotated[str, ..., \"ê¸ì •/ë¶€ì •/ì¤‘ë¦½\"]\n",
    "\n",
    "structured_llm = llm.with_structured_output(AnalysisResult)\n",
    "\n",
    "# LCEL\n",
    "chain = step_prompt | structured_llm\n",
    "\n",
    "# ì§ˆë¬¸\n",
    "text = \"\"\"\n",
    "ì–‘ì ì»´í“¨íŒ…ì€ ì–‘ìì—­í•™ì˜ ì›ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ìƒˆë¡œìš´ í˜•íƒœì˜ ê³„ì‚° ë°©ì‹ì´ë‹¤.\n",
    "ê¸°ì¡´ì˜ ê³ ì „ì  ì»´í“¨í„°ëŠ” 0ê³¼ 1ë¡œ ì´ë£¨ì–´ì§„ ì´ì§„ë²•(bit)ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì§€ë§Œ,\n",
    "ì–‘ì ì»´í“¨í„°ëŠ” ì–‘ì ë¹„íŠ¸(íë¹„íŠ¸, qubit)ë¥¼ ì‚¬ìš©í•˜ì—¬ í›¨ì”¬ ë” ë³µì¡í•˜ê³  ë¹ ë¥¸ ê³„ì‚°ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "íë¹„íŠ¸ëŠ” ë™ì‹œì— 0ê³¼ 1ì˜ ìƒíƒœë¥¼ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì–‘ì ì¤‘ì²©(superposition) ìƒíƒœë¥¼ í™œìš©í•˜ë©°,\n",
    "ì´ë¥¼ í†µí•´ ë³‘ë ¬ ê³„ì‚°ê³¼ ê°™ì€ ê³ ê¸‰ ê¸°ëŠ¥ì´ ê°€ëŠ¥í•˜ë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "output = chain.invoke({\"text\": text})\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pydantic ì‚¬ìš©\n",
    "from typing import List, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class AnalysisResult(BaseModel):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë‹´ëŠ” ìŠ¤í‚¤ë§ˆ\"\"\"\n",
    "    \n",
    "    summary: str = Field(\n",
    "        ...,  # ... ì€ required í•„ë“œë¥¼ ì˜ë¯¸ (í•„ìˆ˜ ì…ë ¥, None í—ˆìš© ì•ˆí•¨)\n",
    "        description=\"í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ë‚´ìš© ìš”ì•½\"\n",
    "    )\n",
    "    \n",
    "    keywords: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš” í‚¤ì›Œë“œ\"\n",
    "    )\n",
    "    \n",
    "    sentiment: Literal[\"ê¸ì •\", \"ë¶€ì •\", \"ì¤‘ë¦½\"] = Field(\n",
    "        ...,\n",
    "        description=\"í…ìŠ¤íŠ¸ì˜ ì „ë°˜ì ì¸ ê°ì • ë¶„ì„ ê²°ê³¼\"\n",
    "    )\n",
    "\n",
    "structured_llm = llm.with_structured_output(AnalysisResult)\n",
    "\n",
    "# LCEL\n",
    "chain = step_prompt | structured_llm\n",
    "\n",
    "# ì§ˆë¬¸\n",
    "output = chain.invoke({\"text\": text})\n",
    "print(output)\n",
    "print(type(output))\n",
    "print(\"-\"*100)\n",
    "print(output.summary)\n",
    "print(output.keywords)\n",
    "print(output.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# [ì‹¤ìŠµ í”„ë¡œì íŠ¸]\n",
    "\n",
    "### ë§ì¶¤í˜• í•™ìŠµ ë„ìš°ë¯¸ ì±—ë´‡ ë§Œë“¤ê¸°\n",
    "\n",
    "- íŠ¹ì • ì£¼ì œì— ëŒ€í•œ í•™ìŠµì„ ë•ëŠ” ì±—ë´‡ì„ ë§Œë“¤ì–´ë´…ë‹ˆë‹¤. ì•ì„œ ë°°ìš´ í”„ë¡¬í”„íŠ¸ ìœ í˜•ë“¤ì„ ì¡°í•©í•˜ì—¬ í™œìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "- (1) í€´ì¦ˆ ë¬¸ì œ ì˜ˆì‹œë¥¼ ë³´ê³ , (2) ê°œë… ì„¤ëª… ì²´ì¸ì„ ì™„ì„±í•©ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) í€´ì¦ˆ ë¬¸ì œ ì¶œì œ (ì˜ˆì‹œ)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"í€´ì¦ˆ ë¬¸ì œ: ë”¥ëŸ¬ë‹ì—ì„œ 'ê³¼ì í•©(overfitting)' ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ëŒ€í‘œì ì¸ ë°©ë²• ì¤‘ í•˜ë‚˜ê°€ ì•„ë‹Œ ê²ƒì€ ë¬´ì—‡ì¸ê°€?\"\n",
      "(\"ë³´ê¸°: ['ë“œë¡­ì•„ì›ƒ(Dropout) ê¸°ë²• ì ìš©', 'ë°ì´í„° ì¦ê°•(Data Augmentation)', 'ëª¨ë¸ì˜ ë³µì¡ë„ ì¦ê°€', 'ì¡°ê¸° \"\n",
      " \"ì¢…ë£Œ(Early Stopping)']\")\n",
      "'ì •ë‹µ: 3'\n",
      "('ì •ë‹µ ì„¤ëª…: ê³¼ì í•©ì€ ëª¨ë¸ì´ í•™ìŠµ ë°ì´í„°ì— ë„ˆë¬´ ì¹˜ì¤‘í•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” í˜„ìƒì…ë‹ˆë‹¤. ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ë“œë¡­ì•„ì›ƒ, ë°ì´í„° ì¦ê°•, '\n",
      " 'ì¡°ê¸° ì¢…ë£Œ ë“± ë‹¤ì–‘í•œ ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ëª¨ë¸ì˜ ë³µì¡ë„ë¥¼ ì¦ê°€ì‹œí‚¤ë©´ ì˜¤íˆë ¤ ê³¼ì í•©ì´ ì‹¬í•´ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´ëŠ” ê³¼ì í•© í•´ê²° ë°©ë²•ì´ '\n",
      " 'ì•„ë‹™ë‹ˆë‹¤.')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyewonmac/study/modu_llm_5/modu_llm5_project/001_chatbot/.venv/lib/python3.12/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=QuizQuestion(question=\"...ë²•ì´ ì•„ë‹™ë‹ˆë‹¤.'), input_type=QuizQuestion])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# í€´ì¦ˆ ë¬¸ì œ ìŠ¤í‚¤ë§ˆ\n",
    "class QuizQuestion(BaseModel):\n",
    "    \"\"\"í€´ì¦ˆ ë¬¸ì œ ìŠ¤í‚¤ë§ˆ\"\"\"\n",
    "    question: str = Field(..., description=\"í€´ì¦ˆ ë¬¸ì œ\")\n",
    "    options: List[str] = Field(..., description=\"ë³´ê¸° (4ê°œ)\")\n",
    "    correct_answer: int = Field(..., description=\"ì •ë‹µ ë²ˆí˜¸ (1-4)\")\n",
    "    explanation: str = Field(..., description=\"ì •ë‹µ ì„¤ëª…\")\n",
    "\n",
    "\n",
    "# í€´ì¦ˆ ìƒì„±ì„ ìœ„í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ í”„ë¡¬í”„íŠ¸\n",
    "# ì£¼ì œ, ë‚œì´ë„(ìƒì¤‘í•˜) ì•„ë˜ì— ì°¸ê³ ì‚¬í•­ì„ ë„£ì–´ í™˜ê°ì„ ì¤„ì¼ ìˆ˜ ìˆë„ë¡ í•´ë³¸ë‹¤.\n",
    "quiz_prompt = PromptTemplate(\n",
    "    template=\"\"\"ë‹¤ìŒ ì£¼ì œì— ëŒ€í•œ í€´ì¦ˆ ë¬¸ì œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”:\n",
    "    \n",
    "ì£¼ì œ: {topic}\n",
    "ë‚œì´ë„(ìƒ/ì¤‘/í•˜): {difficulty}\n",
    "\n",
    "ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” í€´ì¦ˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:\n",
    "1. ë¬¸ì œëŠ” ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ\n",
    "2. 4ê°œì˜ ë³´ê¸° ì œê³µ\n",
    "3. ì •ë‹µê³¼ ì˜¤ë‹µì€ ë¹„ìŠ·í•œ ìˆ˜ì¤€ìœ¼ë¡œ\n",
    "4. ìƒì„¸í•œ ì •ë‹µ ì„¤ëª… í¬í•¨\"\"\",\n",
    "    input_variables=[\"topic\", \"difficulty\"]\n",
    ")\n",
    "\n",
    "# LLM ì •ì˜\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.3)\n",
    "\n",
    "# êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì„œ ì„¤ì •\n",
    "structured_llm = llm.with_structured_output(QuizQuestion)\n",
    "\n",
    "# LCEL ì²´ì¸ êµ¬ì„±\n",
    "chain = quiz_prompt | structured_llm\n",
    "\n",
    "# ì§ˆë¬¸ ì‹¤í–‰\n",
    "output = chain.invoke({\"topic\": \"ì¸ê³µì§€ëŠ¥\", \"difficulty\": \"ìƒ\"})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "pprint(f\"í€´ì¦ˆ ë¬¸ì œ: {output.question}\")\n",
    "pprint(f\"ë³´ê¸°: {output.options}\")\n",
    "pprint(f\"ì •ë‹µ: {output.correct_answer}\")\n",
    "pprint(f\"ì •ë‹µ ì„¤ëª…: {output.explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) ê°œë… ì„¤ëª… ì²´ì¸ (ë¬¸ì œ)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°œë… ì„¤ëª…ì„ ìœ„í•œ ìŠ¤í‚¤ë§ˆ\n",
    "class ConceptExplanation(BaseModel):\n",
    "    \"\"\"ê°œë… ì„¤ëª… ìŠ¤í‚¤ë§ˆ\"\"\"\n",
    "    topic: None\n",
    "    explanation: None\n",
    "    examples: None\n",
    "    related_concepts: None\n",
    "\n",
    "# ê°œë… ì„¤ëª…ì„ ìœ„í•œ ì§€ì‹œí˜• í”„ë¡¬í”„íŠ¸\n",
    "concept_prompt = PromptTemplate(\n",
    "    template=None,\n",
    "    input_variables=[\"topic\", \"difficulty\"]\n",
    ")\n",
    "\n",
    "# êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì„œ ì„¤ì •\n",
    "structured_llm = None\n",
    "\n",
    "# LCEL ì²´ì¸ êµ¬ì„±\n",
    "chain = None\n",
    "\n",
    "# ì§ˆë¬¸ ì‹¤í–‰\n",
    "# output = chain.invoke({\"topic\": \"ì¸ê³µì§€ëŠ¥\", \"difficulty\": \"í•˜\"})\n",
    "\n",
    "# ê°•ì‚¬ë‹˜ ìš”ì²­ì‚¬í•­ : ì§ˆë¬¸ ì‹¤í–‰ - level ë„£ì–´ì„œ, templateì´ Noneì´ ì•„ë‹Œ levelë³„ë¡œ ì¶œë ¥ë  ìˆ˜ ìˆë„ë¡ ì²˜ë¦¬\n",
    "# output = chain.invoke({\"topic\": \"ì¸ê³µì§€ëŠ¥\", \"difficulty\": \"í•˜\", \"level\": \"\"})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "pprint(f\"ì£¼ì œ: {output.topic}\")\n",
    "pprint(f\"ì„¤ëª…: {output.explanation}\")\n",
    "pprint(f\"ì˜ˆì‹œ: {output.examples}\")\n",
    "pprint(f\"ê´€ë ¨ ê°œë…: {output.related_concepts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ì‹¤ìŠµí”„ë¡œì íŠ¸ ê°•ì‚¬ë‹˜ ì½”ë“œ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°œë… ì„¤ëª…ì„ ìœ„í•œ ìŠ¤í‚¤ë§ˆ\n",
    "class ConceptExplanation(BaseModel):\n",
    "    \"\"\"ê°œë… ì„¤ëª… ìŠ¤í‚¤ë§ˆ\"\"\"\n",
    "    topic: str = Field(..., description=\"ì„¤ëª…í•  ì£¼ì œ\")\n",
    "    explanation: str = Field(..., description=\"ì£¼ì œì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…\")\n",
    "    examples: list[str] = Field(..., description=\"ì´í•´ë¥¼ ë•ëŠ” êµ¬ì²´ì ì¸ ì˜ˆì‹œ 3ê°œ\")\n",
    "    related_concepts: list[str] = Field(..., description=\"ê´€ë ¨ëœ ê°œë… 3ê°œ\")\n",
    "\n",
    "# ê°œë… ì„¤ëª…ì„ ìœ„í•œ ì§€ì‹œí˜• í”„ë¡¬í”„íŠ¸\n",
    "concept_prompt = PromptTemplate(\n",
    "    template=\"\"\"ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ì£¼ì œ: {topic}\n",
    "ë‚œì´ë„(ìƒ/ì¤‘/í•˜): {difficulty}\n",
    "\n",
    "ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì„¤ëª…ì„ ìƒì„±í•´ì£¼ì„¸ìš”:\n",
    "1. ë‚œì´ë„ì— ë§ëŠ” ì‰¬ìš´ ìš©ì–´ ì‚¬ìš©\n",
    "2. êµ¬ì²´ì ì¸ ì˜ˆì‹œ 3ê°œ í¬í•¨\n",
    "3. ê´€ë ¨ ê°œë… 3ê°œ ì œì‹œ\n",
    "4. ì²´ê³„ì ì´ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…\"\"\",\n",
    "    input_variables=[\"topic\", \"difficulty\"]\n",
    ")\n",
    "\n",
    "# êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì„œ ì„¤ì •\n",
    "structured_llm = llm.with_structured_output(ConceptExplanation)\n",
    "\n",
    "# LCEL ì²´ì¸ êµ¬ì„±\n",
    "chain = concept_prompt | structured_llm\n",
    "\n",
    "# ì§ˆë¬¸ ì‹¤í–‰\n",
    "output = chain.invoke({\"topic\": \"ì¸ê³µì§€ëŠ¥\", \"difficulty\": \"í•˜\"})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "pprint(f\"ì£¼ì œ: {output.topic}\")\n",
    "pprint(f\"ì„¤ëª…: {output.explanation}\")\n",
    "pprint(f\"ì˜ˆì‹œ: {output.examples}\")\n",
    "pprint(f\"ê´€ë ¨ ê°œë…: {output.related_concepts}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "001-chatbot (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
