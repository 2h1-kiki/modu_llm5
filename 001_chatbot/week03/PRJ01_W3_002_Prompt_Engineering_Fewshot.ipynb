{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  프롬프트 엔지니어링 - Zero-shot, Few-shot\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "1. Zero-shot, One-shot, Few-shot 프롬프팅의 개념과 차이점을 이해한다\n",
    "2. PromptTemplate과 partial 메소드를 사용하여 프롬프트를 구성할 수 있다\n",
    "3. FewShotChatMessagePromptTemplate을 활용하여 고정 예시 기반 프롬프팅을 구현한다\n",
    "4. SemanticSimilarityExampleSelector를 사용하여 동적 Few-shot 프롬프팅을 구현한다\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) LLM 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyewonmac/study/modu_llm_5/modu_llm5_project/001_chatbot/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4.1-nano',\n",
    "    temperature=0.3,\n",
    "    top_p=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama 설치 및 모델 준비 안내 (Dynamic Few-Shot 실습용)\n",
    "print(\"\"\"\n",
    "[Ollama 설정 필수]\n",
    "Dynamic Few-Shot 프롬프팅 실습을 위해 Ollama가 필요합니다.\n",
    "\n",
    "1. Ollama 설치: https://ollama.com/\n",
    "2. 터미널에서 임베딩 모델 다운로드:\n",
    "   ollama pull bge-m3\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot 프롬프팅\n",
    "\n",
    "- **Zero-shot 프롬프팅**은 예시 없이 AI가 즉시 작업을 수행하는 기법입니다\n",
    "\n",
    "- 명확한 **지시사항**만으로 원하는 결과를 얻을 수 있어 **사용이 간단**합니다\n",
    "\n",
    "- 단순하고 직관적인 작업에 적합한 프롬프팅 방식이지만, 작업의 **복잡도에 따라 선택적 사용**이 필요합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 반도체 시장에서 삼성전자의 주요 경쟁업체들은 다음과 같습니다:\n",
      "\n",
      "1. NVIDIA (엔비디아)\n",
      "   - 인공지능 및 딥러닝 분야에서 세계적인 선두 기업으로, GPU 기반의 인공지능 가속기와 데이터 센터용 솔루션을 제공하고 있습니다.\n",
      "2. AMD (Advanced Micro Devices)\n",
      "   - GPU와 CPU를 모두 제조하며, 인공지능 및 고성능 컴퓨팅 시장에서 경쟁력을 갖추고 있습니다.\n",
      "3. 인텔 (Intel)\n",
      "   - 인공지능용 하드웨어와 칩셋 개발에 적극 투자하고 있으며, 특히 인공지능 가속기와 데이터 센터용 솔루션을 제공하고 있습니다.\n",
      "4. 구글 (Google)\n",
      "   - 자체 인공지능 칩인 TPU(Tensor Processing Unit)를 개발하여 클라우드 서비스와 인공지능 애플리케이션에 활용하고 있습니다.\n",
      "5. 마이크로소프트 (Microsoft)\n",
      "   - 인공지능 하드웨어 개발 및 클라우드 기반 인공지능 서비스 제공에 참여하고 있으며, 자체 칩 개발도 검토 중입니다.\n",
      "6. 화웨이 (Huawei)\n",
      "   - 인공지능 칩인 Ascend 시리즈를 개발하여, 통신 및 클라우드 인공지능 시장에 공급하고 있습니다.\n",
      "7. 퀄컴 (Qualcomm)\n",
      "   - 모바일 및 엣지 컴퓨팅용 인공지능 칩셋을 개발하여, 스마트폰과 IoT 기기 등에 공급하고 있습니다.\n",
      "\n",
      "이 외에도 여러 스타트업과 신생 기업들이 인공지능 반도체 시장에 진입하고 있으며, 경쟁은 계속해서 치열하게 전개되고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Zero-shot 프롬프트 템플릿 생성\n",
    "zero_shot_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"다음 시장에서 삼성전자의 경쟁업체를 설명해주세요: {topic}\"\n",
    ")\n",
    "\n",
    "# 체인 생성\n",
    "chain = zero_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Zero-shot 실행\n",
    "topic = \"인공지능 반도체\"\n",
    "zero_shot_result = chain.invoke(input={\"topic\": topic}) \n",
    "\n",
    "print(zero_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**추가필기**\n",
    "- 환각을 낮추기 위해 너무 광범위한 질문보다 한정을 넣어준다.\n",
    "\t- context를 넣어 머신이 공부를 하여 답변을 하도록 유도\n",
    "\t- 요청을 하되, 모델이 내부 지식이 아닌, 제시한 컨텍스트를 토대로 대답을 할 수 있도록 하여 사용자가 제한한 범위 안에서 답변이 나오도록 하는 것이 우리가 해애할 일이라고 생각한다.\n",
    "\t- 따라서 답변을 유도할 때, 사용자는 제한을 두어 환각을 줄이도록 해애한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자의 인공지능 반도체 시장 경쟁업체로 가장 두드러진 기업은 엔비디아입니다. 뉴스에 따르면, 삼성전자는 내년 초 자체 개발한 AI 가속기를 출시하여 AI 반도체 시장에서 엔비디아의 독점적 지위를 도전하려 하고 있습니다. 이는 삼성전자가 세계 최고의 반도체 제조업체로서의 위치를 다시 확립하려는 전략의 일환으로 볼 수 있으며, 엔비디아는 이미 AI 가속기 분야에서 시장을 선도하는 대표적인 경쟁업체입니다. 따라서, 삼성전자의 인공지능 반도체 시장 경쟁업체는 엔비디아라고 할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot 프롬프팅 - 컨텍스트(Context) 제공 \n",
    "zero_shot_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"topic\"],\n",
    "    template=\"\"\"{topic} 시장에서 삼성전자의 경쟁업체를 설명해주세요. \n",
    "    반드시 다음 제시된 뉴스에 근거해서 답변하세요:\n",
    "\n",
    "    [뉴스]\n",
    "    {context}\n",
    "    \n",
    "    [답변]\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# 체인 생성\n",
    "chain = zero_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Zero-shot 실행\n",
    "context = \"\"\"삼성전자가 내년 초에 자체적으로 개발한 인공지능(AI) 가속기를 처음으로 출시할 예정이다. \n",
    "이는 AI 반도체 시장에서 지배적인 위치를 차지하고 있는 엔비디아의 독점을 도전하고, \n",
    "세계 최고의 반도체 제조업체로서의 지위를 다시 확립하려는 삼성전자의 노력으로 해석된다.\n",
    "\"\"\"\n",
    "\n",
    "topic = \"인공지능 반도체\"\n",
    "zero_shot_result = chain.invoke(input={\"context\": context, \"topic\": topic})\n",
    "\n",
    "print(zero_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-shot 프롬프팅\n",
    "\n",
    "- **One-shot 프롬프팅**은 하나의 예시를 통해 AI가 작업 패턴을 학습하는 기법입니다\n",
    "\n",
    "- **Zero-shot** 방식보다 더 나은 성능을 제공하며, **형식화된 작업**에 특히 효과적입니다\n",
    "\n",
    "- 단일 예시로 **품질 향상**이 가능하나, 해당 예시에 **과의존**할 수 있는 한계가 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-shot 프롬프트 템플릿 생성\n",
    "# 1. Zero-shot 프롬프트 템플릿에 예시(example)를 포함하도록 수정\n",
    "# 2. input_variables에 example_topic과 example_response 추가\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "one_shot_prompt = PromptTemplate(\n",
    "    input_variables=[\"example_topic\", \"example_response\", \"topic\"],\n",
    "    template=\"\"\"다음은 특정 시장에서 삼성전자의 경쟁업체를 설명하는 예시이다:\n",
    "\n",
    "시장: {example_topic}\n",
    "경쟁업체: {example_response}\n",
    "\n",
    "이제 다음 시장에서 삼성전자의 경쟁업체를 설명해주세요:\n",
    "시장: {topic}\"\"\"\n",
    ")\n",
    "\n",
    "# Example 데이터 설정\n",
    "example_topic = \"스마트폰\"\n",
    "example_response = \"\"\"애플: 프리미엄 시장에서 주요 경쟁사로, iPhone 시리즈로 경쟁\n",
    "샤오미: 중저가 시장에서 강세를 보이며 글로벌 시장 점유율 확대\n",
    "구글: Pixel 시리즈로 프리미엄 시장 진출, AI 기능 강조\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가필기\n",
    "\n",
    "1. 형식의 중복 피하기\n",
    "예시에서도 \n",
    "```\n",
    "example_response = \n",
    "\"\"\"애플: 프리미엄 시장에서 주요 경쟁사로, iPhone 시리즈로 경쟁\n",
    "샤오미: 중저가 시장에서 강세를 보이며 글로벌 시장 점유율 확대\n",
    "구글: Pixel 시리즈로 프리미엄 시장 진출, AI 기능 강조\"\"\"\n",
    "```\n",
    "\n",
    "- `애플:`, `샤오미:`, `구글:` 이처럼 콜론을 사용하였는데\n",
    "- template의 `시장:` 이렇게 같은 콜론을 사용하는 형태는 모델을 헷갈리게 할 수 있다.\n",
    "\n",
    "2. 원하는 의도가 있을 때\n",
    "- prompt에서 원하는 의도를 넣어주거나\n",
    "- 예시를 넣어주는 주는 것을 추천\n",
    "\t- 예시가 반드시 필요한 경우라면 예시를 5개 이상으로 해도 좋을 것 같다 \n",
    "\t\t- 단, 최신 모델인 경우 + 당연히 토큰이 늘어나지만, 비용이 더 추가되더라도 \n",
    "\n",
    "3. LLM은 2가지의 방식이 있을 수 있다.\n",
    "\t- 환각을 줄이는 RAG 방식\n",
    "\t\t- 출력 품질이 중요하고 검증하기 위한 작업이 필요한 경우\n",
    "\t\t- 토큰이 많이 사용되어 비용이 추가 되더라도 예시를 많이 추가하여 검증을 많이 하는 것이 중요하다고 판단 된다.\n",
    "\t- 환각을 키워 이용하는 경우\n",
    "\t\t- 감성이 필요한 경우\n",
    "\n",
    "\n",
    "- 차주 부터 RAG에 대해서더 자세하게 알게 될 것이다.\n",
    "\t- [modular rag 관련 자료](https://arxiv.org/pdf/2407.21059)\n",
    "\t- RAG는 계속 진화해 왔고, 관련하여 다음주 중에 배우게 될 것이다.\n",
    "\t- Native RAG > Advance RAG > Modular RAG 순서로 배울 예정\n",
    "\t- embedding은 불안전하다.\n",
    "\n",
    "- RAG에서 속도를 향상시키기 위해서는?\n",
    "\t- RangGraph 프레임워크를 사용하여 병렬 실행 하도록 처리\n",
    "\t- Multi Thread를 사용하거나\n",
    "\t- 검색시 병렬 처리를 한다.\n",
    "\t- 따라서 질문\n",
    "\t\t\t- Query rewrite와 Rerank의 경우, LLM으로 처리하면, 전체 RAG에서 처리 속도를 지연시키는 요소가 된다고 하는데, LLM을 사용하지 않고도 이 둘을 처리할 수 있는건가요?\n",
    "\t\t\t- LLM을 사용하지 않고 처리 하는건 불가능하다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) PromptTemplate 그대로 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_shot_result:\n",
      "시장: 인공지능 반도체  \n",
      "경쟁업체: 엔비디아: GPU 기반 AI 가속기 시장의 선두주자로, 딥러닝 및 데이터센터용 AI 칩셋에서 강력한 입지 확보  \n",
      "구글: TPU(Tensor Processing Unit) 개발을 통해 클라우드 AI 서비스와 데이터센터용 AI 가속기 시장에서 경쟁  \n",
      "인텔: CPU 및 AI 가속기 솔루션을 통합하여 기업용 인공지능 인프라 시장에서 경쟁력 강화\n"
     ]
    }
   ],
   "source": [
    "# one_shot_prompt 적용한 체인 생성\n",
    "chain = one_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "# One-shot 실행\n",
    "topic = \"인공지능 반도체\"\n",
    "one_shot_result = chain.invoke(\n",
    "    input={\n",
    "        \"example_topic\": example_topic,\n",
    "        \"example_response\": example_response,\n",
    "        \"topic\": topic\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"one_shot_result:\")\n",
    "print(one_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) partial 메소드 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 데이터를 반영한 부분 프롬프트 출력 \n",
    "partial_prompt = one_shot_prompt.partial(\n",
    "    example_topic=example_topic,\n",
    "    example_response=example_response,\n",
    ")\n",
    "\n",
    "print(f\"partial_prompt:\")\n",
    "print(partial_prompt)\n",
    "\n",
    "# 체인 생성\n",
    "chain = partial_prompt | llm | StrOutputParser()\n",
    "\n",
    "# One-shot 실행\n",
    "topic = \"인공지능 반도체\"\n",
    "one_shot_result = chain.invoke(input={\"topic\": topic})\n",
    "\n",
    "print(f\"one_shot_result:\")\n",
    "print(one_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot 프롬프팅\n",
    "\n",
    "- **Few-shot 프롬프팅**은 AI 모델에게 2-5개의 예시를 제공하여 학습시키는 방법입니다\n",
    "\n",
    "- 이 방식은 **Zero-shot**이나 **One-shot** 프롬프팅보다 더 우수한 성능을 보여주며, 복잡한 작업에서 특히 효과적입니다\n",
    "\n",
    "- Few-shot 프롬프팅은 높은 성능을 제공하지만, 긴 프롬프트로 인한 **비용 증가**를 고려해야 합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) PromptTemplate 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시장: 인공지능 반도체  \n",
      "경쟁업체:  \n",
      "- 엔비디아(미국): GPU 기반 AI 가속기 선도, 딥러닝 분야 강자  \n",
      "- AMD(미국): 고성능 GPU와 AI 가속 솔루션 제공, 엔비디아와 경쟁  \n",
      "- 인텔(미국): CPU와 AI 가속기 통합 솔루션 개발, 데이터 센터 및 엣지 AI 시장 공략  \n",
      "- 구글(미국): TPU(Tensor Processing Unit) 개발, 클라우드 AI 서비스 강화\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Few-shot 프롬프트 템플릿 생성 \n",
    "few_shot_prompt = PromptTemplate(\n",
    "   input_variables=[\"examples\", \"topic\"],\n",
    "   template=\"\"\"다음은 여러 시장에서 삼성전자의 경쟁업체를 설명하는 예시들이다:\n",
    "\n",
    "{examples}\n",
    "\n",
    "이제 다음 시장에서 삼성전자의 경쟁업체를 설명해주세요:\n",
    "시장: {topic}\"\"\"\n",
    ")\n",
    "\n",
    "# Example 데이터 준비\n",
    "examples = \"\"\"\n",
    "시장: 스마트폰\n",
    "경쟁업체: \n",
    "- 애플(미국): 프리미엄 시장 주도, iPhone으로 경쟁\n",
    "- 샤오미(중국): 중저가 시장 강세, 글로벌 확장중\n",
    "- 구글(미국): Pixel로 AI 기능 강조\n",
    "\n",
    "시장: TV\n",
    "경쟁업체:\n",
    "- LG전자(한국): OLED 기술 경쟁\n",
    "- Sony(일본): 프리미엄 시장 경쟁\n",
    "- TCL(중국): 중저가 시장 공략\n",
    "\"\"\"\n",
    "\n",
    "# 체인 생성 및 실행\n",
    "chain = few_shot_prompt | llm | StrOutputParser()\n",
    "result = chain.invoke({\n",
    "   \"examples\": examples,\n",
    "   \"topic\": \"인공지능 반도체\"\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) partial 메소드 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_prompt:\n",
      "input_variables=['topic'] input_types={} partial_variables={'examples': '\\n시장: 스마트폰\\n경쟁업체: \\n- 애플(미국): 프리미엄 시장 주도, iPhone으로 경쟁\\n- 샤오미(중국): 중저가 시장 강세, 글로벌 확장중\\n- 구글(미국): Pixel로 AI 기능 강조\\n\\n시장: TV\\n경쟁업체:\\n- LG전자(한국): OLED 기술 경쟁\\n- Sony(일본): 프리미엄 시장 경쟁\\n- TCL(중국): 중저가 시장 공략\\n'} template='다음은 여러 시장에서 삼성전자의 경쟁업체를 설명하는 예시들이다:\\n\\n{examples}\\n\\n이제 다음 시장에서 삼성전자의 경쟁업체를 설명해주세요:\\n시장: {topic}'\n"
     ]
    }
   ],
   "source": [
    "# partial 메서드를 사용하여 Few-shot 프롬프트 템플릿 생성\n",
    "partial_prompt = few_shot_prompt.partial(\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "print(f\"partial_prompt:\")\n",
    "print(partial_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 생성\n",
    "chain = partial_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Few-shot 실행\n",
    "topic = \"인공지능 반도체\"\n",
    "few_shot_result = chain.invoke(input={\"topic\": topic})\n",
    "\n",
    "print(f\"few_shot_result:\")\n",
    "print(few_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) FewShotChatMessagePromptTemplate 사용`\n",
    "\n",
    "* FewShotChatMessagePromptTemplate는 LangChain에서 제공하는 템플릿으로, **미리 정의된 고정된 예제들(Fixed Examples)** 을 프롬프트에 포함시켜 모델이 일관된 형식과 품질의 응답을 생성할 수 있도록 돕습니다.\n",
    "\n",
    "* 이 방식은 특히 특정 형식이나 구조를 가진 출력이 필요한 경우(예: JSON 형식, 특정 분석 리포트 형식 등) 매우 유용하며, 예제들이 고정되어 있어 결과의 일관성을 보장할 수 있습니다.\n",
    "\n",
    "* 단, 고정된 예제를 사용하기 때문에 상황에 따라 유연하게 대응하기 어려울 수 있으며, 모든 케이스를 커버하기 위해서는 신중한 예제 선택이 필요합니다.\n",
    "\n",
    "---\n",
    "### 추가필기\n",
    "- 예시 데이터의 공백의 경우도 token으로 처리되므로 공백이 없는 것을 추천한다.\n",
    "- 아래 \"input\": dedent(\"\") 안에 가독성으로 공백이 있지만 없는 것이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from textwrap import dedent # text의 모든 줄에서 같은 선행 공백을 제거하는 함수\n",
    "\n",
    "# 예시 데이터 정의 : 뉴스 텍스트(input) + 키워드 추출 결과 (output)\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": dedent(\"\"\"\n",
    "                        정부는 의과대학 입학 정원을 2000명 증가시킬 계획의 세부사항을 이달 20일에 공개할 예정이다. \n",
    "                        지역별 의료 서비스 향상과 소규모 의과대학의 발전을 목표로, 지역 중심의 국립대학 및 소형 의과대학의 \n",
    "                        입학 정원이 최소한 두 배 가량 확대될 것으로 보인다.\n",
    "                        \"\"\"),\n",
    "        \"output\": \"의대 | 정원 | 확대\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": dedent(\"\"\"\n",
    "                        세계보건기구(WHO)는 최근 새로운 건강 위기에 대응하기 위해 국제 협력의 중요성을 강조했다. \n",
    "                        전염병 대응 역량의 강화와 글로벌 보건 시스템의 개선이 필요하다고 발표했다.\n",
    "                        \"\"\"),\n",
    "        \"output\": \"세계보건기구 | 건강위기 | 국제\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 각 예시를 포맷팅할 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"assistant\", \"{output}\")\n",
    "])\n",
    "\n",
    "# Few-shot 프롬프트 템플릿 생성\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,      # 예시 포맷팅 템플릿\n",
    "    examples=examples                   # 예시 데이터 리스트 -> 예시 포맷팅 템플릿에 적용\n",
    ")\n",
    "\n",
    "pprint(few_shot_prompt.invoke({}).to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 프롬프트 템플릿 생성\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 뉴스 텍스트에서 핵심 키워드 3개를 추출하는 전문가입니다.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 프롬프트 템플릿 출력\n",
    "pprint(final_prompt.invoke({\"input\": \"뉴스 기사입니다\"}).to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 추출 체인 생성\n",
    "chain = final_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 키워드 추출 체인 실행\n",
    "result = chain.invoke({\n",
    "    \"input\": dedent(\"\"\"삼성전자가 내년 초에 자체적으로 개발한 인공지능(AI) 가속기를 처음으로 출시할 예정이다. \n",
    "                    이는 AI 반도체 시장에서 지배적인 위치를 차지하고 있는 엔비디아의 독점을 도전하고, \n",
    "                    세계 최고의 반도체 제조업체로서의 지위를 다시 확립하려는 삼성전자의 노력으로 해석된다.\"\"\")\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) Dynamic Few-Shot Prompting`\n",
    "\n",
    "* **Dynamic Few-Shot Prompting**은 상황에 따라 적절한 예시를 동적으로 선택하여 사용하는 고급 프롬프팅 기법으로, **BaseExampleSelector**를 통해 입력값과 가장 연관성이 높은 예시들을 자동으로 선별합니다.\n",
    "\n",
    "* 대표적으로 **SemanticSimilarityExampleSelector**는 의미적 유사도를 기반으로 예시를 선택하며, 이를 통해 주어진 입력 상황에 가장 적합한 예시들만을 효율적으로 활용할 수 있습니다.\n",
    "\n",
    "* **example_prompt**를 통해 선택된 예시들을 AI 시스템이 이해하기 쉬운 형태(예: human-AI 대화 , human-function call)로 변환하여 더 효과적인 학습과 응답 생성이 가능하게 합니다.\n",
    "\n",
    "\n",
    "- **장점**\n",
    "\n",
    "    - 상황에 맞는 가장 연관성 높은 예시만을 선택적으로 활용할 수 있다\n",
    "    - 프롬프트의 길이를 효율적으로 관리할 수 있다\n",
    "    - 응답의 일관성과 품질을 향상시킬 수 있다\n",
    "\n",
    "---\n",
    "### 추가 필기\n",
    "- 예전에는 2-5개 정도의 예제를 제안하는 것을 추천했지만 현재 모델의 경우에는 더 많은 예제를 넣어도 될 것으로 판단된다.\n",
    "- metadata 필터링, 쿼리, \n",
    "- K > 답변생성값이 2 - 5는 낮은 값으로 답변이 제대로 나오지 않는다. 문서 10만개에서 K= 50 or 20이면 10만개에서\n",
    "20개, 50개를 갖고오는 방향이다\n",
    "    - 리콜을 높이기 위해서는 K를 높여야한다.\n",
    "    - 리콜을 높이면 정밀도가 떨어지게 된다.\n",
    "- 관련 없는 예제가 들어오게 되면 환각이 높아지게 된다.\n",
    "\n",
    "- Q. Dynamic Few-Shot Prompting은 RAG와 어떤 점이 다른 걸까요?\n",
    "\n",
    "- 아래 코드에서\n",
    "    - to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "    - 이부분에서 질문, 답변을 모두 join을 하였기 때문에\n",
    "    - `selected_examples = example_selector.select_examples({\"input\":\"상품이 파손되어 왔어요\"})`\n",
    "        - 해당 input과 비교되는 부분이 질문과 답변 모두 유사한 경우로 response가 된다.\n",
    "        - 해당 기준이 질문 or 답변으로 나뉘어지는게 좀 더 안정적이다.\n",
    "\n",
    "- Select Context(검색 기술)\n",
    "    - 우리가 지금까지 검색 기술이 공부한 것\n",
    "        - [링크](https://blog.langchain.com/context-engineering-for-agents/)\n",
    "    - Vector, BM25(sparse)\n",
    "    - 현재는 RAG기반이지만 검색이 key가 된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings \n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# 고객 문의 유형별 응대 예시를 준비\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"환불 절차가 어떻게 되나요?\",\n",
    "        \"output\": \"환불 절차는 다음과 같습니다:\\n1. 구매내역에서 환불을 신청해주세요\\n2. 반품 상품을 발송해주세요\\n3. 상품 검수 후 3-5일 내 환불이 완료됩니다\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"배송이 늦어지고 있어요\", \n",
    "        \"output\": \"불편을 드려 죄송합니다. 주문번호를 알려주시면 배송 상태를 즉시 확인해드리겠습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"옷 사이즈가 안 맞아요\",\n",
    "        \"output\": \"사이즈 교환은 무료로 진행됩니다. 교환 신청 후 동일 상품의 다른 사이즈로 발송해드리겠습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"제품이 불량이에요\",\n",
    "        \"output\": \"불편을 드려 대단히 죄송합니다. 불량 부분 사진과 함께 1:1 문의에 접수해주시면 빠르게 처리해드리겠습니다.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예시 데이터를 벡터화할 텍스트로 변환\n",
    "to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "\n",
    "# Ollama 임베딩 모델 생성\n",
    "embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "\n",
    "# 벡터 스토어 생성\n",
    "vector_store = InMemoryVectorStore.from_texts(\n",
    "    to_vectorize,    # 벡터화할 텍스트 리스트\n",
    "    embeddings,      # 임베딩 모델\n",
    "    metadatas=examples    # 메타데이터: 예시 데이터\n",
    "    )\n",
    "\n",
    "# VectorStore에 저장된 Document 개수 확인\n",
    "print(f\"VectorStore에 저장된 Document 개수: {len(vector_store.store.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "\n",
    "# 유사한 2개의 예시를 선택하는 selector 생성\n",
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vector_store,\n",
    "    k=2\n",
    ")\n",
    "\n",
    "# 선택된 예시 확인\n",
    "selected_examples = example_selector.select_examples({\"input\":\"상품이 파손되어 왔어요\"})\n",
    "pprint(selected_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 프롬프트 템플릿 생성\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=ChatPromptTemplate.from_messages([\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"assistant\", \"{output}\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "pprint(few_shot_prompt.invoke({\"input\": \"상품이 파손되어 왔어요\"}).to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 프롬프트 생성 \n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친절하고 전문적인 고객 서비스 담당자입니다.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "pprint(final_prompt.invoke({\"input\": \"상품이 파손되어 왔어요\"}).to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 체인 생성\n",
    "chain = final_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 체인 실행\n",
    "response = chain.invoke({\n",
    "    \"input\": \"상품이 파손되어 왔어요\"\n",
    "})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 감정 분석기 만들기\n",
    "\n",
    "- Zero-shot 방식으로 텍스트의 감정(긍정/부정)을 분류하는 프롬프트를 작성합니다.\n",
    "- Few-shot 방식으로 3개의 예시를 포함하여 같은 작업을 수행하는 프롬프트를 작성합니다.\n",
    "- LLM 체인을 구성하여 두 방식의 출력 결과를 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot 방식 프롬프트\n",
    "# 1. PromptTemplate을 사용하여 감정 분석 프롬프트 작성\n",
    "# 2. 입력 변수: text\n",
    "# 3. 지시사항: 텍스트의 감정을 '긍정' 또는 '부정'으로 분류\n",
    "# 4. 체인 구성: prompt | llm | StrOutputParser()\n",
    "\n",
    "# 테스트 데이터\n",
    "test_texts = [\n",
    "    \"이 제품 정말 마음에 들어요! 강력 추천합니다.\",\n",
    "    \"배송이 너무 늦고 제품도 불량이네요. 최악입니다.\"\n",
    "]\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot 방식 프롬프트\n",
    "# 1. FewShotChatMessagePromptTemplate 또는 PromptTemplate 사용\n",
    "# 2. 3개의 예시 포함 (긍정 2개, 부정 1개 권장)\n",
    "# 3. 각 예시는 {\"input\": \"텍스트\", \"output\": \"긍정/부정\"} 형태\n",
    "# 4. 체인 구성 및 동일한 테스트 데이터로 실행\n",
    "# 5. Zero-shot 결과와 비교\n",
    "\n",
    "# 예시 데이터 힌트\n",
    "examples = [\n",
    "    {\"input\": \"배송이 빠르고 품질이 좋아요!\", \"output\": \"긍정\"},\n",
    "    # 2개 더 추가...\n",
    "]\n",
    "\n",
    "# 여기에 코드를 작성하세요\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "001-chatbot (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
