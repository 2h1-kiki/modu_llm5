{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a8771c",
   "metadata": {},
   "source": [
    "# [ì‹¤ìŠµ í”„ë¡œì íŠ¸]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d50a8",
   "metadata": {},
   "source": [
    "### **ë‹¤ìŒê³¼ ê°™ì€ ìš”êµ¬ì‚¬í•­ì„ Gradio ChatInterfaceë¡œ êµ¬í˜„í•©ë‹ˆë‹¤**\n",
    "\n",
    "- ì£¼ì œ: ë§ì¶¤í˜• ì—¬í–‰ ì¼ì • ê³„íš ì–´ì‹œìŠ¤í„´íŠ¸\n",
    "- ê¸°ëŠ¥: \n",
    "   - OpenAI Chat Completion APIì™€ LangChainì„ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì„ í˜¸ë„ì— ë§ëŠ” ì—¬í–‰ ì¼ì •ì„ ìƒì„±\n",
    "   - LCELì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ì²´ì¸ êµ¬ì„± (ì‚¬ìš©ì ì…ë ¥ ë¶„ì„ -> ì¼ì • ìƒì„± -> ì„¸ë¶€ ê³„íš ìˆ˜ë¦½)\n",
    "   - ì±„íŒ… íˆìŠ¤í† ë¦¬ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±\n",
    "   - Gradio ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ì‚¬ìš©ìì™€ ëŒ€í™”í˜•ìœ¼ë¡œ ìƒí˜¸ì‘ìš©\n",
    "\n",
    "- ì£¼ìš” í¬ì¸íŠ¸:\n",
    "\n",
    "   1. **ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ ìµœì í™”**\n",
    "      - temperature=0.7: ì ë‹¹í•œ ì°½ì˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ì¼ê´€ëœ ì‘ë‹µ ìƒì„±\n",
    "      - top_p=0.9: ë†’ì€ í™•ë¥ ì˜ í† í°ë§Œ ì„ íƒí•˜ì—¬ ì‘ë‹µì˜ í’ˆì§ˆ í–¥ìƒ\n",
    "      - presence_penaltyì™€ frequency_penalty: ë°˜ë³µì ì¸ ì‘ë‹µì„ ì¤„ì´ê³  ë‹¤ì–‘í•œ ì œì•ˆ ìƒì„±\n",
    "\n",
    "   2. **ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ê³„**\n",
    "      - ì—¬í–‰ í”Œë˜ë„ˆë¡œì„œì˜ ì—­í• ê³¼ ì‘ë‹µ ê°€ì´ë“œë¼ì¸ì„ ëª…í™•íˆ ì •ì˜\n",
    "      - êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•˜ë„ë¡ ì§€ì‹œ\n",
    "      - í•œêµ­ì–´ ì‘ë‹µ ëª…ì‹œ\n",
    "\n",
    "   3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**\n",
    "      - Gradio ë˜ëŠ” LangChain ë©”ëª¨ë¦¬ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€\n",
    "      - ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì—°ì†ì„± ìˆëŠ” ì‘ë‹µ ìƒì„±\n",
    "\n",
    "### ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ\n",
    "\n",
    "- **Step 1**: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "   - ì—¬í–‰ í”Œë˜ë„ˆì˜ ì—­í•  ëª…ì‹œ\n",
    "   - êµ¬ì²´ì ì¸ ì •ë³´ í¬í•¨ ì§€ì‹œ (ë‚ ì§œ, ì¥ì†Œ, ì˜ˆì‚° ë“±)\n",
    "\n",
    "- **Step 2**: ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬\n",
    "   - MessagesPlaceholder ì‚¬ìš©\n",
    "   - HumanMessage/AIMessage ë³€í™˜\n",
    "\n",
    "- **Step 3**: Gradio ì¸í„°í˜ì´ìŠ¤ ì„¤ì •\n",
    "   - ì œëª©ê³¼ ì„¤ëª… ì¶”ê°€\n",
    "\n",
    "**Step 4**: í…ŒìŠ¤íŠ¸\n",
    "   - \"ì„œìš¸ì—ì„œ 2ë°• 3ì¼ ì—¬í–‰ ê³„íš ì§œì¤˜\" ë“±ì˜ ì§ˆë¬¸ ì‹œë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1d48a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f655b825",
   "metadata": {},
   "source": [
    "### ë²„ì „1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6d0b82a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import gradio as gr\n",
    "\n",
    "# ì´ˆê¸° ë©”ì‹œì§€ ì •ì˜\n",
    "INITIAL_MESSAGE = (\n",
    "    \"âœˆï¸ ì•ˆë…•í•˜ì„¸ìš”! ë‹¹ì‹ ì„ ìœ„í•œ ë§ì¶¤ ì—¬í–‰ ê³„íšì„ ë§Œë“¤ì–´ ë“œë¦´ê²Œìš”.\\n\"\n",
    "    \"ì—¬í–‰í•˜ê³  ì‹¶ì€ ë„ì‹œ, ì¼ì •, ì˜ˆì‚°, ë™í–‰ ì¸ì›ì„ ì•Œë ¤ì£¼ì„¸ìš”!\"\n",
    ")\n",
    "\n",
    "# ë©”ì‹œì§€ í”Œë ˆì´ìŠ¤í™€ë”ê°€ ìˆëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"ë‹¹ì‹ ì€ ë§ì¶¤í˜• ì—¬í–‰ í”Œë˜ë„ˆ AIì…ë‹ˆë‹¤.\\n\"\n",
    "        \"ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë°˜ë“œì‹œ í¬í•¨í•´ í•œêµ­ì–´ë¡œ ì œì•ˆí•˜ì„¸ìš”:\\n\"\n",
    "        \"- ğŸ“… ì¼ìë³„ ì¼ì •\\n\"\n",
    "        \"- ğŸ’° ì˜ˆìƒ ì˜ˆì‚°(ìˆ™ë°•/ì‹ë¹„/êµí†µ/ê´€ê´‘)\\n\"\n",
    "        \"- ğŸ½ï¸ í˜„ì§€ ë§›ì§‘ ì¶”ì²œ\\n\"\n",
    "        \"- ğŸš• ì´ë™ ë°©ë²•\\n\"\n",
    "        \"- ğŸ¨ ìˆ™ì†Œ ìœ í˜• ì¶”ì²œ\\n\\n\"\n",
    "        \"ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ë¨¼ì € í•„ìš”í•œ í•­ëª©ì„ ì§ˆë¬¸í•˜ì„¸ìš”.\"\n",
    "    ),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "# LLM ëª¨ë¸ ì •ì˜\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.7,       # ì ë‹¹í•œ ì°½ì˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ì¼ê´€ëœ ì‘ë‹µ ìƒì„±\n",
    "    top_p=0.9,             # ë†’ì€ í™•ë¥ ì˜ í† í°ë§Œ ì„ íƒí•˜ì—¬ ì‘ë‹µì˜ í’ˆì§ˆ í–¥ìƒ\n",
    "    presence_penalty=0.3,  # ë°˜ë³µì ì¸ ì‘ë‹µì„ ì¤„ì´ê³  ë‹¤ì–‘í•œ ì œì•ˆ ìƒì„±(ì´ë¯¸ ë§ì´ ë‚˜ì˜¨ ë‹¨ì–´ì˜ ì¬ë“±ì¥ ì–µì œ)\n",
    "    frequency_penalty=0.3, # ë°˜ë³µì ì¸ ì‘ë‹µì„ ì¤„ì´ê³  ë‹¤ì–‘í•œ ì œì•ˆ ìƒì„±(ìƒˆë¡œìš´ ì£¼ì œë¡œì˜ ì „í™˜ ìœ ë„)\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ + LLM ëª¨ë¸ + ì¶œë ¥íŒŒì„œë¥¼ ì—°ê²°í•˜ì—¬ ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  AI ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (chat_history ì‚¬ìš©)\n",
    "def answer_invoke(message, history):\n",
    "\n",
    "    # ìƒíƒœ ë©”ì‹œì§€ ì¶œë ¥\n",
    "    yield \"ì—¬í–‰ ê³„íšì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤ ğŸ˜Š\"\n",
    "\n",
    "    history_messages = []\n",
    "    for msg in history:\n",
    "        if msg['role'] == \"user\":\n",
    "            history_messages.append(HumanMessage(content=msg['content']))\n",
    "        elif msg['role'] == \"assistant\":\n",
    "            history_messages.append(AIMessage(content=msg['content']))\n",
    "\n",
    "    try:\n",
    "        buffer = \"\"\n",
    "\n",
    "        # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "        for chunk in chain.stream({\n",
    "            \"chat_history\": history_messages,\n",
    "            \"user_input\": message\n",
    "        }):\n",
    "            buffer += chunk\n",
    "            yield buffer\n",
    "\n",
    "    except Exception as e:\n",
    "        yield f\"âš ï¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2378d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê¸°ì¤€\n",
    "BASE_DIR = Path.cwd()          # ì—¬ê¸°ì„œ .ipynb ì‹¤í–‰ ì¤‘ì´ë©´ notebook ìœ„ì¹˜ ê¸°ì¤€\n",
    "DATA_DIR = BASE_DIR / \"data\"   # BASE_DIR/data\n",
    "DATA_DIR.mkdir(exist_ok=True)  # ì—†ìœ¼ë©´ ìë™ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37c9c249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfbase.cidfonts import UnicodeCIDFont\n",
    "\n",
    "# ğŸ”¤ í•œê¸€ í°íŠ¸ ë“±ë¡ (í•„ìˆ˜)\n",
    "pdfmetrics.registerFont(UnicodeCIDFont(\"HYSMyeongJo-Medium\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b1055215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import re\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, ListFlowable, ListItem\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.units import mm\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "\n",
    "# PDF ìƒì„±ìš© ìŠ¤íƒ€ì¼\n",
    "styles = getSampleStyleSheet()\n",
    "styles[\"Normal\"].fontName = \"HYSMyeongJo-Medium\"\n",
    "styles[\"Heading1\"].fontName = \"HYSMyeongJo-Medium\"\n",
    "\n",
    "body_style = ParagraphStyle(\n",
    "    \"Body\",\n",
    "    parent=styles[\"Normal\"],\n",
    "    fontName=\"HYSMyeongJo-Medium\",\n",
    "    fontSize=11,\n",
    "    leading=16,\n",
    ")\n",
    "\n",
    "title_style = ParagraphStyle(\n",
    "    \"Title\",\n",
    "    parent=styles[\"Heading1\"],\n",
    "    fontName=\"HYSMyeongJo-Medium\",\n",
    "    fontSize=18,\n",
    ")\n",
    "\n",
    "# ë§ˆí¬ë‹¤ìš´ â†’ PDF ë³€í™˜\n",
    "def md_to_paragraph(text: str):\n",
    "    flowables = []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            flowables.append(Spacer(1, 6))\n",
    "            continue\n",
    "\n",
    "        # ì œëª© ì²˜ë¦¬\n",
    "        if line.startswith(\"###\"):\n",
    "            content = line[3:].strip()\n",
    "            flowables.append(Paragraph(f\"<b>{content}</b>\", title_style))\n",
    "            flowables.append(Spacer(1, 8))\n",
    "            continue\n",
    "\n",
    "        # ëª©ë¡ ì²˜ë¦¬\n",
    "        if line.startswith(\"- \"):\n",
    "            content = line[2:].strip()\n",
    "            content = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"<b>\\1</b>\", content)\n",
    "            flowables.append(Paragraph(f\"â€¢ {content}\", body_style))\n",
    "            continue\n",
    "\n",
    "        # ì¼ë°˜ ë¬¸ë‹¨ ì²˜ë¦¬\n",
    "        content = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"<b>\\1</b>\", line)\n",
    "        flowables.append(Paragraph(content, body_style))\n",
    "\n",
    "    return flowables\n",
    "\n",
    "# PDF ìƒì„± í•¨ìˆ˜\n",
    "def create_itinerary_pdf(ai_text: str, filename=\"travel_itinerary.pdf\"):\n",
    "    path = DATA_DIR / filename\n",
    "    story = []\n",
    "\n",
    "    story.append(Paragraph(\"âœˆï¸ ë§ì¶¤ ì—¬í–‰ ì¼ì •í‘œ\", title_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "    story.extend(md_to_paragraph(ai_text))\n",
    "\n",
    "    doc = SimpleDocTemplate(\n",
    "        str(path),\n",
    "        pagesize=A4,\n",
    "        rightMargin=20 * mm,\n",
    "        leftMargin=20 * mm,\n",
    "        topMargin=20 * mm,\n",
    "        bottomMargin=20 * mm,\n",
    "    )\n",
    "    doc.build(story)\n",
    "    return str(path.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "06e403ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF ìƒì„±ìš© í‚¤ì›Œë“œ\n",
    "required_keywords = [\"ğŸ“…\", \"ğŸ’°\", \"ğŸ½ï¸\", \"ğŸš•\", \"ğŸ¨\"]\n",
    "def check_itinerary(ai_text: str):\n",
    "    return any(kw in ai_text for kw in required_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f559e8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7899\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7899/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    gr.Markdown(\"## âœˆï¸ ë§ì¶¤í˜• ì—¬í–‰ ì¼ì • ê³„íš ì–´ì‹œìŠ¤í„´íŠ¸\")\n",
    "\n",
    "    chatbot = gr.Chatbot(\n",
    "        value=[{\"role\": \"assistant\", \"content\": INITIAL_MESSAGE}],\n",
    "        height=420,\n",
    "    )\n",
    "\n",
    "    chat = gr.ChatInterface(\n",
    "        fn=answer_invoke,\n",
    "        chatbot=chatbot,\n",
    "    )\n",
    "\n",
    "    status = gr.Markdown()\n",
    "\n",
    "    with gr.Row():\n",
    "        reset_btn = gr.Button(\"ğŸ”„ ìƒˆ ëŒ€í™” ì‹œì‘\")\n",
    "        save_btn = gr.Button(\"ğŸ“¥ ì¼ì • PDF ì €ì¥\")\n",
    "\n",
    "    # ---------- Reset ----------\n",
    "    def reset_chat():\n",
    "        return [{\"role\": \"assistant\", \"content\": INITIAL_MESSAGE}]\n",
    "\n",
    "    reset_btn.click(\n",
    "        fn=reset_chat,\n",
    "        outputs=chatbot,\n",
    "    )\n",
    "\n",
    "    # ---------- PDF ----------\n",
    "    has_itinerary = gr.State(False)  # ì¼ì • ìƒì„± ì—¬ë¶€ í”Œë˜ê·¸\n",
    "\n",
    "    def make_pdf(history, has_itinerary_flag):\n",
    "        last_ai = None\n",
    "\n",
    "        # Chatbot í¬ë§· ëŒ€ì‘ (tuple / dict)\n",
    "        for msg in reversed(history):\n",
    "            if isinstance(msg, dict) and msg.get(\"role\") == \"assistant\":\n",
    "                last_ai = msg.get(\"content\")\n",
    "                break\n",
    "            elif isinstance(msg, (list, tuple)) and len(msg) == 2:\n",
    "                last_ai = msg[1]\n",
    "                break\n",
    "\n",
    "        if not last_ai:\n",
    "            return \"âš ï¸ ì €ì¥í•  AI ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤.\", False\n",
    "\n",
    "        # ë¬¸ìì—´ ë³€í™˜\n",
    "        if isinstance(last_ai, dict) and \"text\" in last_ai:\n",
    "            last_ai_text = last_ai[\"text\"]\n",
    "        elif isinstance(last_ai, list):\n",
    "            last_ai_text = \"\\n\".join(str(x) for x in last_ai)\n",
    "        else:\n",
    "            last_ai_text = str(last_ai)\n",
    "\n",
    "        # ì¼ì • í‚¤ì›Œë“œ í™•ì¸\n",
    "        if not check_itinerary(last_ai_text):\n",
    "            return \"âš ï¸ ì•„ì§ ì—¬í–‰ ì¼ì •ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì—¬í–‰ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\", False\n",
    "\n",
    "        path = create_itinerary_pdf(last_ai_text)\n",
    "        has_itinerary_flag = True\n",
    "        return f\"âœ… PDF ì €ì¥ ì™„ë£Œ: `{path}`\", True\n",
    "\n",
    "    save_btn.click(\n",
    "        fn=make_pdf,\n",
    "        inputs=[chatbot, has_itinerary],\n",
    "        outputs=[status, has_itinerary],\n",
    "    )\n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c7025e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7865\n"
     ]
    }
   ],
   "source": [
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì¢…ë£Œ\n",
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "001-chatbot (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
