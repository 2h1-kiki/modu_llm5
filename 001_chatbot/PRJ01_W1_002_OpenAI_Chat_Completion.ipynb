{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV-Z1B-Pa4L1"
   },
   "source": [
    "# LLM ì›ë¦¬ + OpenAI Chat Completion API í™œìš©\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "1. **LLM ê¸°ë³¸ ê°œë…**: íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ì™€ í† í° ì˜ˆì¸¡ ì›ë¦¬ ì´í•´\n",
    "2. **OpenAI API ê¸°ì´ˆ**: Chat Completion APIì˜ ê¸°ë³¸ ì‚¬ìš©ë²• ìŠµë“\n",
    "3. **ë©€í‹°ëª¨ë‹¬ í™œìš©**: í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ë²• í•™ìŠµ\n",
    "4. **êµ¬ì¡°í™”ëœ ì¶œë ¥**: JSON Schemaë¥¼ ì‚¬ìš©í•œ êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„±\n",
    "5. **ë§¤ê°œë³€ìˆ˜ ìµœì í™”**: Temperature, Top-p ë“± ì£¼ìš” ë§¤ê°œë³€ìˆ˜ í™œìš©\n",
    "6. **ë‹¤ì–‘í•œ API**: Embeddings, Moderation, Function Calling, Streaming í™œìš©\n",
    "\n",
    "---\n",
    "\n",
    "## 1. LLM ê¸°ë³¸ ê°œë…\n",
    "\n",
    "### 1.1 LLM(Large Language Model)ì˜ ìƒì„± ì›ë¦¬\n",
    "\n",
    "**LLMì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?**\n",
    "- **íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡°**: ëŒ€í™”í˜• AIì˜ í•µì‹¬ ì•„í‚¤í…ì²˜\n",
    "- **í† í° ì˜ˆì¸¡**: ë‹¤ìŒì— ì˜¬ ê°€ì¥ ì ì ˆí•œ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡\n",
    "- **í•™ìŠµ ë°©ì‹**: ì¸í„°ë„·ì˜ ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ì „ í›ˆë ¨\n",
    "\n",
    "**í•µì‹¬ í”„ë¡œì„¸ìŠ¤**\n",
    "1. **í† í°í™”**: í…ìŠ¤íŠ¸ë¥¼ ì‘ì€ ë‹¨ìœ„(í† í°)ë¡œ ë¶„í• \n",
    "2. **í™•ë¥  ê³„ì‚°**: ê° í† í°ì´ ë‹¤ìŒì— ì˜¬ í™•ë¥  ê³„ì‚°\n",
    "3. **í† í° ìƒì„±**: í™•ë¥  ë¶„í¬ì— ë”°ë¼ í† í° ì„ íƒ\n",
    "4. **ë°˜ë³µ**: ì¢…ë£Œ ì¡°ê±´ê¹Œì§€ ê³¼ì • ë°˜ë³µ\n",
    "\n",
    "\n",
    "**íŠ¸ëœìŠ¤í¬ë¨¸**:\n",
    "- **ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°**: ì…ë ¥ê³¼ ì¶œë ¥ì„ ë™ì‹œì— ì²˜ë¦¬\n",
    "- **ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜**: ì…ë ¥ì˜ ëª¨ë“  ë¶€ë¶„ì„ ë™ì‹œì— ê³ ë ¤í•˜ì—¬ ì¤‘ìš”í•œ ì •ë³´ì— ì§‘ì¤‘\n",
    "\n",
    "\n",
    "<div style=\"text-align: left; font-size: 12px;\">\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Transformer%2C_full_architecture.png/440px-Transformer%2C_full_architecture.png\"\n",
    "        alt=\"Illustrations for the Transformer and attention mechanism showing the full Transformer architecture\"\n",
    "        width=\"600\"\n",
    "        style=\"border: 0;\">\n",
    "</div>\n",
    "\n",
    "**Image Title:** Transformer Architecture Illustration  \n",
    "**Source:** [GitHub - DL Visuals](https://github.com/dvgodoy/dl-visuals/?tab=readme-ov-file)  \n",
    "**License:** [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/)  \n",
    "**Author(s):** dvgodoy  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. OpenAI API í•µì‹¬ ê°œë…\n",
    "\n",
    "### 1.1 ì£¼ìš” êµ¬ì„± ìš”ì†Œ\n",
    "\n",
    "**1. ë©”ì‹œì§€ í˜•ì‹**\n",
    "\n",
    "  ```python\n",
    "  messages = [\n",
    "      {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"},\n",
    "      {\"role\": \"user\", \"content\": \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"},\n",
    "      {\"role\": \"assistant\", \"content\": \"sort() ë©”ì„œë“œë‚˜ sorted() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"}\n",
    "  ]\n",
    "  ```\n",
    "\n",
    "**2. í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ì£¼ìš” ëª¨ë¸ (2025ë…„ ê¸°ì¤€)**\n",
    "\n",
    "  - **gpt-4.1**: ìµœê³  ì„±ëŠ¥, ë³µì¡í•œ ì‘ì—…ìš©\n",
    "  - **gpt-4.1-mini**: ë¹ ë¥¸ ì†ë„, ë¹„ìš© íš¨ìœ¨ì \n",
    "  - **gpt-4.1-nano**: ì´ˆê³ ì†, ìµœì € ë¹„ìš©\n",
    "  - **o3, o4-mini**: ë³µì¡í•œ ì¶”ë¡  ì‘ì—…ìš©\n",
    "  - **gpt-4o**: ë©€í‹°ëª¨ë‹¬ (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤)\n",
    "\n",
    "  > ** ì°¸ê³ **: ëª¨ë¸ ëª©ë¡ì€ ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤. ìµœì‹  ëª¨ë¸ ì •ë³´ëŠ” [OpenAI Platform - Models](https://platform.openai.com/docs/models)ì—ì„œ í™•ì¸í•˜ì„¸ìš”.\n",
    "\n",
    "**3. API ì‘ë‹µ êµ¬ì¡°**\n",
    "\n",
    "  ```json\n",
    "  {\n",
    "    \"id\": \"chatcmpl-...\",\n",
    "    \"object\": \"chat.completion\",\n",
    "    \"model\": \"gpt-4.1-mini\",\n",
    "    \"choices\": [\n",
    "      {\n",
    "        \"message\": {\n",
    "          \"role\": \"assistant\", \n",
    "          \"content\": \"ìƒì„±ëœ í…ìŠ¤íŠ¸\"\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"usage\": {\n",
    "      \"prompt_tokens\": 10,\n",
    "      \"completion_tokens\": 50,\n",
    "      \"total_tokens\": 60\n",
    "    }\n",
    "  }\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 3. í™˜ê²½ ì„¤ì •\n",
    "\n",
    "\n",
    "- **uv í”„ë¡œì íŠ¸ ì„¤ì •**\n",
    "    - **í”„ë¡œì íŠ¸ ìƒì„±**: `uv init [í”„ë¡œì íŠ¸ëª…]`\n",
    "    - **ê°€ìƒí™˜ê²½ ìƒì„±**: `uv venv --python=3.12`\n",
    "    - **ê°€ìƒí™˜ê²½ í™œì„±í™”**: `.venv/bin/activate` (Unix) ë˜ëŠ” `.venv\\Scripts\\activate` (Windows) # êµ³ì´ í•˜ì§€ ì•Šì•„ë„ ëœë‹¤.\n",
    "\n",
    "\n",
    "- **íŒ¨í‚¤ì§€ ì„¤ì¹˜**\n",
    "\n",
    "    ```bash\n",
    "    # uv ì‚¬ìš© (ê¶Œì¥)\n",
    "    uv add langchain langchain_openai python-dotenv ipykernel\n",
    "\n",
    "    # pip ì‚¬ìš©\n",
    "    pip install langchain langchain_openai python-dotenv ipykernel\n",
    "    ```\n",
    "\n",
    "- **API í‚¤ ì„¤ì •**\n",
    "\n",
    "    ```python\n",
    "    # .env íŒŒì¼ ìƒì„± - í™˜ê²½ë³€ìˆ˜ëŠ” ë¬´ì¡°ê±´ ëŒ€ë¬¸ìë¡œ ì‘ì„±í•´ì•¼í•œë‹¤.\n",
    "    OPENAI_API_KEY=your_api_key_here\n",
    "\n",
    "    # Pythonì—ì„œ ë¡œë“œ\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "\n",
    "    load_dotenv()\n",
    "    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .envì— \"OPENAI_API_KEY\"í‚¤ë¡œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •í•œ API í‚¤ ê°’ì´ ë‚˜ì˜¨ë‹¤.\n",
    "# import os\n",
    "# os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 4. ê¸°ë³¸ ì‚¬ìš©ë²•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 í…ìŠ¤íŠ¸ ë‹µë³€ì„ ìƒì„±\n",
    "\n",
    "* OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "  - `from openai import OpenAI`ë¡œ OpenAI íŒ¨í‚¤ì§€ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤\n",
    "  - `client = OpenAI()`ë¡œ API í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n",
    "  - API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ë‚˜ ì§ì ‘ ì„¤ì •ì„ í†µí•´ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "  - ë³´ì•ˆì„ ìœ„í•´ API í‚¤ëŠ” `.env` íŒŒì¼ì´ë‚˜ í™˜ê²½ë³€ìˆ˜ë¥¼ í†µí•´ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤\n",
    "\n",
    "* Chat Completion ìš”ì²­ êµ¬ì¡°\n",
    "  - `client.chat.completions.create()`ë¥¼ í†µí•´ í…ìŠ¤íŠ¸ ìƒì„±ì„ ìš”ì²­í•©ë‹ˆë‹¤\n",
    "  - `model`: ì‚¬ìš©í•  ëª¨ë¸ì„ ì§€ì • (ì˜ˆ: \"gpt-4.1-mini\")\n",
    "  - `messages`: ëŒ€í™” ë§¥ë½ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì „ë‹¬\n",
    "    - `role`: \"system\", \"user\" ë“±ì˜ ì—­í•  ì§€ì •\n",
    "    - `content`: ì‹¤ì œ ë©”ì‹œì§€ ë‚´ìš©\n",
    "  - `temperature`: ìƒì„± í…ìŠ¤íŠ¸ì˜ ë¬´ì‘ìœ„ì„± ì¡°ì ˆ (0~1)\n",
    "  - `max_tokens`: ìƒì„±ë  ìµœëŒ€ í† í° ìˆ˜ ì œí•œ\n",
    "\n",
    "* ì‘ë‹µ ì²˜ë¦¬\n",
    "  - APIëŠ” JSON í˜•íƒœë¡œ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤\n",
    "  - `response.choices[0].message.content`: ìƒì„±ëœ ë¶„ì„ í…ìŠ¤íŠ¸\n",
    "  - `response.usage`: í† í° ì‚¬ìš©ëŸ‰ ì •ë³´\n",
    "  - `response.id`: ì‘ë‹µì˜ ê³ ìœ  ì‹ë³„ì\n",
    "  - `response.model`: ì‚¬ìš©ëœ ëª¨ë¸ ì •ë³´\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-D5VGXHqmd79kucCKF44ty06V5Yizw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ì˜¤ëŠ˜ ë‚ ì§œëŠ” 2024ë…„ 6ì›” 15ì¼ì…ë‹ˆë‹¤. ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1770204197, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_e01c6f58e1', usage=CompletionUsage(completion_tokens=26, prompt_tokens=25, total_tokens=51, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "====================================================================================================\n",
      "id: chatcmpl-D5VGXHqmd79kucCKF44ty06V5Yizw\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: gpt-4.1-mini-2025-04-14\n",
      "----------------------------------------------------------------------------------------------------\n",
      "text: ì˜¤ëŠ˜ ë‚ ì§œëŠ” 2024ë…„ 6ì›” 15ì¼ì…ë‹ˆë‹¤. ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "usage: CompletionUsage(completion_tokens=26, prompt_tokens=25, total_tokens=51, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    }
   ],
   "source": [
    "# OpenAI APIë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ë°©ë²• (ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)\n",
    "from openai import OpenAI\n",
    "from openai import OpenAIError, APIError, RateLimitError, APIConnectionError\n",
    "import os\n",
    "\n",
    "# í†µì‹ ì„ ìœ„í•œ í´ë¼ì´ì–¸íŠ¸ ìƒì„± (.env íŒŒì¼ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ëŠ” ì£¼ì„ì„ í•´ì œí•˜ê³  api_keyë¥¼ ì§ì ‘ ì…ë ¥)\n",
    "client = OpenAI(\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Completion ìš”ì²­ (prompt -> completion)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini-2025-04-14\",\n",
    "        messages=[\n",
    "            # system ì—­í•  - ì „ë°˜ì ì¸ ë™ì‘ ë°©ì‹ ì •ì˜ (GPT-4 ê³„ì—´ì—ì„œ ê¶Œì¥)\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful programming assistant.\"},\n",
    "            # user ì—­í•  - ì‹¤ì œ ìš”ì²­ ë‚´ìš©\n",
    "            # ì‹œì ì— ëŒ€í•œ ì§ˆë¬¸ì˜ ê²½ìš° ì •í™•í•œ ì‹œê°„ì„ ì…ë ¥í•´ì•¼í•œë‹¤. - ì˜¤ëŠ˜ X\n",
    "            {\"role\": \"user\", \"content\": \"ì˜¤ëŠ˜ ë‚ ì§œëŠ” ì–¸ì œì¸ê°€ìš”?\"},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=2000,\n",
    "    )\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(response)\n",
    "    print(\"=\"*100)\n",
    "    print(\"id:\", response.id)\n",
    "    print(\"-\"*100)\n",
    "    print('model:', response.model)\n",
    "    print(\"-\"*100)\n",
    "    print(\"text:\", response.choices[0].message.content)\n",
    "    print(\"-\"*100)\n",
    "    print(\"usage:\", response.usage)\n",
    "\n",
    "except RateLimitError as e:\n",
    "    print(f\"âš ï¸ Rate Limit ì˜¤ë¥˜: API ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\")\n",
    "    print(f\"ìƒì„¸ ì •ë³´: {e}\")\n",
    "except APIConnectionError as e:\n",
    "    print(f\"âš ï¸ ì—°ê²° ì˜¤ë¥˜: OpenAI API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    print(f\"ìƒì„¸ ì •ë³´: {e}\")\n",
    "except APIError as e:\n",
    "    print(f\"âš ï¸ API ì˜¤ë¥˜: OpenAI APIì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"ìƒì„¸ ì •ë³´: {e}\")\n",
    "except OpenAIError as e:\n",
    "    print(f\"âš ï¸ OpenAI ì˜¤ë¥˜: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ì˜¤ëŠ˜ ë‚ ì§œëŠ” 2024ë…„ 6ì›” 15ì¼ì…ë‹ˆë‹¤. ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ê²°ê³¼ ì¶œë ¥ (Markdown)\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.2 êµ¬ì¡°í™”ëœ JSON ì¶œë ¥\n",
    "\n",
    "êµ¬ì¡°í™”ëœ ì¶œë ¥ì€ ë°ì´í„° ì²˜ë¦¬ì™€ ë¶„ì„ì— ìš©ì´í•˜ë©°, API ì‘ë‹µì˜ ì¼ê´€ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "* JSON Schema ì •ì˜\n",
    "  - `response_format`ì„ í†µí•´ ì‘ë‹µì˜ í˜•ì‹ì„ JSONìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤\n",
    "  - `json_schema`ì—ì„œ ë°ì´í„° êµ¬ì¡°ì™€ ê° í•„ë“œì˜ íŠ¹ì„±ì„ ì •ì˜í•©ë‹ˆë‹¤\n",
    "    - `type`: ë°ì´í„° íƒ€ì… (string, number ë“±)\n",
    "    - `description`: ê° í•„ë“œì— ëŒ€í•œ ì„¤ëª…\n",
    "    - `required`: í•„ìˆ˜ í•„ë“œ ì§€ì •\n",
    "    - `additionalProperties`: ì¶”ê°€ ì†ì„± í—ˆìš© ì—¬ë¶€\n",
    "\n",
    "* ì •ë³´ ì¶”ì¶œ ê³¼ì •\n",
    "  - ì…ë ¥ëœ í…ìŠ¤íŠ¸ì—ì„œ ì •ê·œí™”ëœ í˜•íƒœë¡œ ì •ë³´ë¥¼ ì¶”ì¶œ\n",
    "  - ì§€ì •ëœ ìŠ¤í‚¤ë§ˆì— ë§ì¶° JSON ê°ì²´ êµ¬ì„±\n",
    "  - í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì§€ ì•Šë„ë¡ ê²€ì¦\n",
    "  - ê°€ê²©ê³¼ ê°™ì€ ìˆ«ì ì •ë³´ëŠ” ì ì ˆí•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini-2025-04-14\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"ìƒí’ˆ ì •ë³´ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì¶”ì¶œí•˜ê³ , ê° ì†ì„±ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ì• í”Œ ì•„ì´í° 15 í”„ë¡œ 256GB (ë¸”ë™) - 1,500,000ì›\"\n",
    "        }\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"product_schema\",\n",
    "            \"description\": \"ìƒí’ˆì˜ ìƒì„¸ ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ê¸° ìœ„í•œ ìŠ¤í‚¤ë§ˆ\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"brand\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ì œì¡°ì‚¬ ë˜ëŠ” ë¸Œëœë“œ ì´ë¦„ (ì˜ˆ: ì• í”Œ, ì‚¼ì„±, LG ë“±)\"\n",
    "                    },\n",
    "                    \"model\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ì œí’ˆì˜ ëª¨ë¸ëª… ë˜ëŠ” ì‹œë¦¬ì¦ˆëª…\"\n",
    "                    },\n",
    "                    \"capacity\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ì €ì¥ ìš©ëŸ‰ ë˜ëŠ” ê·œê²© (ì˜ˆ: 256GB, 512GB ë“±)\"\n",
    "                    },\n",
    "                    \"color\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ì œí’ˆì˜ ìƒ‰ìƒ\"\n",
    "                    },\n",
    "                    \"price\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"ì œí’ˆì˜ ê°€ê²© (ë‹¨ìœ„: ì›)\",\n",
    "                        \"minimum\": 0\n",
    "                    },\n",
    "                    \"category\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ì œí’ˆì˜ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: ìŠ¤ë§ˆíŠ¸í°, ë…¸íŠ¸ë¶ ë“±)\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"brand\", \"model\", \"price\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response)\n",
    "print(\"=\"*100)\n",
    "print(\"id:\", response.id)\n",
    "print(\"-\"*100)\n",
    "print('model:', response.model)\n",
    "print(\"-\"*100)\n",
    "print(\"text:\", response.choices[0].message.content)\n",
    "print(\"-\"*100)\n",
    "print(\"usage:\", response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = json.loads(response.choices[0].message.content)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.3 ì´ë¯¸ì§€ ë¶„ì„ (ë©€í‹°ëª¨ë‹¬)\n",
    "\n",
    "OpenAI APIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„(ë©€í‹°ëª¨ë‹¬ ê¸°ëŠ¥ì„ í†µí•´ ì´ë¯¸ì§€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ê³¼ ì„¤ëª…ì„ ìì—°ì–´ë¡œ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "* ì´ë¯¸ì§€ ì…ë ¥ ë°©ì‹\n",
    "  - URL ë°©ì‹\n",
    "    - ì›¹ìƒì˜ ì´ë¯¸ì§€ URLì„ ì§ì ‘ ì „ë‹¬\n",
    "    - `image_url` íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ ì´ë¯¸ì§€ URL ì§€ì •\n",
    "    - ì¸í„°ë„· ì ‘ê·¼ì´ ê°€ëŠ¥í•œ ì´ë¯¸ì§€ì— ëŒ€í•´ ì‚¬ìš©\n",
    "  \n",
    "  - Base64 ì¸ì½”ë”© ë°©ì‹\n",
    "    - ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ì„ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "    - `encode_image()` í•¨ìˆ˜ë¡œ ì´ë¯¸ì§€ íŒŒì¼ì„ Base64ë¡œ ì¸ì½”ë”©\n",
    "    - ì¸ì½”ë”©ëœ ë¬¸ìì—´ì„ `data:image/jpeg;base64,` í˜•ì‹ìœ¼ë¡œ ì „ë‹¬\n",
    "    - ë¡œì»¬ ì´ë¯¸ì§€ë‚˜ ë¹„ê³µê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ì— ì í•©\n",
    "\n",
    "* API ìš”ì²­ êµ¬ì¡°\n",
    "  - `messages` ë°°ì—´ì— ë©€í‹°ëª¨ë‹¬ ì»¨í…ì¸  í¬í•¨\n",
    "    - `type`: \"text\" ë˜ëŠ” \"image_url\"ë¡œ ì»¨í…ì¸  ìœ í˜• êµ¬ë¶„\n",
    "    - í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ì „ë‹¬ ê°€ëŠ¥\n",
    "    - `role`ì„ í†µí•´ ê°œë°œì/ì‚¬ìš©ì ì—­í•  ì§€ì •\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ì´ë¯¸ì§€ URL ì‚¬ìš©`\n",
    "\n",
    "> **í•„ìš” íŒŒì¼**: Base64 ì˜ˆì œì—ì„œ ì‚¬ìš©í•˜ëŠ” `data/celltrion_report_chart.jpg` íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "- uv add pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ ì¶œë ¥\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# ì˜ˆì‹œ ì´ë¯¸ì§€ URL\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/600px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "\n",
    "# ë…¸íŠ¸ë¶ì— ì´ë¯¸ì§€ ì¶œë ¥\n",
    "display(Image(url=image_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "async def download_and_display_image(image_url):\n",
    "    \"\"\"ì´ë¯¸ì§€ë¥¼ ë¹„ë™ê¸°ë¡œ ë‹¤ìš´ë¡œë“œí•˜ê³  í‘œì‹œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    async with httpx.AsyncClient(headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}) as client:\n",
    "        # ë¹„ë™ê¸°ë¡œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "        response = await client.get(image_url)\n",
    "        \n",
    "        # ì‘ë‹µ ìƒíƒœ í™•ì¸\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ì—´ê¸°\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ì •ë³´ ì¶œë ¥\n",
    "        print(f\"ì´ë¯¸ì§€ í¬ê¸°: {img.size}\")\n",
    "        print(f\"ì´ë¯¸ì§€ ëª¨ë“œ: {img.mode}\")\n",
    "        print(f\"ì´ë¯¸ì§€ í¬ë§·: {img.format}\")\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ì¶œë ¥\n",
    "        display(img)\n",
    "        \n",
    "        return img\n",
    "\n",
    "\n",
    "try:\n",
    "    img = await download_and_display_image(image_url)\n",
    "    print(\"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° í‘œì‹œ ì™„ë£Œ!\")\n",
    "except httpx.HTTPError as e:\n",
    "    print(f\"HTTP ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"ì¼ë°˜ ì—ëŸ¬ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What's in this image? Answer in í•œêµ­ì–´.\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url,\n",
    "                    }\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response)\n",
    "print(\"=\"*100)\n",
    "print(\"id:\", response.id)\n",
    "print(\"-\"*100)\n",
    "print('model:', response.model)\n",
    "print(\"-\"*100)\n",
    "print(\"text:\", response.choices[0].message.content)\n",
    "print(\"-\"*100)\n",
    "print(\"usage:\", response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2)  Base 64 encoded format ì‚¬ìš©`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ\n",
    "image_path = \"data/celltrion_report_chart.jpg\"\n",
    "\n",
    "# ì´ë¯¸ì§€ ì¶œë ¥\n",
    "img = Image.open(image_path)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# ì´ë¯¸ì§€ë¥¼ base64 í¬ë§· ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "base64_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# ì´ì „ ì…€ì—ì„œ ì •ì˜í•œ encode_image í•¨ìˆ˜ ì¬ì‚¬ìš©\n",
    "# ì´ë¯¸ì§€ë¥¼ base64 í¬ë§· ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"You are a financial chart analyst. For any chart:\n",
    "                            1. Identify the financial metrics being displayed\n",
    "                            2. Note key price levels, support/resistance areas\n",
    "                            3. Identify significant trends and pattern formations\n",
    "                            4. Calculate relevant indicators (if visible)\n",
    "                            5. Highlight trading volume patterns\n",
    "                            6. Point out any significant market events\n",
    "                            7. Provide technical analysis insights\n",
    "                            Be specific with price levels and dates. Answer in í•œêµ­ì–´.\"\"\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What does this chart show?\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.4 ì˜¤ë””ì˜¤ ì¶œë ¥\n",
    "\n",
    "\n",
    "OpenAI APIì˜ ìŒì„± ìƒì„±(Text-to-Speech) ê¸°ëŠ¥ì„ í†µí•´ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "* API ìš”ì²­ ì„¤ì •\n",
    "  - `model`: \"gpt-4o-mini-audio-preview\"ì™€ ê°™ì€ ì˜¤ë””ì˜¤ ì§€ì› ëª¨ë¸ ì‚¬ìš©\n",
    "  - `modalities`: [\"text\", \"audio\"]ë¡œ í…ìŠ¤íŠ¸ì™€ ì˜¤ë””ì˜¤ ëª¨ë‘ ì¶œë ¥\n",
    "  - `audio` íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    - `voice`: ìŒì„± ì¢…ë¥˜ ì„ íƒ (ì˜ˆ: \"alloy\")\n",
    "    - `format`: ì¶œë ¥ í¬ë§· ì§€ì • (ì˜ˆ: \"wav\")\n",
    "\n",
    "* ìŒì„± ìƒì„± ê³¼ì •\n",
    "  - APIëŠ” í…ìŠ¤íŠ¸ ì‘ë‹µê³¼ í•¨ê»˜ Base64ë¡œ ì¸ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„° ë°˜í™˜\n",
    "  - ì‘ë‹µ êµ¬ì¡°:\n",
    "    - `completion.choices[0].message.content`: í…ìŠ¤íŠ¸ ì‘ë‹µ\n",
    "    - `completion.choices[0].message.audio.data`: Base64 ì¸ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„°\n",
    "\n",
    "* ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥\n",
    "  - Base64 ë””ì½”ë”©\n",
    "    ```python\n",
    "        wav_bytes = base64.b64decode(completion.choices[0].message.audio.data)\n",
    "    ```\n",
    "  - íŒŒì¼ë¡œ ì €ì¥\n",
    "    ```python\n",
    "        with open(\"sample.wav\", \"wb\") as f:\n",
    "            f.write(wav_bytes)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini-audio-preview\",\n",
    "    modalities=[\"text\", \"audio\"],\n",
    "    audio={\"voice\": \"alloy\", \"format\": \"wav\"},\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ì•ˆë…•í•˜ì„¸ìš”. ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŒì„± íŒŒì¼ ì €ì¥\n",
    "import base64\n",
    "\n",
    "wav_bytes = base64.b64decode(completion.choices[0].message.audio.data)\n",
    "with open(\"sample.wav\", \"wb\") as f:\n",
    "    f.write(wav_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í† í° ì‚¬ìš©ëŸ‰\n",
    "print(response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "**[ì‹¤ìŠµ 1]**: OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ê³  í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "- `íŒíŠ¸: python-dotenv íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n",
    "# íŒíŠ¸:\n",
    "# 1. from dotenv import load_dotenv ì„í¬íŠ¸\n",
    "# 2. load_dotenv()ë¡œ .env íŒŒì¼ ë¡œë“œ\n",
    "# 3. from openai import OpenAI ì„í¬íŠ¸\n",
    "# 4. client = OpenAI()ë¡œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ì‹¤ìŠµ 2]**: ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ OpenAI API(gpt-4.1-mini)ë¡œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def get_simple_completion(prompt: str) -> str:\n",
    "    client = OpenAI()\n",
    "    # íŒíŠ¸:\n",
    "    # 1. client.chat.completions.create() í˜¸ì¶œ\n",
    "    # 2. model=\"gpt-4.1-mini\" ì§€ì •\n",
    "    # 3. messagesì— user roleë¡œ prompt ì „ë‹¬\n",
    "    # 4. response.choices[0].message.content ë°˜í™˜\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. ë§¤ê°œë³€ìˆ˜ ìµœì í™”\n",
    "\n",
    "### 5.1 ì£¼ìš” ë§¤ê°œë³€ìˆ˜ \n",
    "\n",
    "| ë§¤ê°œë³€ìˆ˜ | ë²”ìœ„ | ìš©ë„ | ì¶”ì²œê°’ |\n",
    "|---------|------|------|--------|\n",
    "| `temperature` | 0~2 | ì°½ì˜ì„± ì¡°ì ˆ | 0.3 (ì •í™•ì„±), 0.7 (ê· í˜•), 1.2 (ì°½ì˜ì„±) |\n",
    "| `top_p` | 0~1 | ì‘ë‹µ ë‹¤ì–‘ì„± | 0.9 (ê¸°ë³¸), 0.3 (ì§‘ì¤‘ì ) |\n",
    "| `max_tokens` | 1~8192+ | ìµœëŒ€ ê¸¸ì´ | ì‘ì—…ì— ë”°ë¼ ì¡°ì ˆ |\n",
    "| `frequency_penalty` | -2~2 | ë°˜ë³µ ì–µì œ | 0.3~0.6 |\n",
    "| `presence_penalty` | -2~2 | ìƒˆ ì£¼ì œ ë„ì… | 0.3~0.6 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„¤ì •\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ì •í™•í•œ ì •ë³´ ì œê³µ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ ë©”ì„œë“œë“¤ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"}],\n",
    "    temperature=0.2,  # ë‚®ì€ ì°½ì˜ì„±\n",
    "    top_p=0.3,        # ì§‘ì¤‘ì  ì‘ë‹µ\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. ì°½ì˜ì  ê¸€ì“°ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"ìš°ì£¼ ì •ê±°ì¥ì—ì„œì˜ í•˜ë£¨ë¥¼ ì†Œì„¤ë¡œ ì¨ì£¼ì„¸ìš”.\"}],\n",
    "    temperature=1.1,  # ë†’ì€ ì°½ì˜ì„±\n",
    "    top_p=0.9,        # ë‹¤ì–‘í•œ í‘œí˜„\n",
    "    max_tokens=1000,\n",
    "    frequency_penalty=0.5  # ë°˜ë³µ ë°©ì§€\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ì½”ë“œ ìƒì„±**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"ì›¹ ìŠ¤í¬ë˜í•‘ì„ ìœ„í•œ Python í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\"}],\n",
    "    temperature=0.4,  # ì•½ê°„ì˜ ì°½ì˜ì„±\n",
    "    max_tokens=800\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ê³„ì‚°\n",
    "\n",
    "### 6.1 í† í° ì‚¬ìš©ëŸ‰ ì´í•´í•˜ê¸°\n",
    "\n",
    "OpenAI APIëŠ” í† í° ë‹¨ìœ„ë¡œ ê³¼ê¸ˆë©ë‹ˆë‹¤. í† í°ì€ í…ìŠ¤íŠ¸ì˜ ì‘ì€ ë‹¨ìœ„ë¡œ, ì˜ì–´ëŠ” ì•½ 4ìë‹¹ 1í† í°, í•œê¸€ì€ ì•½ 1-2ìë‹¹ 1í† í°ì…ë‹ˆë‹¤.\n",
    "\n",
    "**í† í° êµ¬ì„±**\n",
    "- **prompt_tokens**: ì…ë ¥ í† í° (system + user ë©”ì‹œì§€)\n",
    "- **completion_tokens**: ì¶œë ¥ í† í° (assistant ì‘ë‹µ)\n",
    "- **total_tokens**: ì „ì²´ í† í° (ì…ë ¥ + ì¶œë ¥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# ì˜ˆì œ: í† í° ì‚¬ìš©ëŸ‰ í™•ì¸\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# í† í° ì‚¬ìš©ëŸ‰ í™•ì¸\n",
    "usage = response.usage\n",
    "print(f\"ì…ë ¥ í† í°: {usage.prompt_tokens}\")\n",
    "print(f\"ì¶œë ¥ í† í°: {usage.completion_tokens}\")\n",
    "print(f\"ì´ í† í°: {usage.total_tokens}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# ë¹„ìš© ê³„ì‚° (2025ë…„ 1ì›” ê¸°ì¤€ ì˜ˆì‹œ ê°€ê²©)\n",
    "# gpt-4.1-mini: ì…ë ¥ $0.075 / 1M tokens, ì¶œë ¥ $0.300 / 1M tokens\n",
    "input_cost = (usage.prompt_tokens / 1_000_000) * 0.075\n",
    "output_cost = (usage.completion_tokens / 1_000_000) * 0.300\n",
    "total_cost = input_cost + output_cost\n",
    "\n",
    "print(f\"ì…ë ¥ ë¹„ìš©: ${input_cost:.6f}\")\n",
    "print(f\"ì¶œë ¥ ë¹„ìš©: ${output_cost:.6f}\")\n",
    "print(f\"ì´ ë¹„ìš©: ${total_cost:.6f}\")\n",
    "print(f\"ì´ ë¹„ìš© (ì›í™”): ì•½ {total_cost * 1500:.4f}ì›\")\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nìµœì‹  ê°€ê²© ì •ë³´ëŠ” https://openai.com/api/pricing ì—ì„œ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. ì‹¤ìŠµ ë¬¸ì œ\n",
    "\n",
    "**ë¬¸ì œ 1: ì–¸ì–´ ë²ˆì—­ê¸° ë§Œë“¤ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(text, target_language):\n",
    "    # íŒíŠ¸:\n",
    "    # 1. OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "    # 2. system ë©”ì‹œì§€ë¡œ ë²ˆì—­ê¸° ì—­í•  ì •ì˜\n",
    "    # 3. user ë©”ì‹œì§€ë¡œ ë²ˆì—­í•  í…ìŠ¤íŠ¸ì™€ ëª©í‘œ ì–¸ì–´ ì „ë‹¬\n",
    "    # 4. ì‘ë‹µ ë°˜í™˜\n",
    "    \n",
    "    \n",
    "    return \n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "result = translator(\"ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”!\", \"ì˜ì–´\")\n",
    "print(result)  # ì˜ˆìƒ ì¶œë ¥: Hello, the weather is nice today!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ë¬¸ì œ 2: ê°ì • ë¶„ì„ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    # íŒíŠ¸:\n",
    "    # 1. OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "    # 2. response_formatì— json_schema ì •ì˜\n",
    "    # 3. sentimentì™€ confidence í•„ë“œë¥¼ í¬í•¨í•˜ëŠ” ìŠ¤í‚¤ë§ˆ ì‘ì„±\n",
    "    # 4. JSON ì‘ë‹µ íŒŒì‹±í•˜ì—¬ ë°˜í™˜\n",
    "    \n",
    "\n",
    "    return \n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "result = analyze_sentiment(\"ì˜¤ëŠ˜ ì‹œí—˜ì„ ì˜ ë´¤ì–´ìš”! ì •ë§ ê¸°ì©ë‹ˆë‹¤.\")\n",
    "print(result)\n",
    "# ì˜ˆìƒ ì¶œë ¥: {'sentiment': 'positive', 'confidence': 0.95}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. OpenAI ë‹¤ì–‘í•œ API í™œìš©\n",
    "\n",
    "### 8.1 Embeddings API - í…ìŠ¤íŠ¸ ì„ë² ë”©\n",
    "\n",
    "í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰, í´ëŸ¬ìŠ¤í„°ë§, ë¶„ë¥˜ ë“±ì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ìš©ë„**\n",
    "- ë¬¸ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "- ì‹œë§¨í‹± ê²€ìƒ‰ (ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰)\n",
    "- ì¶”ì²œ ì‹œìŠ¤í…œ\n",
    "- í…ìŠ¤íŠ¸ ë¶„ë¥˜ ë° í´ëŸ¬ìŠ¤í„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜\n",
    "texts = [\n",
    "    \"íŒŒì´ì¬ì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.\",\n",
    "    \"Python is a programming language.\",\n",
    "    \"ì‚¬ê³¼ëŠ” ê³¼ì¼ì…ë‹ˆë‹¤.\",\n",
    "    \"Apple is a fruit.\"\n",
    "]\n",
    "\n",
    "# ì„ë² ë”© ìƒì„±\n",
    "embeddings = []\n",
    "for text in texts:\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",  # ë˜ëŠ” \"text-embedding-3-large\"\n",
    "        input=text\n",
    "    )\n",
    "    embeddings.append(response.data[0].embedding)\n",
    "\n",
    "# ë²¡í„° ì°¨ì› í™•ì¸\n",
    "print(f\"ì„ë² ë”© ë²¡í„° ì°¨ì›: {len(embeddings[0])}\")\n",
    "print(f\"ì²« 10ê°œ ê°’: {embeddings[0][:10]}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# ìœ ì‚¬ë„ ë¹„êµ\n",
    "print(\"\\nğŸ“Š ìœ ì‚¬ë„ ë¶„ì„:\")\n",
    "print(f\"'{texts[0]}' vs '{texts[1]}': {cosine_similarity(embeddings[0], embeddings[1]):.4f}\")\n",
    "print(f\"'{texts[0]}' vs '{texts[2]}': {cosine_similarity(embeddings[0], embeddings[2]):.4f}\")\n",
    "print(f\"'{texts[2]}' vs '{texts[3]}': {cosine_similarity(embeddings[2], embeddings[3]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Moderation API - ì½˜í…ì¸  ê²€ì—´\n",
    "\n",
    "ë¶€ì ì ˆí•œ ì½˜í…ì¸ ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ í•„í„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ê°ì§€ ì¹´í…Œê³ ë¦¬**\n",
    "- í­ë ¥ì ì¸ ì½˜í…ì¸ \n",
    "- í˜ì˜¤ ë°œì–¸\n",
    "- ì„±ì ì¸ ì½˜í…ì¸ \n",
    "- ìí•´ ê´€ë ¨ ë‚´ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# ì½˜í…ì¸  ê²€ì—´ ì˜ˆì œ\n",
    "texts_to_check = [\n",
    "    \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”!\",\n",
    "    \"I want to hurt someone\",  # ë¶€ì ì ˆí•œ ì˜ˆì‹œ\n",
    "]\n",
    "\n",
    "for text in texts_to_check:\n",
    "    response = client.moderations.create(\n",
    "        model=\"omni-moderation-latest\",  # ë˜ëŠ” \"text-moderation-latest\"\n",
    "        input=text\n",
    "    )\n",
    "    \n",
    "    result = response.results[0]\n",
    "    print(f\"\\ní…ìŠ¤íŠ¸: {text}\")\n",
    "    print(f\"ìœ„ë°˜ ì—¬ë¶€: {result.flagged}\")\n",
    "    \n",
    "    if result.flagged:\n",
    "        print(\"ê°ì§€ëœ ì¹´í…Œê³ ë¦¬:\")\n",
    "        categories = result.categories\n",
    "        for category, flagged in vars(categories).items():\n",
    "            if flagged:\n",
    "                print(f\"  - {category}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Function Calling - í•¨ìˆ˜ í˜¸ì¶œ\n",
    "\n",
    "LLMì´ ì™¸ë¶€ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ë™ì ì¸ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ì‚¬ìš© ì‚¬ë¡€**\n",
    "- API í˜¸ì¶œ (ë‚ ì”¨, ì£¼ì‹ ì •ë³´ ë“±)\n",
    "- ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬\n",
    "- ê³„ì‚° ìˆ˜í–‰\n",
    "- ì™¸ë¶€ ë„êµ¬ ì—°ë™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# 1. í•¨ìˆ˜ ì •ì˜ (ì‹¤ì œ ì‹¤í–‰ë  í•¨ìˆ˜)\n",
    "def get_current_weather(location, unit=\"celsius\"):\n",
    "    \"\"\"ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ì˜ˆì‹œ)\"\"\"\n",
    "    # ì‹¤ì œë¡œëŠ” ë‚ ì”¨ APIë¥¼ í˜¸ì¶œí•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ë”ë¯¸ ë°ì´í„° ë°˜í™˜\n",
    "    weather_data = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"22\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": \"ë§‘ìŒ\"\n",
    "    }\n",
    "    return json.dumps(weather_data, ensure_ascii=False)\n",
    "\n",
    "# 2. í•¨ìˆ˜ ìŠ¤í‚¤ë§ˆ ì •ì˜ (LLMì—ê²Œ ì•Œë ¤ì¤„ í•¨ìˆ˜ ì •ë³´)\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"íŠ¹ì • ìœ„ì¹˜ì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ë„ì‹œëª… (ì˜ˆ: ì„œìš¸, ë¶€ì‚°)\"\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"ì˜¨ë„ ë‹¨ìœ„\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# 3. LLMì—ê²Œ ì§ˆë¬¸\n",
    "messages = [{\"role\": \"user\", \"content\": \"ì„œìš¸ì˜ ë‚ ì”¨ê°€ ì–´ë•Œ?\"}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"  # LLMì´ ìë™ìœ¼ë¡œ í•¨ìˆ˜ í˜¸ì¶œ ì—¬ë¶€ ê²°ì •\n",
    ")\n",
    "\n",
    "# 4. LLMì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ë ¤ê³  í•˜ëŠ”ì§€ í™•ì¸\n",
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "\n",
    "if tool_calls:\n",
    "    # 5. í•¨ìˆ˜ ì‹¤í–‰\n",
    "    available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "    }\n",
    "    \n",
    "    messages.append(response_message)\n",
    "    \n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        print(f\"ğŸ”§ í•¨ìˆ˜ í˜¸ì¶œ: {function_name}\")\n",
    "        print(f\"   ì¸ì: {function_args}\")\n",
    "        \n",
    "        # ì‹¤ì œ í•¨ìˆ˜ ì‹¤í–‰\n",
    "        function_response = function_to_call(**function_args)\n",
    "        print(f\"   ê²°ê³¼: {function_response}\")\n",
    "        \n",
    "        # 6. í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ LLMì—ê²Œ ì „ë‹¬\n",
    "        messages.append({\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response,\n",
    "        })\n",
    "    \n",
    "    # 7. ìµœì¢… ì‘ë‹µ ìƒì„±\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    print(\"\\nğŸ’¬ ìµœì¢… ì‘ë‹µ:\")\n",
    "    print(final_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Streaming - ì‹¤ì‹œê°„ ì‘ë‹µ\n",
    "\n",
    "ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ ì‚¬ìš©ì ê²½í—˜ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì¥ì **\n",
    "- ë¹ ë¥¸ ì´ˆê¸° ì‘ë‹µ (First Token Time ë‹¨ì¶•)\n",
    "- ChatGPTì²˜ëŸ¼ ì ì§„ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ ìƒì„±\n",
    "- ì‚¬ìš©ìì—ê²Œ ì¦‰ê°ì ì¸ í”¼ë“œë°± ì œê³µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "print(\"ğŸ’¬ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ:\\n\")\n",
    "\n",
    "# stream=Trueë¡œ ì„¤ì •í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"ì¸ê³µì§€ëŠ¥ì˜ ì—­ì‚¬ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"}],\n",
    "    stream=True  # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”\n",
    ")\n",
    "\n",
    "# ì‹¤ì‹œê°„ìœ¼ë¡œ í† í°ì„ ë°›ì•„ì„œ ì¶œë ¥\n",
    "for chunk in stream:\n",
    "    # deltaì— contentê°€ ìˆìœ¼ë©´ ì¶œë ¥\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\\nâœ… ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "001-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
