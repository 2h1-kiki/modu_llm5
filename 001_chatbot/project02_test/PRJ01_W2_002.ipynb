{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97af8bf8",
   "metadata": {},
   "source": [
    "RAG의 기본 개념 / 문서 전처리 과정의 이해\n",
    "\n",
    "학습 목표\n",
    "- RAG(Retrieval-Augmented Generation)의 기본 개념 이해\n",
    "- 문서 로딩, 청크 분할, 임베딩, 벡터 저장 과정 실습\n",
    "- LangChain을 활용한 RAG 파이프 라인 구축\n",
    "- 검색 기반 질의 응답 시스템 구현\n",
    "\n",
    "1. RAG 개념 및 아키텍처\n",
    "\t- Rag란?\n",
    "\t\t- RAG(Rentrieval-Augmented Generation)는 기존 LLM의 한계를 보완하기 위한 방법론\n",
    "\t\t\t- 문제점 : LLM은 훈련 시점의 고정된 데이터에만 의존\n",
    "\t\t\t- 해결책 : 외부 지식 베이스를 동적으로 검색하여 응답 생성 시 활용\n",
    "\t\t\t- 장점 : 최신 정보, 도메인 특화 지식, 사실 기반 응답 가능\n",
    "\n",
    "\t- RAG의 핵심 구성요서\n",
    "\t\t1. 검색(Retrieval) 시스템\n",
    "\t\t\t- 임베딩 모델 : 텍스트를 벡터로 변환\n",
    "\t\t\t- 벡터 데이터베이스 : 임베딩 벡터 저장 및 인덱싱\n",
    "\t\t\t- 유사도 검색 : 코사인 유사도, 유클리 거리 등\n",
    "\n",
    "\t\t2. 증강(Augmentation)\n",
    "\t\t\t- 검색된 문서 전처리 및 포맷팅\n",
    "\t\t\t- 프롬프트 엔지니어링\n",
    "\t\t\t- 컨텍스트 길이 관리\n",
    "\t\t\n",
    "\t\t3. 생성(Generation)\n",
    "\t\t\t- LLM을 통한 최종 응답 생성\n",
    "\t\t\t- 검색된 컨텍스트와 원본 질의 결합\n",
    "\n",
    "2. 최신 LangChain을 활용한 RAG구현\n",
    "\t- step1. Indexing\n",
    "\t\t1. 문서 수집 및 전처리\n",
    "\t\t2. 문서 청크 분할\n",
    "\t\t3. 임베딩 생성\n",
    "\t\t4. 벡터 저장소 구축\n",
    "\n",
    "\t- 문서 청크 분할(Split Texts)\n",
    "\t\t- 불러온 데이터를 작은 크기의 단위 chunk로 분할하는 과정\n",
    "\t\t- 자연어 처리(NLP) 기술을 활용하여 큰 문서를 처리가 쉽도록 문단, 문장 또는 구 단위로 나누는 작업\n",
    "\t\t- 검색 효율성을 높이기 위한 중요한 과정\n",
    "\t\t\t1. 청크 크기 선택\n",
    "\t\t\t\t- 너무 작은 청크 : 문맥 손실\n",
    "\t\t\t\t- 너무 큰 청크 : 관련성 저하\n",
    "\t\t\t2. 중복 영역 설정\n",
    "\t\t\t\t- 문맥 유지를 위해 필요\n",
    "\t\t\t\t- 일반적으로 10-20% 권장\n",
    "\t\t- LangChain기본 Text Splitter종류\n",
    "\t\t\t- `RecursiveCharacterTextSplitter`\n",
    "\t\t\t\t- 여러 구분자를 우선순위대로 시도하여 문서를 자연스럽게 분할\n",
    "\t\t\t\t- 기본 구분자 순서 : `[\"\\n\\n\", \"\\n\", \" \", \"\"]`\n",
    "\t\t\t\t- 대부분의 경우에 가장 좋은 성능을 보임\n",
    "\t\t\t- `CharacterTextSplitter`\n",
    "\t\t\t\t- 단일 구분자로만 분할 (예: `\\n\\n`)\n",
    "\t\t\t\t- 간단한 경우에 사용\n",
    "\t\t- `chunk_size`\n",
    "\t\t\t- 엄격한 최대값이 아닌 목표값이기 때문에 `Created a chunk of size 9814, which is longer than the specified 1000`경고 나타날 수 있다.\n",
    "\t\t\t- `separator=\"\\n\\n\"`로 문단 단위로 분할하기 때문에 하나의 문단이 `chunk_size`보다 크면 그대로 유지 된다.\n",
    "\t\t\t- 이는 문맥을 유지하기 위한 의도된 동작입니다.\n",
    "\n",
    "3. 문서 임베딩 생성(Document Embeddings)\n",
    "\t- 임베딩 모델을 사용하여 텍스트를 벡터로 변환\n",
    "\t- 임베딩을 기반으로 유사성 검색에 사용\n",
    "\t- 임베딩 모델 선택\n",
    "\t\t- 성능가 비용 고려\n",
    "\t\t- 다국어 지원 여부 확인\n",
    "\n",
    "4. 백터 저장소 구축 (Vectorstores)\n",
    "\t- 임베딩 벡터를 벡터저장소에 저장\n",
    "\t- 저장된 임베딩을 기반으로 유사성 검색을 수행하는데 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f2402ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 0 ==========\n",
      "title: \"그래서 AGI 왔다고?\"…오픈AI 올트먼, X에 오묘한 메시지\n",
      "len: 1507\n",
      "\"그래서 AGI 왔다고?\"…오픈AI 올트먼, X에 오묘한 메시지\n",
      "NAVER\n",
      "뉴스\n",
      "엔터\n",
      "스포츠\n",
      "날씨\n",
      "프리미엄\n",
      "검색\n",
      "언론사별\n",
      "정치\n",
      "경제\n",
      "사회\n",
      "생활/문화\n",
      "IT/과학\n",
      "세계\n",
      "신문보기\n",
      "오피니언\n",
      "TV\n",
      "팩트체크\n",
      "알고리즘 안내\n",
      "정정보도 모음\n",
      "디지털타임스\n",
      "디지털타임스\n",
      "보러가기\n",
      "닫기\n",
      "닫기\n",
      "PICK\n",
      "안내\n",
      "언론사가 주요기사로선정한 기사입니다.\n",
      "언론사별 바로가기\n",
      "닫기\n",
      "\"그래서 AGI 왔다고?\"…오픈AI 올트먼, X에 오묘한 메시지\n",
      "입력\n",
      "2025.01.05. 오후 5:48\n",
      "수정\n",
      "2025.01.05. 오후 5:50\n",
      "기사원문\n",
      "추천\n",
      "반응\n",
      "쏠쏠정보\n",
      "0\n",
      "흥미진진\n",
      "0\n",
      "공감백배\n",
      "0\n",
      "분석탁월\n",
      "0\n",
      "후속강추\n",
      "0\n",
      "댓글\n",
      "반응\n",
      "텍스트 음성 변환 서비스 사용하기\n",
      "성별\n",
      "남성\n",
      "여성\n",
      "말하기 속도\n",
      "느림\n",
      "보통\n",
      "빠름\n",
      "이동 통신망을 이용하여 음성을 재생하면 별도의 데이터\n",
      "========= 1 ==========\n",
      "title: AI에 진심인 MS, 1년간 데이터센터에 118兆 붓는다\n",
      "len: 2623\n",
      "AI에 진심인 MS, 1년간 데이터센터에 118兆 붓는다\n",
      "NAVER\n",
      "뉴스\n",
      "엔터\n",
      "스포츠\n",
      "날씨\n",
      "프리미엄\n",
      "검색\n",
      "언론사별\n",
      "정치\n",
      "경제\n",
      "사회\n",
      "생활/문화\n",
      "IT/과학\n",
      "세계\n",
      "신문보기\n",
      "오피니언\n",
      "TV\n",
      "팩트체크\n",
      "알고리즘 안내\n",
      "정정보도 모음\n",
      "지디넷코리아\n",
      "지디넷코리아\n",
      "보러가기\n",
      "닫기\n",
      "닫기\n",
      "PICK\n",
      "안내\n",
      "언론사가 주요기사로선정한 기사입니다.\n",
      "언론사별 바로가기\n",
      "닫기\n",
      "AI에 진심인 MS, 1년간 데이터센터에 118兆 붓는다\n",
      "장유미 기자\n",
      "입력\n",
      "2025.01.05. 오후 2:31\n",
      "기사원문\n",
      "추천\n",
      "반응\n",
      "쏠쏠정보\n",
      "0\n",
      "흥미진진\n",
      "0\n",
      "공감백배\n",
      "0\n",
      "분석탁월\n",
      "0\n",
      "후속강추\n",
      "0\n",
      "댓글\n",
      "반응\n",
      "텍스트 음성 변환 서비스 사용하기\n",
      "성별\n",
      "남성\n",
      "여성\n",
      "말하기 속도\n",
      "느림\n",
      "보통\n",
      "빠름\n",
      "이동 통신망을 이용하여 음성을 재생하면 별도의 데이터 통화료가 부과될 수 있습니다.\n",
      "본문듣기 시\n",
      "========= 2 ==========\n",
      "title: \"게임 만들 사람 줄어도 괜찮아\" AI가 책임진다\n",
      "len: 2637\n",
      "\"게임 만들 사람 줄어도 괜찮아\" AI가 책임진다\n",
      "NAVER\n",
      "뉴스\n",
      "엔터\n",
      "스포츠\n",
      "날씨\n",
      "프리미엄\n",
      "검색\n",
      "언론사별\n",
      "정치\n",
      "경제\n",
      "사회\n",
      "생활/문화\n",
      "IT/과학\n",
      "세계\n",
      "신문보기\n",
      "오피니언\n",
      "TV\n",
      "팩트체크\n",
      "알고리즘 안내\n",
      "정정보도 모음\n",
      "머니투데이\n",
      "머니투데이\n",
      "보러가기\n",
      "닫기\n",
      "닫기\n",
      "\"게임 만들 사람 줄어도 괜찮아\" AI가 책임진다\n",
      "최우영 기자\n",
      "TALK\n",
      "입력\n",
      "2025.01.04. 오전 9:01\n",
      "수정\n",
      "2025.01.04. 오전 9:01\n",
      "기사원문\n",
      "추천\n",
      "반응\n",
      "쏠쏠정보\n",
      "0\n",
      "흥미진진\n",
      "0\n",
      "공감백배\n",
      "0\n",
      "분석탁월\n",
      "0\n",
      "후속강추\n",
      "0\n",
      "댓글\n",
      "반응\n",
      "텍스트 음성 변환 서비스 사용하기\n",
      "성별\n",
      "남성\n",
      "여성\n",
      "말하기 속도\n",
      "느림\n",
      "보통\n",
      "빠름\n",
      "이동 통신망을 이용하여 음성을 재생하면 별도의 데이터 통화료가 부과될 수 있습니다.\n",
      "본문듣기 시작\n",
      "닫기\n",
      "글자 크기 변경하기\n",
      "글자크기\n",
      "가1단\n"
     ]
    }
   ],
   "source": [
    "# 최신 LangChain을 활용한 RAG구현 - 1. 문서 수집 및 전처리\n",
    "# 1. 문서 데이터 로드 (Load Data)\n",
    "# \t- RAG에 사용할 데이터를 불러오는 단계 (검색에 사용될 지식이나 정보)\n",
    "# \t- 외부 데이터 소스에서 정보를 수집하고, 필요한 형식으로 변환하여 시스템에 로드\n",
    "import re\n",
    "from langchain_community.document_loaders import WebBaseLoader # Data Loader - 웹페이지 데이터 가져오기\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 1단계: 데이터 준비 - 웹문서 검색을 위해 관련 URL 가져오기\n",
    "web_urls = [\n",
    "    \"https://n.news.naver.com/mnews/article/029/0002927209\",\n",
    "    \"https://n.news.naver.com/mnews/article/092/0002358620\",\n",
    "    \"https://n.news.naver.com/mnews/article/008/0005136824\",\n",
    "]\n",
    "\n",
    "\n",
    "# 2단계: WebBaseLoader를 사용해 텍스트 로드\n",
    "\"\"\"\n",
    "힌트:\n",
    "- WebBaseLoader를 사용하여 web_urls의 문서들을 로드하세요\n",
    "- loader.load()를 호출하여 Document 객체 리스트를 얻습니다\n",
    "- 로드된 문서의 개수를 출력하여 확인하세요\n",
    "\n",
    "기대 출력:\n",
    "- 로드된 문서 개수: 3개 (URL 개수와 동일)\n",
    "\"\"\"\n",
    "loader = WebBaseLoader(web_urls)\n",
    "\n",
    "# 웹페이지 텍스트 > Document 객체로 변환\n",
    "docs = loader.load()\n",
    "\n",
    "# 라인 제거\n",
    "def remove_boilerplate_lines(text: str) -> str:\n",
    "    lines = []\n",
    "    for line in text.splitlines():\n",
    "        s = line.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "\n",
    "        # 기자 이메일 라인 제거 (예: 장유미 기자(sweet@zdnet.co.kr))\n",
    "        if re.search(r\"기자.*\\([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\)\", s):\n",
    "            continue\n",
    "\n",
    "        # 저작권/무단전재/재배포/AI 학습 금지 제거\n",
    "        if any(k in s for k in [\"Copyright\", \"All rights reserved\", \"무단 전재\", \"재배포\", \"AI 학습 이용 금지\"]):\n",
    "            continue\n",
    "\n",
    "        # 네이버 공통 UI/메뉴/정책/구독 블록 제거(필요하면 계속 추가)\n",
    "        if any(k in s for k in [\n",
    "            \"본문 바로가기\", \"구독\", \"댓글 정책\", \"랭킹\", \"많이 본 뉴스\", \"이슈 NOW\", \"기사 섹션\"\n",
    "        ]):\n",
    "            continue\n",
    "\n",
    "        lines.append(s)\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# docs 정제하기\n",
    "def clean_newlines(text: str) -> str:\n",
    "    # 1) NBSP 같은 특수 공백 제거\n",
    "    text = text.replace(\"\\xa0\", \" \")\n",
    "\n",
    "    # 2) 줄 끝 공백 제거\n",
    "    text = re.sub(r\"[ \\t]+\\n\", \"\\n\", text)\n",
    "\n",
    "    # 3) 너무 많은 줄바꿈을 \"문단 경계\"로 통일\n",
    "    #    - 핵심: separator=\"\\n\\n\"가 의미를 가지게 만드는 것\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "\n",
    "    # 4) 공백 과다 압축\n",
    "    text = re.sub(r\"[ \\t]{2,}\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def trim_naver_article(text: str) -> str:\n",
    "    end_markers = [\n",
    "        \"Copyright\", \"All rights reserved\", \"무단 전재\", \"언론사홈\", \"많이 본 뉴스\", \"댓글 정책\", \"랭킹 뉴스\",\n",
    "        \"이슈 NOW\", \"함께 볼만한 뉴스\", \"기자 프로필\", \"기사 섹션 분류 안내\"\n",
    "    ]\n",
    "    for marker in end_markers:\n",
    "        idx = text.find(marker)\n",
    "        if idx != -1 and idx > 0:\n",
    "            text = text[:idx]\n",
    "            break\n",
    "    return text.strip()\n",
    "\n",
    "clean_docs = [\n",
    "    Document(\n",
    "        page_content=remove_boilerplate_lines(\n",
    "            trim_naver_article(\n",
    "                clean_newlines(doc.page_content)\n",
    "            )\n",
    "        ),\n",
    "        metadata=doc.metadata\n",
    "    )\n",
    "    for doc in docs\n",
    "]\n",
    "\n",
    "# 출력 : 로드된 문서 개수: 3개 (URL 개수와 동일)\n",
    "# print(f\"Document: {docs}\")\n",
    "# print(f\"Document: {docs}\")\n",
    "# print(f\"Document 개수: {len(docs)}\")\n",
    "\n",
    "for idx, doc in enumerate(clean_docs):\n",
    "    print(f\"========= {idx} ==========\")\n",
    "    print(f\"title: {doc.metadata.get('title')}\")\n",
    "    print(f\"len: {len(doc.page_content)}\")\n",
    "    print(doc.page_content[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "594f5032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- chunk 0 ---\n",
      "source: https://n.news.naver.com/mnews/article/029/0002927209\n",
      "\"그래서 AGI 왔다고?\"…오픈AI 올트먼, X에 오묘한 메시지\n",
      "NAVER\n",
      "뉴스\n",
      "엔터\n",
      "스포츠\n",
      "날씨\n",
      "프리미엄\n",
      "검색\n",
      "언론사별\n",
      "정치\n",
      "경제\n",
      "사회\n",
      "생활/문화\n",
      "IT/과학\n",
      "세계\n",
      "신문보기\n",
      "오피니언\n",
      "TV\n",
      "팩트체크\n",
      "알고리즘 안내\n",
      "정정보도 모음\n",
      "디지털타임스\n",
      "디지털타임스\n",
      "보러가기\n",
      "닫기\n",
      "닫기\n",
      "PICK\n",
      "안내\n",
      "언론사가 주요기사로선정한 기사입니다.\n",
      "언론사별 바로가기\n",
      "닫기\n",
      "\"그래서 AGI 왔다고?\"…오픈AI 올트먼, X에 오묘한 메시지\n",
      "입력\n",
      "2025.01.05. 오후 5:48\n",
      "수정\n",
      "2025.01.05. 오후 5:50\n",
      "기사원문\n",
      "추천\n",
      "반응\n",
      "쏠쏠정보\n",
      "0\n",
      "흥미진진\n",
      "0\n",
      "\n",
      "\n",
      "--- chunk 1 ---\n",
      "source: https://n.news.naver.com/mnews/article/092/0002358620\n",
      "AI에 진심인 MS, 1년간 데이터센터에 118兆 붓는다\n",
      "NAVER\n",
      "뉴스\n",
      "엔터\n",
      "스포츠\n",
      "날씨\n",
      "프리미엄\n",
      "검색\n",
      "언론사별\n",
      "정치\n",
      "경제\n",
      "사회\n",
      "생활/문화\n",
      "IT/과학\n",
      "세계\n",
      "신문보기\n",
      "오피니언\n",
      "TV\n",
      "팩트체크\n",
      "알고리즘 안내\n",
      "정정보도 모음\n",
      "지디넷코리아\n",
      "지디넷코리아\n",
      "보러가기\n",
      "닫기\n",
      "닫기\n",
      "PICK\n",
      "안내\n",
      "언론사가 주요기사로선정한 기사입니다.\n",
      "언론사별 바로가기\n",
      "닫기\n",
      "AI에 진심인 MS, 1년간 데이터센터에 118兆 붓는다\n",
      "장유미 기자\n",
      "입력\n",
      "2025.01.05. 오후 2:31\n",
      "기사원문\n",
      "추천\n",
      "반응\n",
      "쏠쏠정보\n",
      "0\n",
      "흥미진진\n",
      "0\n",
      "공감백배\n",
      "0\n",
      "분석탁월\n",
      "0\n",
      "후속강추\n",
      "0\n",
      "댓글\n",
      "\n",
      "\n",
      "--- chunk 2 ---\n",
      "source: https://n.news.naver.com/mnews/article/008/0005136824\n",
      "\"게임 만들 사람 줄어도 괜찮아\" AI가 책임진다\n",
      "NAVER\n",
      "뉴스\n",
      "엔터\n",
      "스포츠\n",
      "날씨\n",
      "프리미엄\n",
      "검색\n",
      "언론사별\n",
      "정치\n",
      "경제\n",
      "사회\n",
      "생활/문화\n",
      "IT/과학\n",
      "세계\n",
      "신문보기\n",
      "오피니언\n",
      "TV\n",
      "팩트체크\n",
      "알고리즘 안내\n",
      "정정보도 모음\n",
      "머니투데이\n",
      "머니투데이\n",
      "보러가기\n",
      "닫기\n",
      "닫기\n",
      "\"게임 만들 사람 줄어도 괜찮아\" AI가 책임진다\n",
      "최우영 기자\n",
      "TALK\n",
      "입력\n",
      "2025.01.04. 오전 9:01\n",
      "수정\n",
      "2025.01.04. 오전 9:01\n",
      "기사원문\n",
      "추천\n",
      "반응\n",
      "쏠쏠정보\n",
      "0\n",
      "흥미진진\n",
      "0\n",
      "공감백배\n",
      "0\n",
      "분석탁월\n",
      "0\n",
      "후속강추\n",
      "0\n",
      "댓글\n",
      "반응\n",
      "텍스트 음성 변환 서비스 사용하기\n",
      "성별\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter # 문서 청크 분할(Split Texts)\n",
    "\n",
    "# 3단계: CharacterTextSplitter로 문서 분할\n",
    "\"\"\"\n",
    "힌트:\n",
    "- CharacterTextSplitter를 import하세요\n",
    "- chunk_size=500, chunk_overlap=100으로 설정하세요\n",
    "- separator=\"\\n\\n\"로 문단 단위 분할\n",
    "- split_documents() 메서드를 사용하여 문서를 분할하세요\n",
    "- 분할된 청크의 개수를 출력하세요\n",
    "\n",
    "기대 출력:\n",
    "- 분할된 청크 개수: 약 20-40개 (문서 내용에 따라 다를 수 있음)\n",
    "\"\"\"\n",
    "text_splitter = CharacterTextSplitter(\n",
    "\tseparator=\"\\n\\n\",       # 문단 구분자 - 구분자를 기준으로 나눈다.\n",
    "\tchunk_size=500,         # 문단 길이\n",
    "\tchunk_overlap=100,      # 겹치는 길이\n",
    "\tlength_function=len,    # 길이 측정 함수\n",
    "\tis_separator_regex=False,   # separator가 정규식인지 여부\n",
    ")\n",
    "\n",
    "splitted_docs = text_splitter.split_documents(clean_docs)\n",
    "\n",
    "# 초반 청크 확인(필수)\n",
    "for i, d in enumerate(splitted_docs[:10]):\n",
    "    print(f\"\\n--- chunk {i} ---\")\n",
    "    print(\"source:\", d.metadata.get(\"source\"))\n",
    "    print(d.page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5d102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 개수 : 43\n"
     ]
    }
   ],
   "source": [
    "# 글자 수 기준으로 엄격하게 분할하기\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 1000자씩 잘라서 Document로 전환\n",
    "text_splitter = CharacterTextSplitter(\n",
    "\tseparator=\"\",\n",
    "\tchunk_size=1000,\n",
    "\tlength_function=len,\n",
    "\tis_separator_regex=False,\n",
    ")\n",
    "\n",
    "equally_splitted_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Document 개수 : {len(equally_splitted_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0abdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 Document 개수 : 15 / 청크 개수: 15\n"
     ]
    }
   ],
   "source": [
    "# 4단계: 임베딩 및 벡터 저장소 구현\n",
    "\"\"\"\n",
    "힌트:\n",
    "- OpenAIEmbeddings를 사용하여 임베딩 모델을 생성하세요\n",
    "- Chroma 벡터 저장소를 생성하세요\n",
    "- add_documents()를 사용하여 분할된 문서를 벡터 저장소에 추가하세요\n",
    "- 저장된 문서 개수를 확인하세요\n",
    "\n",
    "기대 출력:\n",
    "- 임베딩 모델 생성 완료\n",
    "- 벡터 저장소에 저장된 문서 개수: (3단계의 청크 개수와 동일)\n",
    "\"\"\"\n",
    "import time # 컬렉션 이름을 매번 새로 만들기\n",
    "from langchain_openai import OpenAIEmbeddings # OpenAI Embeddings - 문장 임베딩\n",
    "from langchain_chroma import Chroma # Chroma 백터 저장소에 문서 저장하기\n",
    "\n",
    "\n",
    "# OpenAIEmbeddings를 사용하여 embedding model 생성\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\") # 사용할 모델 이름을 지정 가능\n",
    "# Chroma 벡터 저장소를 생성\n",
    "# time으로 매번 이름을 매번 새롭게 만들기 - 재실행 누적문제로 retriver가 이상해지는걸 크게 줄일 수 있다.\n",
    "vector_store = Chroma(\n",
    "\tcollection_name=f\"naver_news_{int(time.time())}\", \n",
    "\tembedding_function=embedding_model\n",
    ")\n",
    "# add_documents()를 사용하여 분할된 문서를 벡터 저장소에 추가\n",
    "document_ids = vector_store.add_documents(splitted_docs)\n",
    "\n",
    "# 저장된 문서 개수 확인\n",
    "print(f\"저장된 Document 개수 : {len(document_ids)} / 청크 개수: {len(splitted_docs)}\")\n",
    "\n",
    "## chroma 실행 시 Failed to send telemetry event 경고는 Chroma의 사용 통계 수집 기능과 관련된 것으로, 실제 기능에는 영향 주지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40b56437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- hit 0 ---\n",
      "source: https://n.news.naver.com/mnews/article/092/0002358620\n",
      "장유미 기자(sweet@zdnet.co.kr)\n",
      "\n",
      "--- hit 1 ---\n",
      "source: https://n.news.naver.com/mnews/article/029/0002927209\n",
      "\"그래서 AGI 왔다고?\"…오픈AI 올트먼, X에 오묘한 메시지\n",
      "\n",
      "본문 바로가기\n",
      "\n",
      "NAVER\n",
      "\n",
      "뉴스\n",
      "\n",
      "엔터\n",
      "\n",
      "스포츠\n",
      "\n",
      "날씨\n",
      "\n",
      "프리미엄\n",
      "\n",
      "검색\n",
      "\n",
      "언론사별\n",
      "\n",
      "정치\n",
      "\n",
      "경제\n",
      "\n",
      "사회\n",
      "\n",
      "생활/문화\n",
      "\n",
      "IT/과학\n",
      "\n",
      "세계\n",
      "\n",
      "랭킹\n",
      "\n",
      "신문보기\n",
      "\n",
      "오피니언\n",
      "\n",
      "TV\n",
      "\n",
      "팩트체크\n",
      "\n",
      "알고리즘 안내\n",
      "\n",
      "정정보도 모음\n",
      "\n",
      "디지털타임스\n",
      "\n",
      "디지털타임스\n",
      "\n",
      "구독\n",
      "\n",
      "디지털타임스 언론사 구독되었습니다. 메인 뉴스판에서 주요뉴스를 볼 수 있습니다.\n",
      "보러가기\n",
      "닫기\n",
      "\n",
      "디지털타임스 언론사 구독 해지\n",
      "\n",
      "--- hit 2 ---\n",
      "source: https://n.news.naver.com/mnews/article/029/0002927209\n",
      "김나인 기자(silkni@dt.co.kr)\n",
      "\n",
      "--- hit 3 ---\n",
      "source: https://n.news.naver.com/mnews/article/008/0005136824\n",
      "\"게임 만들 사람 줄어도 괜찮아\" AI가 책임진다\n",
      "\n",
      "본문 바로가기\n",
      "\n",
      "NAVER\n",
      "\n",
      "뉴스\n",
      "\n",
      "엔터\n",
      "\n",
      "스포츠\n",
      "\n",
      "날씨\n",
      "\n",
      "프리미엄\n",
      "\n",
      "검색\n",
      "\n",
      "언론사별\n",
      "\n",
      "정치\n",
      "\n",
      "경제\n",
      "\n",
      "사회\n",
      "\n",
      "생활/문화\n",
      "\n",
      "IT/과학\n",
      "\n",
      "세계\n",
      "\n",
      "랭킹\n",
      "\n",
      "신문보기\n",
      "\n",
      "오피니언\n",
      "\n",
      "TV\n",
      "\n",
      "팩트체크\n",
      "\n",
      "알고리즘 안내\n",
      "\n",
      "정정보도 모음\n",
      "\n",
      "머니투데이\n",
      "\n",
      "머니투데이\n",
      "\n",
      "구독\n",
      "\n",
      "머니투데이 언론사 구독되었습니다. 메인 뉴스판에서 주요뉴스를 볼 수 있습니다.\n",
      "보러가기\n",
      "닫기\n",
      "\n",
      "머니투데이 언론사 구독 해지되었습니다.\n",
      "닫기\n",
      "\n",
      "\"\n",
      "\n",
      "--- hit 4 ---\n",
      "source: https://n.news.naver.com/mnews/article/092/0002358620\n",
      "AI에 진심인 MS, 1년간 데이터센터에 118兆 붓는다\n",
      "\n",
      "본문 바로가기\n",
      "\n",
      "NAVER\n",
      "\n",
      "뉴스\n",
      "\n",
      "엔터\n",
      "\n",
      "스포츠\n",
      "\n",
      "날씨\n",
      "\n",
      "프리미엄\n",
      "\n",
      "검색\n",
      "\n",
      "언론사별\n",
      "\n",
      "정치\n",
      "\n",
      "경제\n",
      "\n",
      "사회\n",
      "\n",
      "생활/문화\n",
      "\n",
      "IT/과학\n",
      "\n",
      "세계\n",
      "\n",
      "랭킹\n",
      "\n",
      "신문보기\n",
      "\n",
      "오피니언\n",
      "\n",
      "TV\n",
      "\n",
      "팩트체크\n",
      "\n",
      "알고리즘 안내\n",
      "\n",
      "정정보도 모음\n",
      "\n",
      "지디넷코리아\n",
      "\n",
      "지디넷코리아\n",
      "\n",
      "구독\n",
      "\n",
      "지디넷코리아 언론사 구독되었습니다. 메인 뉴스판에서 주요뉴스를 볼 수 있습니다.\n",
      "보러가기\n",
      "닫기\n",
      "\n",
      "지디넷코리아 언론사 구독 해지되었습니\n",
      "\n",
      "--- hit 5 ---\n",
      "source: https://n.news.naver.com/mnews/article/008/0005136824\n",
      "추천\n",
      "반응\n",
      "\n",
      "쏠쏠정보\n",
      "0\n",
      "\n",
      "흥미진진\n",
      "0\n",
      "\n",
      "공감백배\n",
      "0\n",
      "\n",
      "분석탁월\n",
      "0\n",
      "\n",
      "후속강추\n",
      "0\n",
      "\n",
      "댓글\n",
      "반응\n",
      "\n",
      "텍스트 음성 변환 서비스 사용하기\n",
      "\n",
      "성별\n",
      "남성\n",
      "여성\n",
      "\n",
      "말하기 속도\n",
      "느림\n",
      "보통\n",
      "빠름\n",
      "\n",
      "이동 통신망을 이용하여 음성을 재생하면 별도의 데이터 통화료가 부과될 수 있습니다.\n",
      "본문듣기 시작\n",
      "\n",
      "닫기\n",
      "\n",
      "글자 크기 변경하기\n",
      "\n",
      "글자크기\n",
      "\n",
      "가1단계\n",
      "작게\n",
      "\n",
      "가2단계\n",
      "보통\n",
      "\n",
      "가3단계\n",
      "크게\n",
      "\n",
      "가4단계\n",
      "아주크게\n",
      "\n",
      "가5단계\n",
      "최대크게\n",
      "\n",
      "닫기\n",
      "\n",
      "SNS 보내기\n",
      "\n",
      "인쇄하기\n",
      "\n",
      "[게임\n",
      "\n",
      "--- hit 6 ---\n",
      "source: https://n.news.naver.com/mnews/article/092/0002358620\n",
      "추천\n",
      "반응\n",
      "\n",
      "쏠쏠정보\n",
      "0\n",
      "\n",
      "흥미진진\n",
      "0\n",
      "\n",
      "공감백배\n",
      "0\n",
      "\n",
      "분석탁월\n",
      "0\n",
      "\n",
      "후속강추\n",
      "0\n",
      "\n",
      "댓글\n",
      "반응\n",
      "\n",
      "텍스트 음성 변환 서비스 사용하기\n",
      "\n",
      "성별\n",
      "남성\n",
      "여성\n",
      "\n",
      "말하기 속도\n",
      "느림\n",
      "보통\n",
      "빠름\n",
      "\n",
      "이동 통신망을 이용하여 음성을 재생하면 별도의 데이터 통화료가 부과될 수 있습니다.\n",
      "본문듣기 시작\n",
      "\n",
      "닫기\n",
      "\n",
      "글자 크기 변경하기\n",
      "\n",
      "글자크기\n",
      "\n",
      "가1단계\n",
      "작게\n",
      "\n",
      "가2단계\n",
      "보통\n",
      "\n",
      "가3단계\n",
      "크게\n",
      "\n",
      "가4단계\n",
      "아주크게\n",
      "\n",
      "가5단계\n",
      "최대크게\n",
      "\n",
      "닫기\n",
      "\n",
      "SNS 보내기\n",
      "\n",
      "인쇄하기\n",
      "\n",
      "--- hit 7 ---\n",
      "source: https://n.news.naver.com/mnews/article/008/0005136824\n",
      "게임 콘텐츠 '발 번역'의 대표 사례인 마이트 앤 매직6. /사진=마이트 앤 매직6AI(인공지능)가 일상 곳곳에 침투하는 시대, 게임도 예외는 아니다. 단순 반복 작업부터 창의성이 요구되는 영역까지 AI가 사람을 대체하는 사례가 늘고 있다. 중소형 제작사들은 AI를 활용해 부족한 인적 자원을 보완하며 양산형 게임을 말 그대로 '찍어내고' 있다. AI의 활약은 게임 개발 속도를 줄이고 질적 수준을 높이는 일등공신이지만, 동시에 게임산업 종사자들의\n",
      "\n",
      "--- hit 8 ---\n",
      "source: https://n.news.naver.com/mnews/article/008/0005136824\n",
      "AI NPC 이야기를 그린 웹툰 '태백: 튜토리얼 맨'. /사진=네이버웹툰게임 속 NPC는 개발자가 미리 입력해놓은 대화만 하는 게 과거의 문법이었다. 이젠 AI NPC가 상황에 맞춰 매번 새로운 말을 만들어내고, 이용자와 상호작용하는 시대가 되고 있다. 챗GPT나 제미나이 같은 대화형 AI를 게임에 그대로 구현하는 것이다.중국 넷이즈의 '역수한' 시리즈가 AI NPC를 이미 도입해 선보이고 있다. 국내에서도 넥슨, 크래프톤, 엔씨소프트, 넷마\n",
      "\n",
      "--- hit 9 ---\n",
      "source: https://n.news.naver.com/mnews/article/008/0005136824\n",
      "레벨 테스트에 AI를 적극 활용한 퍼즐게임 퍼즈업 아미토이. /사진=엔씨소프트코딩은 생성형 AI가 사람을 돕는 대표적인 분야다. 게임 역시 수많은 코딩 작업이 필요한데, AI는 여기 드는 시간과 인력을 대폭 줄여주는 역할을 하고 있다. '판교의 등대' '구로의 등대'처럼 밤새 건물 전체에서 야근을 진행하며 사람을 갈아넣던 과거의 개발 방식이 근본적으로 변할 수 있는 단초가 마련되는 셈이다.내부 테스트 역시 마찬가지다. 개발 과정에서 파악하지 못\n",
      "0 https://n.news.naver.com/mnews/article/092/0002358620\n",
      "브래드 스미스, 자사 블로그서 투자 계획 밝혀…MS, 엔비디아 칩 구매도 경쟁사보다 2배 多최근 인공지능(AI) 핵심 인프라인 데이터센터에 대한 미국 빅테크들의 투자가 쏟아지는 가운데 마이크로소프트(MS)가 올해도 대규모 자금을 투입해 주도권 잡기에 속도를 낸다.5일 업계에 따르면 브래드 스미스 MS 부회장은 지난 3일 자사 블로그를 통해 AI 기술 구현을 위한 데이터센터에 연간 800억 달러(약 117조7천600억원)를 투자한다고 발표했다. \n",
      "1 https://n.news.naver.com/mnews/article/092/0002358620\n",
      "AI에 진심인 MS, 1년간 데이터센터에 118兆 붓는다\n",
      "\n",
      "본문 바로가기\n",
      "\n",
      "NAVER\n",
      "\n",
      "뉴스\n",
      "\n",
      "엔터\n",
      "\n",
      "스포츠\n",
      "\n",
      "날씨\n",
      "\n",
      "프리미엄\n",
      "\n",
      "검색\n",
      "\n",
      "언론사별\n",
      "\n",
      "정치\n",
      "\n",
      "경제\n",
      "\n",
      "사회\n",
      "\n",
      "생활/문화\n",
      "\n",
      "IT/과학\n",
      "\n",
      "세계\n",
      "\n",
      "랭킹\n",
      "\n",
      "신문보기\n",
      "\n",
      "오피니언\n",
      "\n",
      "TV\n",
      "\n",
      "팩트체크\n",
      "\n",
      "알고리즘 안내\n",
      "\n",
      "정정보도 모음\n",
      "\n",
      "지디넷코리아\n",
      "\n",
      "지디넷코리아\n",
      "\n",
      "구독\n",
      "\n",
      "지디넷코리아 언론사 구독되었습니다. 메인 뉴스판에서 주요뉴스를 볼 수 있습니다.\n",
      "보러가기\n",
      "닫기\n",
      "\n",
      "지디넷코리아 언론사 구독 해지되었습니\n",
      "2 https://n.news.naver.com/mnews/article/092/0002358620\n",
      "브래드 스미스(Brad Smith) 마이크로소프트 부회장 (사진=MS)MS는 지난해 7~9월인 회계연도 1분기에 전 세계에서 200억 달러를 지출했다. 이 중 149억 달러가 부동산과 장비에 지출됐다. 2분기에도 지출이 증가할 것이라고 예고한 바 있다. 3분기 지출금은 전년 동기 대비 50% 늘어난 149억 달러(약 21조4053억원)로, 이 중 대부분이 데이터 센터 증축에 사용됐다.앞서 MS는 2024 회계연도에 AI 투자를 포함한 전체 자본\n",
      "3 https://n.news.naver.com/mnews/article/092/0002358620\n",
      "장유미 기자(sweet@zdnet.co.kr)\n",
      "4 https://n.news.naver.com/mnews/article/008/0005136824\n",
      "추천\n",
      "반응\n",
      "\n",
      "쏠쏠정보\n",
      "0\n",
      "\n",
      "흥미진진\n",
      "0\n",
      "\n",
      "공감백배\n",
      "0\n",
      "\n",
      "분석탁월\n",
      "0\n",
      "\n",
      "후속강추\n",
      "0\n",
      "\n",
      "댓글\n",
      "반응\n",
      "\n",
      "텍스트 음성 변환 서비스 사용하기\n",
      "\n",
      "성별\n",
      "남성\n",
      "여성\n",
      "\n",
      "말하기 속도\n",
      "느림\n",
      "보통\n",
      "빠름\n",
      "\n",
      "이동 통신망을 이용하여 음성을 재생하면 별도의 데이터 통화료가 부과될 수 있습니다.\n",
      "본문듣기 시작\n",
      "\n",
      "닫기\n",
      "\n",
      "글자 크기 변경하기\n",
      "\n",
      "글자크기\n",
      "\n",
      "가1단계\n",
      "작게\n",
      "\n",
      "가2단계\n",
      "보통\n",
      "\n",
      "가3단계\n",
      "크게\n",
      "\n",
      "가4단계\n",
      "아주크게\n",
      "\n",
      "가5단계\n",
      "최대크게\n",
      "\n",
      "닫기\n",
      "\n",
      "SNS 보내기\n",
      "\n",
      "인쇄하기\n",
      "\n",
      "[게임\n"
     ]
    }
   ],
   "source": [
    "# 5단계: RAG 기반 QA 체인 구현\n",
    "\"\"\"\n",
    "힌트:\n",
    "- ChatOpenAI로 LLM 모델을 생성하세요 (model=\"gpt-4.1-nano\")\n",
    "- ChatPromptTemplate으로 프롬프트 템플릿을 만드세요\n",
    "- 벡터 저장소에서 as_retriever()로 검색기를 생성하세요\n",
    "- RunnableParallel 사용하여 RAG 체인을 구성하세요\n",
    "\n",
    "기대 출력:\n",
    "- RAG 체인 생성 완료\n",
    "\"\"\"\n",
    "# RunableParallel을 사용한 RAG 체인\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# ChatOpenAI로 LLM 모델을 생성하세요 (model=\"gpt-4.1-nano\") \n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\",temperature=0)\n",
    "# llm = ChatOpenAI(model=\"gpt-4.1-mini\",temperature=0)\n",
    "# llm = ChatOpenAI(model=\"gpt-4.1\",temperature=0)\n",
    "\n",
    "# ChatPromptTemplate으로 프롬프트 템플릿 생성\n",
    "# 시스템 프롬프트\n",
    "system_prompt = (\n",
    "\t\"너는 뉴스 요약 비서야, 제공된 자료에서만 근거를 사용해 답해. \"\n",
    "\t\"자료에 없는 내용은 '확인불가'라고 말해. 추측 금지. \"\n",
    "\t\"한국어로 간결하고 정확하게 답변해.\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "\t(\"system\", system_prompt),\n",
    "\t(\"human\", \n",
    "\t\"아래 자료를 바탕으로 질문에 답해줘.\\n\\n\"\n",
    "\t\"## 자료\\n{context}\\n\\n\"\n",
    "\t\"## 질문\\n{question}\\n\\n\"\n",
    "\t\"출력형식 : \\n\"\n",
    "\t\"1) 요약: (3~5문장)\\n\"\n",
    "\t\"2) 주요 인물: (이름 목록)\\n\"\n",
    "\t\"3) 사건/이슈: (한 문장)\\n\"\n",
    "\t)\n",
    "])\n",
    "\n",
    "# 벡터 저장소에서 as_retriever()로 검색기를 생성\n",
    "retriever = vector_store.as_retriever(\n",
    "\tsearch_type=\"mmr\", # 다양성 확보 - 3개 기사에서 골고루 뽑히기 쉬움\n",
    "\tsearch_kwargs={\"k\": 12, \"fetch_k\": 30} # k를 늘려야 요약 자료가 생김\n",
    ")\n",
    "\n",
    "rag_chain = (\n",
    "\tRunnableParallel({\n",
    "\t\t\"docs\": retriever,\n",
    "\t\t\"question\": RunnablePassthrough()\n",
    "\t}) \n",
    "\t| RunnableLambda(lambda x: {\n",
    "\t\t\"context\": \"\\n\\n\".join(doc.page_content for doc in x[\"docs\"]), # docs -> context 문자열화\n",
    "\t\t\"question\": x[\"question\"]\n",
    "\t})\n",
    "\t| prompt \n",
    "\t| llm \n",
    "\t| StrOutputParser()\n",
    ")\n",
    "\n",
    "# 6단계: QA 체인으로 질문 응답\n",
    "\"\"\"\n",
    "힌트:\n",
    "- 뉴스 기사와 관련된 질문을 준비하세요\n",
    "- rag_chain.invoke({\"question\": 질문})으로 답변을 얻으세요\n",
    "- response['answer']로 답변 내용을 확인하세요\n",
    "- response['context']로 검색된 문서를 확인하세요\n",
    "\n",
    "기대 출력:\n",
    "- 질문에 대한 답변이 출력됩니다\n",
    "- 검색된 관련 문서들의 내용이 포함됩니다\n",
    "\n",
    "예시 질문:\n",
    "- \"기사의 주요 내용을 요약해주세요\"\n",
    "- \"주요 인물은 누구인가요?\"\n",
    "- \"어떤 사건에 대한 기사인가요?\"\n",
    "\"\"\"\n",
    "\n",
    "# query = \"1. 기사의 내용을 요약해주세요. 2. 주요 인물은 누구인가요? 3. 어떤 사건에 대한 기사인가요?\"\n",
    "# response = rag_chain.invoke(query)\n",
    "\n",
    "# print(f\"\\n답변:\\n{response}\")\n",
    "\n",
    "hits = retriever.invoke(\"기사 내용을 요약해줘\")\n",
    "for idx, doc in enumerate(hits[:10]):\n",
    "\tprint(f\"\\n--- hit {idx} ---\") \n",
    "\tprint(f\"source: {doc.metadata.get('source')}\") \n",
    "\tprint(doc.page_content[:250])\n",
    "\n",
    "hits = retriever.invoke(\"MS가 데이터센터에 800억 달러 투자한다는 내용 요약해줘\")\n",
    "for i, d in enumerate(hits[:5]):\n",
    "    print(i, d.metadata.get(\"source\"))\n",
    "    print(d.page_content[:250])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7a907",
   "metadata": {},
   "source": [
    "### 실습 프로젝트\n",
    "\n",
    "[RAG 파이프라인 구축하기] 이제 배운 내용을 바탕으로 실제 RAG 파이프라인을 직접 구축해보겠습니다.\n",
    "\n",
    "**목표**: 뉴스 기사를 로드하고, 청크로 분할하여 벡터 저장소에 저장한 후, 질문에 답변하는 RAG 시스템 구축\n",
    "\n",
    "**단계별 가이드**:\n",
    "1. 데이터 준비 → 텍스트 처리 → 임베딩 → 검색 → 평가\n",
    "2. 각 과제마다 구현해야 할 함수와 결과물 정의\n",
    "3. 단위 테스트를 통한 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47350baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1단계: 데이터 준비 - 웹문서 검색을 위해 관련 URL 가져오기\n",
    "web_urls = [\n",
    "    \"https://n.news.naver.com/mnews/article/029/0002927209\",\n",
    "    \"https://n.news.naver.com/mnews/article/092/0002358620\",\n",
    "    \"https://n.news.naver.com/mnews/article/008/0005136824\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b0b3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2단계: WebBaseLoader를 사용해 텍스트 로드\n",
    "\"\"\"\n",
    "힌트:\n",
    "- WebBaseLoader를 사용하여 web_urls의 문서들을 로드하세요\n",
    "- loader.load()를 호출하여 Document 객체 리스트를 얻습니다\n",
    "- 로드된 문서의 개수를 출력하여 확인하세요\n",
    "\n",
    "기대 출력:\n",
    "- 로드된 문서 개수: 3개 (URL 개수와 동일)\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e65389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3단계: CharacterTextSplitter로 문서 분할\n",
    "\"\"\"\n",
    "힌트:\n",
    "- CharacterTextSplitter를 import하세요\n",
    "- chunk_size=500, chunk_overlap=100으로 설정하세요\n",
    "- separator=\"\\n\\n\"로 문단 단위 분할\n",
    "- split_documents() 메서드를 사용하여 문서를 분할하세요\n",
    "- 분할된 청크의 개수를 출력하세요\n",
    "\n",
    "기대 출력:\n",
    "- 분할된 청크 개수: 약 20-40개 (문서 내용에 따라 다를 수 있음)\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d47d6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4단계: 임베딩 및 벡터 저장소 구현\n",
    "\"\"\"\n",
    "힌트:\n",
    "- OpenAIEmbeddings를 사용하여 임베딩 모델을 생성하세요\n",
    "- Chroma 벡터 저장소를 생성하세요\n",
    "- add_documents()를 사용하여 분할된 문서를 벡터 저장소에 추가하세요\n",
    "- 저장된 문서 개수를 확인하세요\n",
    "\n",
    "기대 출력:\n",
    "- 임베딩 모델 생성 완료\n",
    "- 벡터 저장소에 저장된 문서 개수: (3단계의 청크 개수와 동일)\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e42d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5단계: RAG 기반 QA 체인 구현\n",
    "\"\"\"\n",
    "힌트:\n",
    "- ChatOpenAI로 LLM 모델을 생성하세요 (model=\"gpt-4.1-nano\")\n",
    "- ChatPromptTemplate으로 프롬프트 템플릿을 만드세요\n",
    "- 벡터 저장소에서 as_retriever()로 검색기를 생성하세요\n",
    "- RunnableParallel 사용하여 RAG 체인을 구성하세요\n",
    "\n",
    "기대 출력:\n",
    "- RAG 체인 생성 완료\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b26d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6단계: QA 체인으로 질문 응답\n",
    "\"\"\"\n",
    "힌트:\n",
    "- 뉴스 기사와 관련된 질문을 준비하세요\n",
    "- rag_chain.invoke({\"question\": 질문})으로 답변을 얻으세요\n",
    "- response['answer']로 답변 내용을 확인하세요\n",
    "- response['context']로 검색된 문서를 확인하세요\n",
    "\n",
    "기대 출력:\n",
    "- 질문에 대한 답변이 출력됩니다\n",
    "- 검색된 관련 문서들의 내용이 포함됩니다\n",
    "\n",
    "예시 질문:\n",
    "- \"기사의 주요 내용을 요약해주세요\"\n",
    "- \"주요 인물은 누구인가요?\"\n",
    "- \"어떤 사건에 대한 기사인가요?\"\n",
    "\"\"\"\n",
    "pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "001-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
