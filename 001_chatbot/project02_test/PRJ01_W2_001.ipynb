{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53bde2eb",
   "metadata": {},
   "source": [
    "NLP 기초: Tokenization + Embediding이해\n",
    "\n",
    "학습 목표\n",
    "1. 토큰화(Tokenization) 이해\n",
    "\t- 단어 단위 토큰화 (형태소 분석)\n",
    "\t- 서브워드 토큰화 (wordPiece, sentencePiece)\n",
    "\t- 한국어 토큰화 도구 활용 (Kiwi, BERT, BGE-M3)\n",
    "2. 임배딩(Embedding) 이해\n",
    "\t- 단어 임베딩(BoW, TF-IDF, Word2Vec)\n",
    "\t- 문장 임베딩(평균 기반, SBERT)\n",
    "\t- 임베딩 벡터 의미와 활용\n",
    "3. 텍스트 유사도 측정\n",
    "\t- 유사도 메트릭(유클리드 거리, 코사인 유사도, 내적)\n",
    "\t- 실제 문장 간 유사도 비교\n",
    "\t- 유사도 결과 시각화\n",
    "\n",
    "### Toeknization 토큰화\n",
    "- 개념: 텍스트를 분석 가능한 작은 단위로 나누는 과정, 컴퓨터가 자연어를 이해하기 위한 첫 단계로, 의미있는 최소 단위로 텍스트를 분할한다.\n",
    "\t- 단어 단위 토큰화 : Word Tokenization\n",
    "\t- 서브워드 토큰화 : Subword Tokenization\n",
    "\n",
    "1. 단어 단위 토큰화 Word Tokenization\n",
    "\t- 특징\n",
    "\t\t- 형태소 분석을 기반으로 의미 있는 최소 단위로 분리\n",
    "\t\t- 조사, 어미 등 문법적 요소도 개별 토큰으로 분리\n",
    "\t\t- 한국어의 교착어 특성을 잘 반영\n",
    "\t- 활용 분야\n",
    "\t\t- 문장 분석, 품사 태깅\n",
    "\t\t- 텍스트 분류, 감성 분석\n",
    "\t\t- 구문 분석, 의존 구문 분석\n",
    "\t- 예시 : `\"자연어처리는 재미있다\"` ->  → `[\"자연어\", \"처리\", \"는\", \"재미\", \"있\", \"다\"]`\n",
    "\n",
    "2. 서브워드 토큰화 Subword Tokenization\n",
    "- 특징\n",
    "\t- 형태소보다 작은 의미 단위 사용 > 문법체계보다 더 작은 단위\n",
    "\t- 자주 등장하는 문자열 패턴을 토큰으로 활용 > 자주 보이는 문자열의 조합을 토큰으로 정의하는 방식으로 학습하는 것 같다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
